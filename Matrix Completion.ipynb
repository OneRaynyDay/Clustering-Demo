{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayzhang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3,13,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, MatrixFactorization\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('data_formatted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()\n",
    "df = df[columns[16:31]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uses_slides</th>\n",
       "      <th>tolerates_tardiness</th>\n",
       "      <th>needs_textbook</th>\n",
       "      <th>is_podcasted</th>\n",
       "      <th>engaging_lectures</th>\n",
       "      <th>useful_textbooks</th>\n",
       "      <th>appropriately_priced</th>\n",
       "      <th>snazzy_dresser</th>\n",
       "      <th>often_funny</th>\n",
       "      <th>tough_tests</th>\n",
       "      <th>participation_matters</th>\n",
       "      <th>gives_extra_credit</th>\n",
       "      <th>would_take_again</th>\n",
       "      <th>group_projects</th>\n",
       "      <th>issues_ptes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uses_slides tolerates_tardiness needs_textbook is_podcasted  \\\n",
       "0         NaN                 NaN            NaN          NaN   \n",
       "1         NaN                 NaN            NaN          NaN   \n",
       "2         NaN                 NaN            NaN          NaN   \n",
       "3         NaN                 NaN            NaN          NaN   \n",
       "4         NaN                 NaN            NaN          NaN   \n",
       "\n",
       "  engaging_lectures useful_textbooks appropriately_priced snazzy_dresser  \\\n",
       "0               NaN              NaN                  NaN            NaN   \n",
       "1               NaN              NaN                  NaN            NaN   \n",
       "2               NaN              NaN                  NaN            NaN   \n",
       "3               NaN              NaN                  NaN            NaN   \n",
       "4               NaN              NaN                  NaN            NaN   \n",
       "\n",
       "  often_funny tough_tests participation_matters gives_extra_credit  \\\n",
       "0         NaN         NaN                   NaN                NaN   \n",
       "1         NaN         NaN                   NaN                NaN   \n",
       "2         NaN         NaN                   NaN                NaN   \n",
       "3         NaN         NaN                   NaN                NaN   \n",
       "4         NaN         NaN                   NaN                NaN   \n",
       "\n",
       "  would_take_again group_projects issues_ptes  \n",
       "0              NaN            NaN         NaN  \n",
       "1              NaN            NaN         NaN  \n",
       "2              NaN            NaN         NaN  \n",
       "3              NaN            NaN         NaN  \n",
       "4              NaN            NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uses_slides</th>\n",
       "      <th>tolerates_tardiness</th>\n",
       "      <th>needs_textbook</th>\n",
       "      <th>is_podcasted</th>\n",
       "      <th>engaging_lectures</th>\n",
       "      <th>useful_textbooks</th>\n",
       "      <th>appropriately_priced</th>\n",
       "      <th>snazzy_dresser</th>\n",
       "      <th>often_funny</th>\n",
       "      <th>tough_tests</th>\n",
       "      <th>participation_matters</th>\n",
       "      <th>gives_extra_credit</th>\n",
       "      <th>would_take_again</th>\n",
       "      <th>group_projects</th>\n",
       "      <th>issues_ptes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4801</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4808</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4811</th>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4812</th>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4815</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4816</th>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4821</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4825</th>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4826</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4832</th>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uses_slides tolerates_tardiness needs_textbook is_podcasted  \\\n",
       "5              f                   f              t            f   \n",
       "9              f                 NaN              t            f   \n",
       "12             t                   t              t            t   \n",
       "13             t                   t              t            f   \n",
       "14             f                   f              f            f   \n",
       "15             t                   t              t            f   \n",
       "16             t                   t            NaN            f   \n",
       "17             t                   t              f            f   \n",
       "19           NaN                 NaN              t          NaN   \n",
       "20             t                   f              f            f   \n",
       "21           NaN                   f              f            f   \n",
       "24           NaN                 NaN            NaN            f   \n",
       "27             f                   t              t            f   \n",
       "31             f                   f              t            f   \n",
       "32             f                   t              t            f   \n",
       "33             t                   f              t            f   \n",
       "35             t                   t              f            f   \n",
       "37           NaN                 NaN            NaN          NaN   \n",
       "38             f                   t              t            f   \n",
       "39           NaN                 NaN            NaN          NaN   \n",
       "40             t                   t              t            f   \n",
       "41             f                   t              t            f   \n",
       "42             t                   t            NaN          NaN   \n",
       "43             t                   t              f            t   \n",
       "44             t                   t              f            f   \n",
       "45             t                   t              t            f   \n",
       "46             t                   f              f            t   \n",
       "49             t                 NaN              f            f   \n",
       "50             t                   t              t            f   \n",
       "51             t                   t              f            f   \n",
       "...          ...                 ...            ...          ...   \n",
       "4800           t                   t              t            t   \n",
       "4801           t                   t              t            f   \n",
       "4802           t                   f              t            f   \n",
       "4803           t                   t              t            f   \n",
       "4804           f                   t              t            f   \n",
       "4807           f                   t              f            t   \n",
       "4808           t                   t              f            f   \n",
       "4809           f                   t              f            f   \n",
       "4810           t                   f              t          NaN   \n",
       "4811         NaN                   t              t            f   \n",
       "4812           f                 NaN            NaN            f   \n",
       "4813           t                   t              t            f   \n",
       "4814           f                 NaN              t            t   \n",
       "4815           t                   t              t            f   \n",
       "4816         NaN                   t              t            f   \n",
       "4817           t                   t              t            f   \n",
       "4818           t                 NaN              t            f   \n",
       "4819           t                   t              t            f   \n",
       "4821           t                   t              t            t   \n",
       "4822           f                   t              t            f   \n",
       "4823           f                   t              t            t   \n",
       "4824         NaN                 NaN            NaN          NaN   \n",
       "4825           f                   t              t            f   \n",
       "4826           t                   t              f            f   \n",
       "4827           t                 NaN            NaN            f   \n",
       "4828           t                 NaN            NaN          NaN   \n",
       "4829           f                 NaN            NaN          NaN   \n",
       "4830           t                   t              t          NaN   \n",
       "4831           t                   t              t            f   \n",
       "4832           f                 NaN            NaN            f   \n",
       "\n",
       "     engaging_lectures useful_textbooks appropriately_priced snazzy_dresser  \\\n",
       "5                    t                t                    t              t   \n",
       "9                    f                t                  NaN              t   \n",
       "12                   t                t                    t              f   \n",
       "13                   t                f                    f              f   \n",
       "14                   f                f                    t              f   \n",
       "15                   t                t                    t              t   \n",
       "16                   t                f                  NaN              t   \n",
       "17                   f                f                    f              f   \n",
       "19                 NaN              NaN                  NaN            NaN   \n",
       "20                   t                t                    t              t   \n",
       "21                   t              NaN                  NaN            NaN   \n",
       "24                   t                t                  NaN            NaN   \n",
       "27                 NaN                t                  NaN            NaN   \n",
       "31                   f                t                    f              f   \n",
       "32                   f                t                    t              f   \n",
       "33                   t                t                    f              t   \n",
       "35                   f                t                    f              t   \n",
       "37                 NaN              NaN                  NaN            NaN   \n",
       "38                   f                t                    t              f   \n",
       "39                 NaN              NaN                  NaN            NaN   \n",
       "40                   f              NaN                  NaN              f   \n",
       "41                   t                t                    f            NaN   \n",
       "42                   t              NaN                  NaN            NaN   \n",
       "43                   t                f                  NaN            NaN   \n",
       "44                   t                f                    f              f   \n",
       "45                   f                f                    f              f   \n",
       "46                   f                f                    f              f   \n",
       "49                   f                f                  NaN              f   \n",
       "50                   t                t                    t              t   \n",
       "51                   t                f                    f              f   \n",
       "...                ...              ...                  ...            ...   \n",
       "4800                 t                f                    t              t   \n",
       "4801                 t                t                    t              t   \n",
       "4802                 t                t                    t              t   \n",
       "4803                 t                t                    t              t   \n",
       "4804                 t                t                    t              f   \n",
       "4807               NaN                t                    t              t   \n",
       "4808                 t                t                    t              t   \n",
       "4809                 t                f                    t              t   \n",
       "4810                 t                t                  NaN              t   \n",
       "4811                 t                t                    t              f   \n",
       "4812                 f              NaN                  NaN              f   \n",
       "4813                 t                t                    t              t   \n",
       "4814                 t                t                    t              f   \n",
       "4815                 t                t                    t              t   \n",
       "4816               NaN                t                  NaN            NaN   \n",
       "4817               NaN                f                  NaN            NaN   \n",
       "4818                 t                t                    f              t   \n",
       "4819                 t                t                    t              t   \n",
       "4821                 t                f                  NaN            NaN   \n",
       "4822                 t                t                    t              t   \n",
       "4823                 t                t                  NaN              f   \n",
       "4824               NaN              NaN                  NaN            NaN   \n",
       "4825                 t                t                  NaN              t   \n",
       "4826                 f              NaN                    t            NaN   \n",
       "4827                 t                f                  NaN            NaN   \n",
       "4828                 f                t                  NaN              f   \n",
       "4829                 f              NaN                  NaN            NaN   \n",
       "4830                 t                t                    t            NaN   \n",
       "4831                 t                f                    t              f   \n",
       "4832                 t                f                  NaN            NaN   \n",
       "\n",
       "     often_funny tough_tests participation_matters gives_extra_credit  \\\n",
       "5              t           f                     f                  f   \n",
       "9              f         NaN                   NaN                  f   \n",
       "12             t           f                     f                  t   \n",
       "13             t           f                     f                  t   \n",
       "14             f           t                     t                  f   \n",
       "15             t           f                     t                  f   \n",
       "16             t           f                     f                NaN   \n",
       "17             f           t                     f                  f   \n",
       "19           NaN         NaN                   NaN                NaN   \n",
       "20             t           t                     t                  t   \n",
       "21             t           f                     f                  f   \n",
       "24             t         NaN                   NaN                NaN   \n",
       "27           NaN           t                     f                  f   \n",
       "31             t           t                     f                  f   \n",
       "32             f           t                     t                  f   \n",
       "33             t           t                     t                  f   \n",
       "35             f           f                     t                  f   \n",
       "37           NaN         NaN                   NaN                NaN   \n",
       "38             t           t                     t                  f   \n",
       "39           NaN           t                   NaN                NaN   \n",
       "40             f         NaN                     t                NaN   \n",
       "41             f           f                     t                  f   \n",
       "42           NaN         NaN                   NaN                NaN   \n",
       "43             t           t                     f                  f   \n",
       "44             t           t                     f                  f   \n",
       "45             f           t                     t                  f   \n",
       "46             f           t                     f                  t   \n",
       "49             f         NaN                     t                  f   \n",
       "50             t           f                     f                  f   \n",
       "51             f           t                     f                  t   \n",
       "...          ...         ...                   ...                ...   \n",
       "4800           t           f                     f                  f   \n",
       "4801           f           f                     t                  f   \n",
       "4802           t           f                     t                  f   \n",
       "4803           f           f                     t                  f   \n",
       "4804           f           t                     t                  f   \n",
       "4807           f           t                     f                  f   \n",
       "4808           t           t                     f                  t   \n",
       "4809           t           t                     f                  f   \n",
       "4810           f           t                     t                  t   \n",
       "4811           t           f                     f                  t   \n",
       "4812           f           f                     f                  f   \n",
       "4813           t           f                     t                  f   \n",
       "4814           t           f                     f                  f   \n",
       "4815           t           f                     t                  f   \n",
       "4816           t         NaN                   NaN                NaN   \n",
       "4817           f           f                   NaN                  t   \n",
       "4818           t           f                     f                NaN   \n",
       "4819           t           f                     t                  t   \n",
       "4821           t           f                     t                  f   \n",
       "4822           t           t                     f                  f   \n",
       "4823           t           t                     f                  f   \n",
       "4824         NaN         NaN                   NaN                NaN   \n",
       "4825           t           f                     f                  f   \n",
       "4826           f           t                     f                  t   \n",
       "4827           t           f                   NaN                  f   \n",
       "4828         NaN           t                     f                NaN   \n",
       "4829           f           t                   NaN                NaN   \n",
       "4830           t           f                     t                NaN   \n",
       "4831           t           f                     f                  f   \n",
       "4832         NaN         NaN                     f                NaN   \n",
       "\n",
       "     would_take_again group_projects issues_ptes  \n",
       "5                   t              f           t  \n",
       "9                   f              f         NaN  \n",
       "12                  t              f           f  \n",
       "13                  t              f           f  \n",
       "14                  f              t           t  \n",
       "15                  t              f           f  \n",
       "16                  t              f         NaN  \n",
       "17                  f              f         NaN  \n",
       "19                NaN            NaN         NaN  \n",
       "20                  t              f           f  \n",
       "21                  t              f         NaN  \n",
       "24                NaN            NaN         NaN  \n",
       "27                NaN              f         NaN  \n",
       "31                  t              f           f  \n",
       "32                  f              f           f  \n",
       "33                  t              t           f  \n",
       "35                  t              f           f  \n",
       "37                NaN            NaN           f  \n",
       "38                  f              f         NaN  \n",
       "39                NaN            NaN         NaN  \n",
       "40                  f              f         NaN  \n",
       "41                  t              f         NaN  \n",
       "42                NaN            NaN         NaN  \n",
       "43                  t              f         NaN  \n",
       "44                  t              f           f  \n",
       "45                  f              t           t  \n",
       "46                  f              f         NaN  \n",
       "49                  f            NaN         NaN  \n",
       "50                  t              f           f  \n",
       "51                  t              f           f  \n",
       "...               ...            ...         ...  \n",
       "4800                t              f           f  \n",
       "4801                f              f           f  \n",
       "4802                t              f           f  \n",
       "4803                f              f           f  \n",
       "4804                t              f           f  \n",
       "4807                t              f           t  \n",
       "4808                t              t           f  \n",
       "4809                f              f         NaN  \n",
       "4810                f              f           f  \n",
       "4811                t              f           f  \n",
       "4812                f              f         NaN  \n",
       "4813                t              t           t  \n",
       "4814                t              f           f  \n",
       "4815                t              f           f  \n",
       "4816              NaN            NaN         NaN  \n",
       "4817              NaN            NaN         NaN  \n",
       "4818                t              f         NaN  \n",
       "4819                t              t         NaN  \n",
       "4821                t              t           t  \n",
       "4822                t              f           f  \n",
       "4823                t              f           t  \n",
       "4824              NaN              f         NaN  \n",
       "4825                t              f         NaN  \n",
       "4826              NaN              f         NaN  \n",
       "4827                t              f           f  \n",
       "4828                f            NaN         NaN  \n",
       "4829              NaN              f         NaN  \n",
       "4830                t              t           t  \n",
       "4831                t              f         NaN  \n",
       "4832                t            NaN         NaN  \n",
       "\n",
       "[3467 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how='all')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   1., ...,   1.,   0.,   1.],\n",
       "       [  0.,  nan,   1., ...,   0.,   0.,  nan],\n",
       "       [  1.,   1.,   1., ...,   1.,   0.,   0.],\n",
       "       ..., \n",
       "       [  1.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [  1.,   1.,   1., ...,   1.,   0.,  nan],\n",
       "       [  0.,  nan,  nan, ...,   1.,  nan,  nan]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.values\n",
    "x[x=='f'] = 0.\n",
    "x[x=='t'] = 1.\n",
    "x = x.astype(np.float64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.ma.array(x, mask=np.isnan(x)) # Use a mask to mark the NaNs\n",
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "x = x - mean # The sum function ignores the masked values.\n",
    "x = x / std # The std function ignores the masked values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/3467 with 0 missing, elapsed time: 2.334\n",
      "Imputing row 101/3467 with 12 missing, elapsed time: 2.345\n",
      "Imputing row 201/3467 with 14 missing, elapsed time: 2.357\n",
      "Imputing row 301/3467 with 14 missing, elapsed time: 2.367\n",
      "Imputing row 401/3467 with 0 missing, elapsed time: 2.378\n",
      "Imputing row 501/3467 with 0 missing, elapsed time: 2.388\n",
      "Imputing row 601/3467 with 14 missing, elapsed time: 2.400\n",
      "Imputing row 701/3467 with 0 missing, elapsed time: 2.413\n",
      "Imputing row 801/3467 with 0 missing, elapsed time: 2.422\n",
      "Imputing row 901/3467 with 14 missing, elapsed time: 2.432\n",
      "Imputing row 1001/3467 with 14 missing, elapsed time: 2.445\n",
      "Imputing row 1101/3467 with 2 missing, elapsed time: 2.456\n",
      "Imputing row 1201/3467 with 1 missing, elapsed time: 2.467\n",
      "Imputing row 1301/3467 with 0 missing, elapsed time: 2.478\n",
      "Imputing row 1401/3467 with 2 missing, elapsed time: 2.487\n",
      "Imputing row 1501/3467 with 0 missing, elapsed time: 2.500\n",
      "Imputing row 1601/3467 with 6 missing, elapsed time: 2.512\n",
      "Imputing row 1701/3467 with 14 missing, elapsed time: 2.527\n",
      "Imputing row 1801/3467 with 0 missing, elapsed time: 2.540\n",
      "Imputing row 1901/3467 with 1 missing, elapsed time: 2.552\n",
      "Imputing row 2001/3467 with 13 missing, elapsed time: 2.561\n",
      "Imputing row 2101/3467 with 7 missing, elapsed time: 2.571\n",
      "Imputing row 2201/3467 with 1 missing, elapsed time: 2.579\n",
      "Imputing row 2301/3467 with 5 missing, elapsed time: 2.588\n",
      "Imputing row 2401/3467 with 0 missing, elapsed time: 2.598\n",
      "Imputing row 2501/3467 with 0 missing, elapsed time: 2.609\n",
      "Imputing row 2601/3467 with 13 missing, elapsed time: 2.620\n",
      "Imputing row 2701/3467 with 1 missing, elapsed time: 2.627\n",
      "Imputing row 2801/3467 with 13 missing, elapsed time: 2.638\n",
      "Imputing row 2901/3467 with 14 missing, elapsed time: 2.650\n",
      "Imputing row 3001/3467 with 9 missing, elapsed time: 2.660\n",
      "Imputing row 3101/3467 with 1 missing, elapsed time: 2.669\n",
      "Imputing row 3201/3467 with 4 missing, elapsed time: 2.678\n",
      "Imputing row 3301/3467 with 0 missing, elapsed time: 2.688\n",
      "Imputing row 3401/3467 with 14 missing, elapsed time: 2.696\n"
     ]
    }
   ],
   "source": [
    "x_filled_knn = KNN(k=8).complete(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SoftImpute] Max Singular Value of X_init = 89.487897\n",
      "[SoftImpute] Iter 1: observed MAE=0.033427 rank=15\n",
      "[SoftImpute] Iter 2: observed MAE=0.033426 rank=15\n",
      "[SoftImpute] Iter 3: observed MAE=0.033426 rank=15\n",
      "[SoftImpute] Iter 4: observed MAE=0.033425 rank=15\n",
      "[SoftImpute] Iter 5: observed MAE=0.033423 rank=15\n",
      "[SoftImpute] Iter 6: observed MAE=0.033421 rank=15\n",
      "[SoftImpute] Iter 7: observed MAE=0.033419 rank=15\n",
      "[SoftImpute] Iter 8: observed MAE=0.033417 rank=15\n",
      "[SoftImpute] Iter 9: observed MAE=0.033414 rank=15\n",
      "[SoftImpute] Iter 10: observed MAE=0.033411 rank=15\n",
      "[SoftImpute] Iter 11: observed MAE=0.033409 rank=15\n",
      "[SoftImpute] Iter 12: observed MAE=0.033405 rank=15\n",
      "[SoftImpute] Iter 13: observed MAE=0.033402 rank=15\n",
      "[SoftImpute] Iter 14: observed MAE=0.033399 rank=15\n",
      "[SoftImpute] Iter 15: observed MAE=0.033396 rank=15\n",
      "[SoftImpute] Iter 16: observed MAE=0.033392 rank=15\n",
      "[SoftImpute] Iter 17: observed MAE=0.033389 rank=15\n",
      "[SoftImpute] Iter 18: observed MAE=0.033385 rank=15\n",
      "[SoftImpute] Iter 19: observed MAE=0.033381 rank=15\n",
      "[SoftImpute] Iter 20: observed MAE=0.033378 rank=15\n",
      "[SoftImpute] Iter 21: observed MAE=0.033374 rank=15\n",
      "[SoftImpute] Iter 22: observed MAE=0.033371 rank=15\n",
      "[SoftImpute] Iter 23: observed MAE=0.033367 rank=15\n",
      "[SoftImpute] Iter 24: observed MAE=0.033363 rank=15\n",
      "[SoftImpute] Iter 25: observed MAE=0.033360 rank=15\n",
      "[SoftImpute] Iter 26: observed MAE=0.033356 rank=15\n",
      "[SoftImpute] Iter 27: observed MAE=0.033353 rank=15\n",
      "[SoftImpute] Iter 28: observed MAE=0.033349 rank=15\n",
      "[SoftImpute] Iter 29: observed MAE=0.033346 rank=15\n",
      "[SoftImpute] Iter 30: observed MAE=0.033343 rank=15\n",
      "[SoftImpute] Iter 31: observed MAE=0.033339 rank=15\n",
      "[SoftImpute] Iter 32: observed MAE=0.033336 rank=15\n",
      "[SoftImpute] Iter 33: observed MAE=0.033333 rank=15\n",
      "[SoftImpute] Iter 34: observed MAE=0.033330 rank=15\n",
      "[SoftImpute] Iter 35: observed MAE=0.033327 rank=15\n",
      "[SoftImpute] Iter 36: observed MAE=0.033323 rank=15\n",
      "[SoftImpute] Iter 37: observed MAE=0.033320 rank=15\n",
      "[SoftImpute] Iter 38: observed MAE=0.033318 rank=15\n",
      "[SoftImpute] Iter 39: observed MAE=0.033315 rank=15\n",
      "[SoftImpute] Iter 40: observed MAE=0.033312 rank=15\n",
      "[SoftImpute] Iter 41: observed MAE=0.033309 rank=15\n",
      "[SoftImpute] Iter 42: observed MAE=0.033306 rank=15\n",
      "[SoftImpute] Iter 43: observed MAE=0.033304 rank=15\n",
      "[SoftImpute] Iter 44: observed MAE=0.033301 rank=15\n",
      "[SoftImpute] Iter 45: observed MAE=0.033299 rank=15\n",
      "[SoftImpute] Iter 46: observed MAE=0.033296 rank=15\n",
      "[SoftImpute] Iter 47: observed MAE=0.033294 rank=15\n",
      "[SoftImpute] Iter 48: observed MAE=0.033292 rank=15\n",
      "[SoftImpute] Iter 49: observed MAE=0.033289 rank=15\n",
      "[SoftImpute] Iter 50: observed MAE=0.033287 rank=15\n",
      "[SoftImpute] Iter 51: observed MAE=0.033285 rank=15\n",
      "[SoftImpute] Iter 52: observed MAE=0.033283 rank=15\n",
      "[SoftImpute] Iter 53: observed MAE=0.033281 rank=15\n",
      "[SoftImpute] Iter 54: observed MAE=0.033279 rank=15\n",
      "[SoftImpute] Iter 55: observed MAE=0.033277 rank=15\n",
      "[SoftImpute] Iter 56: observed MAE=0.033275 rank=15\n",
      "[SoftImpute] Iter 57: observed MAE=0.033273 rank=15\n",
      "[SoftImpute] Iter 58: observed MAE=0.033272 rank=15\n",
      "[SoftImpute] Iter 59: observed MAE=0.033270 rank=15\n",
      "[SoftImpute] Iter 60: observed MAE=0.033268 rank=15\n",
      "[SoftImpute] Iter 61: observed MAE=0.033267 rank=15\n",
      "[SoftImpute] Iter 62: observed MAE=0.033265 rank=15\n",
      "[SoftImpute] Iter 63: observed MAE=0.033263 rank=15\n",
      "[SoftImpute] Iter 64: observed MAE=0.033262 rank=15\n",
      "[SoftImpute] Iter 65: observed MAE=0.033261 rank=15\n",
      "[SoftImpute] Iter 66: observed MAE=0.033259 rank=15\n",
      "[SoftImpute] Iter 67: observed MAE=0.033258 rank=15\n",
      "[SoftImpute] Iter 68: observed MAE=0.033256 rank=15\n",
      "[SoftImpute] Iter 69: observed MAE=0.033255 rank=15\n",
      "[SoftImpute] Iter 70: observed MAE=0.033254 rank=15\n",
      "[SoftImpute] Iter 71: observed MAE=0.033253 rank=15\n",
      "[SoftImpute] Iter 72: observed MAE=0.033251 rank=15\n",
      "[SoftImpute] Iter 73: observed MAE=0.033250 rank=15\n",
      "[SoftImpute] Iter 74: observed MAE=0.033249 rank=15\n",
      "[SoftImpute] Iter 75: observed MAE=0.033248 rank=15\n",
      "[SoftImpute] Iter 76: observed MAE=0.033247 rank=15\n",
      "[SoftImpute] Iter 77: observed MAE=0.033246 rank=15\n",
      "[SoftImpute] Iter 78: observed MAE=0.033245 rank=15\n",
      "[SoftImpute] Iter 79: observed MAE=0.033244 rank=15\n",
      "[SoftImpute] Iter 80: observed MAE=0.033243 rank=15\n",
      "[SoftImpute] Iter 81: observed MAE=0.033242 rank=15\n",
      "[SoftImpute] Iter 82: observed MAE=0.033241 rank=15\n",
      "[SoftImpute] Iter 83: observed MAE=0.033241 rank=15\n",
      "[SoftImpute] Iter 84: observed MAE=0.033240 rank=15\n",
      "[SoftImpute] Iter 85: observed MAE=0.033239 rank=15\n",
      "[SoftImpute] Iter 86: observed MAE=0.033238 rank=15\n",
      "[SoftImpute] Iter 87: observed MAE=0.033237 rank=15\n",
      "[SoftImpute] Iter 88: observed MAE=0.033237 rank=15\n",
      "[SoftImpute] Iter 89: observed MAE=0.033236 rank=15\n",
      "[SoftImpute] Iter 90: observed MAE=0.033235 rank=15\n",
      "[SoftImpute] Iter 91: observed MAE=0.033235 rank=15\n",
      "[SoftImpute] Iter 92: observed MAE=0.033234 rank=15\n",
      "[SoftImpute] Iter 93: observed MAE=0.033233 rank=15\n",
      "[SoftImpute] Iter 94: observed MAE=0.033233 rank=15\n",
      "[SoftImpute] Iter 95: observed MAE=0.033232 rank=15\n",
      "[SoftImpute] Iter 96: observed MAE=0.033232 rank=15\n",
      "[SoftImpute] Iter 97: observed MAE=0.033231 rank=15\n",
      "[SoftImpute] Iter 98: observed MAE=0.033230 rank=15\n",
      "[SoftImpute] Iter 99: observed MAE=0.033230 rank=15\n",
      "[SoftImpute] Iter 100: observed MAE=0.033229 rank=15\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=1.789758\n"
     ]
    }
   ],
   "source": [
    "x_filled_softimpute = SoftImpute().complete(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1 of 1 mini-batches from (3467, 15)\n",
      "downhill: compiling evaluation function\n",
      "downhill: compiling Adam optimizer\n",
      "downhill: setting: rms_halflife = 14\n",
      "downhill: setting: rms_regularizer = 1e-08\n",
      "downhill: setting: patience = 5\n",
      "downhill: setting: validate_every = 10\n",
      "downhill: setting: min_improvement = 0.005\n",
      "downhill: setting: max_gradient_norm = 5\n",
      "downhill: setting: max_gradient_elem = 0\n",
      "downhill: setting: learning_rate = TensorConstant{0.001}\n",
      "downhill: setting: momentum = 0\n",
      "downhill: setting: nesterov = False\n",
      "downhill: validation 0 loss=8.562536 error=8.273648 grad(V)=1.569059 grad(U)=0.015941 *\n",
      "downhill: Adam 1 loss=8.562536 error=8.273648 grad(V)=1.569059 grad(U)=0.015941\n",
      "downhill: Adam 2 loss=8.533726 error=8.245061 grad(V)=1.559738 grad(U)=0.015853\n",
      "downhill: Adam 3 loss=8.494965 error=8.206601 grad(V)=1.547233 grad(U)=0.015735\n",
      "downhill: Adam 4 loss=8.449814 error=8.161802 grad(V)=1.532721 grad(U)=0.015598\n",
      "downhill: Adam 5 loss=8.400227 error=8.112604 grad(V)=1.516849 grad(U)=0.015448\n",
      "downhill: Adam 6 loss=8.347486 error=8.060278 grad(V)=1.500044 grad(U)=0.015288\n",
      "downhill: Adam 7 loss=8.292508 error=8.005735 grad(V)=1.482609 grad(U)=0.015123\n",
      "downhill: Adam 8 loss=8.235976 error=7.949653 grad(V)=1.464771 grad(U)=0.014954\n",
      "downhill: Adam 9 loss=8.178415 error=7.892552 grad(V)=1.446702 grad(U)=0.014782\n",
      "downhill: Adam 10 loss=8.120235 error=7.834840 grad(V)=1.428535 grad(U)=0.014610\n",
      "downhill: validation 1 loss=8.061761 error=7.776839 grad(V)=1.410375 grad(U)=0.014438 *\n",
      "downhill: Adam 11 loss=8.061761 error=7.776839 grad(V)=1.410375 grad(U)=0.014438\n",
      "downhill: Adam 12 loss=8.003253 error=7.718806 grad(V)=1.392301 grad(U)=0.014266\n",
      "downhill: Adam 13 loss=7.944916 error=7.660947 grad(V)=1.374378 grad(U)=0.014095\n",
      "downhill: Adam 14 loss=7.886917 error=7.603424 grad(V)=1.356655 grad(U)=0.013927\n",
      "downhill: Adam 15 loss=7.829386 error=7.546370 grad(V)=1.339171 grad(U)=0.013761\n",
      "downhill: Adam 16 loss=7.772430 error=7.489886 grad(V)=1.321955 grad(U)=0.013597\n",
      "downhill: Adam 17 loss=7.716129 error=7.434056 grad(V)=1.305030 grad(U)=0.013435\n",
      "downhill: Adam 18 loss=7.660549 error=7.378943 grad(V)=1.288411 grad(U)=0.013277\n",
      "downhill: Adam 19 loss=7.605737 error=7.324594 grad(V)=1.272109 grad(U)=0.013121\n",
      "downhill: Adam 20 loss=7.551731 error=7.271046 grad(V)=1.256132 grad(U)=0.012969\n",
      "downhill: validation 2 loss=7.498556 error=7.218325 grad(V)=1.240483 grad(U)=0.012820 *\n",
      "downhill: Adam 21 loss=7.498556 error=7.218325 grad(V)=1.240483 grad(U)=0.012820\n",
      "downhill: Adam 22 loss=7.446228 error=7.166446 grad(V)=1.225164 grad(U)=0.012674\n",
      "downhill: Adam 23 loss=7.394759 error=7.115421 grad(V)=1.210174 grad(U)=0.012530\n",
      "downhill: Adam 24 loss=7.344151 error=7.065253 grad(V)=1.195510 grad(U)=0.012390\n",
      "downhill: Adam 25 loss=7.294406 error=7.015941 grad(V)=1.181169 grad(U)=0.012253\n",
      "downhill: Adam 26 loss=7.245518 error=6.967482 grad(V)=1.167145 grad(U)=0.012119\n",
      "downhill: Adam 27 loss=7.197480 error=6.919867 grad(V)=1.153433 grad(U)=0.011988\n",
      "downhill: Adam 28 loss=7.150282 error=6.873087 grad(V)=1.140026 grad(U)=0.011860\n",
      "downhill: Adam 29 loss=7.103910 error=6.827128 grad(V)=1.126918 grad(U)=0.011734\n",
      "downhill: Adam 30 loss=7.058351 error=6.781976 grad(V)=1.114100 grad(U)=0.011612\n",
      "downhill: validation 3 loss=7.013589 error=6.737617 grad(V)=1.101566 grad(U)=0.011492 *\n",
      "downhill: Adam 31 loss=7.013589 error=6.737617 grad(V)=1.101566 grad(U)=0.011492\n",
      "downhill: Adam 32 loss=6.969609 error=6.694034 grad(V)=1.089307 grad(U)=0.011374\n",
      "downhill: Adam 33 loss=6.926392 error=6.651209 grad(V)=1.077317 grad(U)=0.011259\n",
      "downhill: Adam 34 loss=6.883922 error=6.609127 grad(V)=1.065587 grad(U)=0.011147\n",
      "downhill: Adam 35 loss=6.842180 error=6.567767 grad(V)=1.054109 grad(U)=0.011037\n",
      "downhill: Adam 36 loss=6.801149 error=6.527113 grad(V)=1.042877 grad(U)=0.010929\n",
      "downhill: Adam 37 loss=6.760810 error=6.487147 grad(V)=1.031882 grad(U)=0.010824\n",
      "downhill: Adam 38 loss=6.721145 error=6.447851 grad(V)=1.021118 grad(U)=0.010721\n",
      "downhill: Adam 39 loss=6.682137 error=6.409206 grad(V)=1.010576 grad(U)=0.010620\n",
      "downhill: Adam 40 loss=6.643767 error=6.371195 grad(V)=1.000251 grad(U)=0.010521\n",
      "downhill: validation 4 loss=6.606018 error=6.333801 grad(V)=0.990135 grad(U)=0.010424 *\n",
      "downhill: Adam 41 loss=6.606018 error=6.333801 grad(V)=0.990135 grad(U)=0.010424\n",
      "downhill: Adam 42 loss=6.568874 error=6.297008 grad(V)=0.980222 grad(U)=0.010329\n",
      "downhill: Adam 43 loss=6.532316 error=6.260797 grad(V)=0.970506 grad(U)=0.010236\n",
      "downhill: Adam 44 loss=6.496329 error=6.225153 grad(V)=0.960979 grad(U)=0.010145\n",
      "downhill: Adam 45 loss=6.460898 error=6.190060 grad(V)=0.951637 grad(U)=0.010055\n",
      "downhill: Adam 46 loss=6.426006 error=6.155503 grad(V)=0.942473 grad(U)=0.009967\n",
      "downhill: Adam 47 loss=6.391638 error=6.121466 grad(V)=0.933482 grad(U)=0.009881\n",
      "downhill: Adam 48 loss=6.357779 error=6.087935 grad(V)=0.924659 grad(U)=0.009796\n",
      "downhill: Adam 49 loss=6.324417 error=6.054896 grad(V)=0.915998 grad(U)=0.009713\n",
      "downhill: Adam 50 loss=6.291536 error=6.022335 grad(V)=0.907494 grad(U)=0.009631\n",
      "downhill: validation 5 loss=6.259123 error=5.990239 grad(V)=0.899142 grad(U)=0.009551 *\n",
      "downhill: Adam 51 loss=6.259123 error=5.990239 grad(V)=0.899142 grad(U)=0.009551\n",
      "downhill: Adam 52 loss=6.227165 error=5.958595 grad(V)=0.890939 grad(U)=0.009473\n",
      "downhill: Adam 53 loss=6.195650 error=5.927390 grad(V)=0.882878 grad(U)=0.009395\n",
      "downhill: Adam 54 loss=6.164565 error=5.896612 grad(V)=0.874957 grad(U)=0.009319\n",
      "downhill: Adam 55 loss=6.133899 error=5.866250 grad(V)=0.867171 grad(U)=0.009244\n",
      "downhill: Adam 56 loss=6.103641 error=5.836293 grad(V)=0.859515 grad(U)=0.009171\n",
      "downhill: Adam 57 loss=6.073779 error=5.806729 grad(V)=0.851987 grad(U)=0.009098\n",
      "downhill: Adam 58 loss=6.044303 error=5.777548 grad(V)=0.844582 grad(U)=0.009027\n",
      "downhill: Adam 59 loss=6.015202 error=5.748740 grad(V)=0.837298 grad(U)=0.008957\n",
      "downhill: Adam 60 loss=5.986467 error=5.720295 grad(V)=0.830129 grad(U)=0.008888\n",
      "downhill: validation 6 loss=5.958089 error=5.692203 grad(V)=0.823074 grad(U)=0.008820 *\n",
      "downhill: Adam 61 loss=5.958089 error=5.692203 grad(V)=0.823074 grad(U)=0.008820\n",
      "downhill: Adam 62 loss=5.930057 error=5.664456 grad(V)=0.816129 grad(U)=0.008753\n",
      "downhill: Adam 63 loss=5.902363 error=5.637045 grad(V)=0.809291 grad(U)=0.008688\n",
      "downhill: Adam 64 loss=5.874999 error=5.609960 grad(V)=0.802557 grad(U)=0.008623\n",
      "downhill: Adam 65 loss=5.847956 error=5.583195 grad(V)=0.795924 grad(U)=0.008559\n",
      "downhill: Adam 66 loss=5.821227 error=5.556740 grad(V)=0.789390 grad(U)=0.008496\n",
      "downhill: Adam 67 loss=5.794803 error=5.530589 grad(V)=0.782951 grad(U)=0.008434\n",
      "downhill: Adam 68 loss=5.768677 error=5.504733 grad(V)=0.776606 grad(U)=0.008373\n",
      "downhill: Adam 69 loss=5.742842 error=5.479166 grad(V)=0.770353 grad(U)=0.008312\n",
      "downhill: Adam 70 loss=5.717290 error=5.453881 grad(V)=0.764187 grad(U)=0.008253\n",
      "downhill: validation 7 loss=5.692016 error=5.428871 grad(V)=0.758109 grad(U)=0.008194 *\n",
      "downhill: Adam 71 loss=5.692016 error=5.428871 grad(V)=0.758109 grad(U)=0.008194\n",
      "downhill: Adam 72 loss=5.667013 error=5.404129 grad(V)=0.752114 grad(U)=0.008136\n",
      "downhill: Adam 73 loss=5.642275 error=5.379650 grad(V)=0.746202 grad(U)=0.008079\n",
      "downhill: Adam 74 loss=5.617795 error=5.355428 grad(V)=0.740370 grad(U)=0.008023\n",
      "downhill: Adam 75 loss=5.593567 error=5.331456 grad(V)=0.734616 grad(U)=0.007967\n",
      "downhill: Adam 76 loss=5.569587 error=5.307728 grad(V)=0.728939 grad(U)=0.007912\n",
      "downhill: Adam 77 loss=5.545847 error=5.284241 grad(V)=0.723336 grad(U)=0.007858\n",
      "downhill: Adam 78 loss=5.522344 error=5.260987 grad(V)=0.717806 grad(U)=0.007804\n",
      "downhill: Adam 79 loss=5.499072 error=5.237963 grad(V)=0.712346 grad(U)=0.007751\n",
      "downhill: Adam 80 loss=5.476026 error=5.215162 grad(V)=0.706957 grad(U)=0.007699\n",
      "downhill: validation 8 loss=5.453201 error=5.192582 grad(V)=0.701635 grad(U)=0.007647 *\n",
      "downhill: Adam 81 loss=5.453201 error=5.192582 grad(V)=0.701635 grad(U)=0.007647\n",
      "downhill: Adam 82 loss=5.430593 error=5.170216 grad(V)=0.696379 grad(U)=0.007596\n",
      "downhill: Adam 83 loss=5.408196 error=5.148060 grad(V)=0.691189 grad(U)=0.007546\n",
      "downhill: Adam 84 loss=5.386007 error=5.126110 grad(V)=0.686061 grad(U)=0.007496\n",
      "downhill: Adam 85 loss=5.364022 error=5.104362 grad(V)=0.680996 grad(U)=0.007447\n",
      "downhill: Adam 86 loss=5.342235 error=5.082812 grad(V)=0.675992 grad(U)=0.007398\n",
      "downhill: Adam 87 loss=5.320645 error=5.061455 grad(V)=0.671047 grad(U)=0.007350\n",
      "downhill: Adam 88 loss=5.299245 error=5.040289 grad(V)=0.666160 grad(U)=0.007302\n",
      "downhill: Adam 89 loss=5.278034 error=5.019308 grad(V)=0.661329 grad(U)=0.007255\n",
      "downhill: Adam 90 loss=5.257006 error=4.998511 grad(V)=0.656555 grad(U)=0.007209\n",
      "downhill: validation 9 loss=5.236159 error=4.977892 grad(V)=0.651836 grad(U)=0.007163 *\n",
      "downhill: Adam 91 loss=5.236159 error=4.977892 grad(V)=0.651836 grad(U)=0.007163\n",
      "downhill: Adam 92 loss=5.215489 error=4.957449 grad(V)=0.647169 grad(U)=0.007117\n",
      "downhill: Adam 93 loss=5.194993 error=4.937178 grad(V)=0.642556 grad(U)=0.007072\n",
      "downhill: Adam 94 loss=5.174667 error=4.917077 grad(V)=0.637993 grad(U)=0.007028\n",
      "downhill: Adam 95 loss=5.154509 error=4.897141 grad(V)=0.633482 grad(U)=0.006984\n",
      "downhill: Adam 96 loss=5.134516 error=4.877369 grad(V)=0.629019 grad(U)=0.006940\n",
      "downhill: Adam 97 loss=5.114683 error=4.857757 grad(V)=0.624605 grad(U)=0.006897\n",
      "downhill: Adam 98 loss=5.095009 error=4.838302 grad(V)=0.620238 grad(U)=0.006854\n",
      "downhill: Adam 99 loss=5.075491 error=4.819001 grad(V)=0.615918 grad(U)=0.006812\n",
      "downhill: Adam 100 loss=5.056126 error=4.799853 grad(V)=0.611644 grad(U)=0.006770\n",
      "downhill: validation 10 loss=5.036911 error=4.780853 grad(V)=0.607415 grad(U)=0.006729 *\n",
      "downhill: Adam 101 loss=5.036911 error=4.780853 grad(V)=0.607415 grad(U)=0.006729\n",
      "downhill: Adam 102 loss=5.017844 error=4.762000 grad(V)=0.603230 grad(U)=0.006688\n",
      "downhill: Adam 103 loss=4.998923 error=4.743292 grad(V)=0.599088 grad(U)=0.006647\n",
      "downhill: Adam 104 loss=4.980144 error=4.724725 grad(V)=0.594988 grad(U)=0.006607\n",
      "downhill: Adam 105 loss=4.961506 error=4.706297 grad(V)=0.590930 grad(U)=0.006567\n",
      "downhill: Adam 106 loss=4.943006 error=4.688006 grad(V)=0.586914 grad(U)=0.006528\n",
      "downhill: Adam 107 loss=4.924642 error=4.669850 grad(V)=0.582937 grad(U)=0.006489\n",
      "downhill: Adam 108 loss=4.906412 error=4.651827 grad(V)=0.579000 grad(U)=0.006450\n",
      "downhill: Adam 109 loss=4.888314 error=4.633935 grad(V)=0.575102 grad(U)=0.006412\n",
      "downhill: Adam 110 loss=4.870345 error=4.616171 grad(V)=0.571243 grad(U)=0.006374\n",
      "downhill: validation 11 loss=4.852503 error=4.598533 grad(V)=0.567421 grad(U)=0.006336 *\n",
      "downhill: Adam 111 loss=4.852503 error=4.598533 grad(V)=0.567421 grad(U)=0.006336\n",
      "downhill: Adam 112 loss=4.834787 error=4.581020 grad(V)=0.563636 grad(U)=0.006299\n",
      "downhill: Adam 113 loss=4.817195 error=4.563629 grad(V)=0.559887 grad(U)=0.006262\n",
      "downhill: Adam 114 loss=4.799724 error=4.546359 grad(V)=0.556174 grad(U)=0.006226\n",
      "downhill: Adam 115 loss=4.782373 error=4.529208 grad(V)=0.552496 grad(U)=0.006189\n",
      "downhill: Adam 116 loss=4.765140 error=4.512174 grad(V)=0.548853 grad(U)=0.006153\n",
      "downhill: Adam 117 loss=4.748023 error=4.495256 grad(V)=0.545243 grad(U)=0.006118\n",
      "downhill: Adam 118 loss=4.731021 error=4.478451 grad(V)=0.541668 grad(U)=0.006083\n",
      "downhill: Adam 119 loss=4.714132 error=4.461758 grad(V)=0.538125 grad(U)=0.006048\n",
      "downhill: Adam 120 loss=4.697355 error=4.445175 grad(V)=0.534615 grad(U)=0.006013\n",
      "downhill: validation 12 loss=4.680687 error=4.428701 grad(V)=0.531136 grad(U)=0.005979 *\n",
      "downhill: Adam 121 loss=4.680687 error=4.428701 grad(V)=0.531136 grad(U)=0.005979\n",
      "downhill: Adam 122 loss=4.664127 error=4.412335 grad(V)=0.527690 grad(U)=0.005945\n",
      "downhill: Adam 123 loss=4.647674 error=4.396074 grad(V)=0.524274 grad(U)=0.005911\n",
      "downhill: Adam 124 loss=4.631326 error=4.379918 grad(V)=0.520888 grad(U)=0.005877\n",
      "downhill: Adam 125 loss=4.615081 error=4.363864 grad(V)=0.517533 grad(U)=0.005844\n",
      "downhill: Adam 126 loss=4.598939 error=4.347912 grad(V)=0.514208 grad(U)=0.005811\n",
      "downhill: Adam 127 loss=4.582897 error=4.332059 grad(V)=0.510911 grad(U)=0.005779\n",
      "downhill: Adam 128 loss=4.566956 error=4.316306 grad(V)=0.507643 grad(U)=0.005746\n",
      "downhill: Adam 129 loss=4.551112 error=4.300650 grad(V)=0.504404 grad(U)=0.005714\n",
      "downhill: Adam 130 loss=4.535365 error=4.285090 grad(V)=0.501193 grad(U)=0.005683\n",
      "downhill: validation 13 loss=4.519714 error=4.269624 grad(V)=0.498009 grad(U)=0.005651 *\n",
      "downhill: Adam 131 loss=4.519714 error=4.269624 grad(V)=0.498009 grad(U)=0.005651\n",
      "downhill: Adam 132 loss=4.504157 error=4.254253 grad(V)=0.494852 grad(U)=0.005620\n",
      "downhill: Adam 133 loss=4.488693 error=4.238973 grad(V)=0.491722 grad(U)=0.005589\n",
      "downhill: Adam 134 loss=4.473321 error=4.223785 grad(V)=0.488618 grad(U)=0.005558\n",
      "downhill: Adam 135 loss=4.458040 error=4.208687 grad(V)=0.485541 grad(U)=0.005527\n",
      "downhill: Adam 136 loss=4.442849 error=4.193678 grad(V)=0.482489 grad(U)=0.005497\n",
      "downhill: Adam 137 loss=4.427746 error=4.178756 grad(V)=0.479462 grad(U)=0.005467\n",
      "downhill: Adam 138 loss=4.412730 error=4.163921 grad(V)=0.476460 grad(U)=0.005437\n",
      "downhill: Adam 139 loss=4.397801 error=4.149172 grad(V)=0.473483 grad(U)=0.005408\n",
      "downhill: Adam 140 loss=4.382956 error=4.134507 grad(V)=0.470530 grad(U)=0.005378\n",
      "downhill: validation 14 loss=4.368197 error=4.119926 grad(V)=0.467601 grad(U)=0.005349 *\n",
      "downhill: Adam 141 loss=4.368197 error=4.119926 grad(V)=0.467601 grad(U)=0.005349\n",
      "downhill: Adam 142 loss=4.353520 error=4.105427 grad(V)=0.464696 grad(U)=0.005320\n",
      "downhill: Adam 143 loss=4.338925 error=4.091010 grad(V)=0.461814 grad(U)=0.005291\n",
      "downhill: Adam 144 loss=4.324412 error=4.076674 grad(V)=0.458956 grad(U)=0.005263\n",
      "downhill: Adam 145 loss=4.309979 error=4.062417 grad(V)=0.456119 grad(U)=0.005235\n",
      "downhill: Adam 146 loss=4.295626 error=4.048239 grad(V)=0.453306 grad(U)=0.005207\n",
      "downhill: Adam 147 loss=4.281351 error=4.034138 grad(V)=0.450514 grad(U)=0.005179\n",
      "downhill: Adam 148 loss=4.267153 error=4.020115 grad(V)=0.447745 grad(U)=0.005151\n",
      "downhill: Adam 149 loss=4.253032 error=4.006167 grad(V)=0.444997 grad(U)=0.005124\n",
      "downhill: Adam 150 loss=4.238987 error=3.992295 grad(V)=0.442270 grad(U)=0.005097\n",
      "downhill: validation 15 loss=4.225017 error=3.978497 grad(V)=0.439564 grad(U)=0.005070 *\n",
      "downhill: Adam 151 loss=4.225017 error=3.978497 grad(V)=0.439564 grad(U)=0.005070\n",
      "downhill: Adam 152 loss=4.211121 error=3.964773 grad(V)=0.436880 grad(U)=0.005043\n",
      "downhill: Adam 153 loss=4.197298 error=3.951121 grad(V)=0.434215 grad(U)=0.005016\n",
      "downhill: Adam 154 loss=4.183548 error=3.937541 grad(V)=0.431571 grad(U)=0.004990\n",
      "downhill: Adam 155 loss=4.169869 error=3.924032 grad(V)=0.428948 grad(U)=0.004964\n",
      "downhill: Adam 156 loss=4.156261 error=3.910593 grad(V)=0.426344 grad(U)=0.004938\n",
      "downhill: Adam 157 loss=4.142723 error=3.897224 grad(V)=0.423759 grad(U)=0.004912\n",
      "downhill: Adam 158 loss=4.129255 error=3.883924 grad(V)=0.421194 grad(U)=0.004886\n",
      "downhill: Adam 159 loss=4.115856 error=3.870692 grad(V)=0.418648 grad(U)=0.004860\n",
      "downhill: Adam 160 loss=4.102525 error=3.857528 grad(V)=0.416121 grad(U)=0.004835\n",
      "downhill: validation 16 loss=4.089260 error=3.844430 grad(V)=0.413613 grad(U)=0.004810 *\n",
      "downhill: Adam 161 loss=4.089260 error=3.844430 grad(V)=0.413613 grad(U)=0.004810\n",
      "downhill: Adam 162 loss=4.076063 error=3.831398 grad(V)=0.411123 grad(U)=0.004785\n",
      "downhill: Adam 163 loss=4.062932 error=3.818431 grad(V)=0.408651 grad(U)=0.004760\n",
      "downhill: Adam 164 loss=4.049865 error=3.805530 grad(V)=0.406198 grad(U)=0.004735\n",
      "downhill: Adam 165 loss=4.036864 error=3.792692 grad(V)=0.403762 grad(U)=0.004711\n",
      "downhill: Adam 166 loss=4.023926 error=3.779917 grad(V)=0.401344 grad(U)=0.004687\n",
      "downhill: Adam 167 loss=4.011052 error=3.767205 grad(V)=0.398944 grad(U)=0.004663\n",
      "downhill: Adam 168 loss=3.998240 error=3.754556 grad(V)=0.396560 grad(U)=0.004639\n",
      "downhill: Adam 169 loss=3.985491 error=3.741968 grad(V)=0.394194 grad(U)=0.004615\n",
      "downhill: Adam 170 loss=3.972802 error=3.729440 grad(V)=0.391845 grad(U)=0.004591\n",
      "downhill: validation 17 loss=3.960175 error=3.716974 grad(V)=0.389512 grad(U)=0.004568 *\n",
      "downhill: Adam 171 loss=3.960175 error=3.716974 grad(V)=0.389512 grad(U)=0.004568\n",
      "downhill: Adam 172 loss=3.947608 error=3.704566 grad(V)=0.387196 grad(U)=0.004544\n",
      "downhill: Adam 173 loss=3.935101 error=3.692218 grad(V)=0.384897 grad(U)=0.004521\n",
      "downhill: Adam 174 loss=3.922653 error=3.679929 grad(V)=0.382613 grad(U)=0.004498\n",
      "downhill: Adam 175 loss=3.910263 error=3.667698 grad(V)=0.380345 grad(U)=0.004475\n",
      "downhill: Adam 176 loss=3.897932 error=3.655524 grad(V)=0.378094 grad(U)=0.004453\n",
      "downhill: Adam 177 loss=3.885657 error=3.643407 grad(V)=0.375858 grad(U)=0.004430\n",
      "downhill: Adam 178 loss=3.873440 error=3.631346 grad(V)=0.373637 grad(U)=0.004408\n",
      "downhill: Adam 179 loss=3.861279 error=3.619342 grad(V)=0.371432 grad(U)=0.004385\n",
      "downhill: Adam 180 loss=3.849174 error=3.607393 grad(V)=0.369242 grad(U)=0.004363\n",
      "downhill: validation 18 loss=3.837125 error=3.595498 grad(V)=0.367067 grad(U)=0.004341 *\n",
      "downhill: Adam 181 loss=3.837125 error=3.595498 grad(V)=0.367067 grad(U)=0.004341\n",
      "downhill: Adam 182 loss=3.825130 error=3.583659 grad(V)=0.364907 grad(U)=0.004319\n",
      "downhill: Adam 183 loss=3.813190 error=3.571873 grad(V)=0.362761 grad(U)=0.004298\n",
      "downhill: Adam 184 loss=3.801303 error=3.560140 grad(V)=0.360630 grad(U)=0.004276\n",
      "downhill: Adam 185 loss=3.789470 error=3.548460 grad(V)=0.358514 grad(U)=0.004255\n",
      "downhill: Adam 186 loss=3.777690 error=3.536833 grad(V)=0.356412 grad(U)=0.004233\n",
      "downhill: Adam 187 loss=3.765963 error=3.525258 grad(V)=0.354323 grad(U)=0.004212\n",
      "downhill: Adam 188 loss=3.754287 error=3.513735 grad(V)=0.352249 grad(U)=0.004191\n",
      "downhill: Adam 189 loss=3.742663 error=3.502262 grad(V)=0.350189 grad(U)=0.004170\n",
      "downhill: Adam 190 loss=3.731091 error=3.490841 grad(V)=0.348143 grad(U)=0.004150\n",
      "downhill: validation 19 loss=3.719569 error=3.479469 grad(V)=0.346110 grad(U)=0.004129 *\n",
      "downhill: Adam 191 loss=3.719569 error=3.479469 grad(V)=0.346110 grad(U)=0.004129\n",
      "downhill: Adam 192 loss=3.708097 error=3.468148 grad(V)=0.344091 grad(U)=0.004109\n",
      "downhill: Adam 193 loss=3.696675 error=3.456876 grad(V)=0.342085 grad(U)=0.004088\n",
      "downhill: Adam 194 loss=3.685302 error=3.445653 grad(V)=0.340092 grad(U)=0.004068\n",
      "downhill: Adam 195 loss=3.673979 error=3.434478 grad(V)=0.338112 grad(U)=0.004048\n",
      "downhill: Adam 196 loss=3.662705 error=3.423352 grad(V)=0.336145 grad(U)=0.004028\n",
      "downhill: Adam 197 loss=3.651478 error=3.412274 grad(V)=0.334191 grad(U)=0.004008\n",
      "downhill: Adam 198 loss=3.640300 error=3.401243 grad(V)=0.332250 grad(U)=0.003988\n",
      "downhill: Adam 199 loss=3.629169 error=3.390259 grad(V)=0.330321 grad(U)=0.003968\n",
      "downhill: Adam 200 loss=3.618085 error=3.379321 grad(V)=0.328405 grad(U)=0.003949\n",
      "downhill: validation 20 loss=3.607048 error=3.368430 grad(V)=0.326501 grad(U)=0.003929 *\n",
      "downhill: Adam 201 loss=3.607048 error=3.368430 grad(V)=0.326501 grad(U)=0.003929\n",
      "downhill: Adam 202 loss=3.596058 error=3.357585 grad(V)=0.324610 grad(U)=0.003910\n",
      "downhill: Adam 203 loss=3.585113 error=3.346786 grad(V)=0.322730 grad(U)=0.003891\n",
      "downhill: Adam 204 loss=3.574214 error=3.336032 grad(V)=0.320863 grad(U)=0.003872\n",
      "downhill: Adam 205 loss=3.563361 error=3.325322 grad(V)=0.319008 grad(U)=0.003853\n",
      "downhill: Adam 206 loss=3.552552 error=3.314657 grad(V)=0.317164 grad(U)=0.003834\n",
      "downhill: Adam 207 loss=3.541788 error=3.304037 grad(V)=0.315332 grad(U)=0.003815\n",
      "downhill: Adam 208 loss=3.531068 error=3.293460 grad(V)=0.313512 grad(U)=0.003797\n",
      "downhill: Adam 209 loss=3.520392 error=3.282927 grad(V)=0.311703 grad(U)=0.003778\n",
      "downhill: Adam 210 loss=3.509759 error=3.272436 grad(V)=0.309906 grad(U)=0.003760\n",
      "downhill: validation 21 loss=3.499170 error=3.261989 grad(V)=0.308120 grad(U)=0.003741 *\n",
      "downhill: Adam 211 loss=3.499170 error=3.261989 grad(V)=0.308120 grad(U)=0.003741\n",
      "downhill: Adam 212 loss=3.488623 error=3.251584 grad(V)=0.306345 grad(U)=0.003723\n",
      "downhill: Adam 213 loss=3.478120 error=3.241222 grad(V)=0.304581 grad(U)=0.003705\n",
      "downhill: Adam 214 loss=3.467658 error=3.230901 grad(V)=0.302828 grad(U)=0.003687\n",
      "downhill: Adam 215 loss=3.457238 error=3.220622 grad(V)=0.301086 grad(U)=0.003669\n",
      "downhill: Adam 216 loss=3.446861 error=3.210385 grad(V)=0.299355 grad(U)=0.003651\n",
      "downhill: Adam 217 loss=3.436524 error=3.200188 grad(V)=0.297635 grad(U)=0.003634\n",
      "downhill: Adam 218 loss=3.426229 error=3.190032 grad(V)=0.295925 grad(U)=0.003616\n",
      "downhill: Adam 219 loss=3.415975 error=3.179916 grad(V)=0.294226 grad(U)=0.003599\n",
      "downhill: Adam 220 loss=3.405760 error=3.169841 grad(V)=0.292537 grad(U)=0.003581\n",
      "downhill: validation 22 loss=3.395587 error=3.159805 grad(V)=0.290859 grad(U)=0.003564 *\n",
      "downhill: Adam 221 loss=3.395587 error=3.159805 grad(V)=0.290859 grad(U)=0.003564\n",
      "downhill: Adam 222 loss=3.385453 error=3.149809 grad(V)=0.289191 grad(U)=0.003547\n",
      "downhill: Adam 223 loss=3.375359 error=3.139853 grad(V)=0.287533 grad(U)=0.003530\n",
      "downhill: Adam 224 loss=3.365304 error=3.129935 grad(V)=0.285885 grad(U)=0.003513\n",
      "downhill: Adam 225 loss=3.355289 error=3.120056 grad(V)=0.284248 grad(U)=0.003496\n",
      "downhill: Adam 226 loss=3.345312 error=3.110216 grad(V)=0.282620 grad(U)=0.003479\n",
      "downhill: Adam 227 loss=3.335374 error=3.100414 grad(V)=0.281002 grad(U)=0.003462\n",
      "downhill: Adam 228 loss=3.325474 error=3.090649 grad(V)=0.279394 grad(U)=0.003446\n",
      "downhill: Adam 229 loss=3.315613 error=3.080923 grad(V)=0.277796 grad(U)=0.003429\n",
      "downhill: Adam 230 loss=3.305789 error=3.071234 grad(V)=0.276207 grad(U)=0.003413\n",
      "downhill: validation 23 loss=3.296003 error=3.061582 grad(V)=0.274628 grad(U)=0.003396 *\n",
      "downhill: Adam 231 loss=3.296003 error=3.061582 grad(V)=0.274628 grad(U)=0.003396\n",
      "downhill: Adam 232 loss=3.286254 error=3.051967 grad(V)=0.273059 grad(U)=0.003380\n",
      "downhill: Adam 233 loss=3.276543 error=3.042389 grad(V)=0.271499 grad(U)=0.003364\n",
      "downhill: Adam 234 loss=3.266868 error=3.032848 grad(V)=0.269948 grad(U)=0.003348\n",
      "downhill: Adam 235 loss=3.257230 error=3.023343 grad(V)=0.268406 grad(U)=0.003332\n",
      "downhill: Adam 236 loss=3.247628 error=3.013874 grad(V)=0.266874 grad(U)=0.003316\n",
      "downhill: Adam 237 loss=3.238063 error=3.004440 grad(V)=0.265351 grad(U)=0.003300\n",
      "downhill: Adam 238 loss=3.228533 error=2.995042 grad(V)=0.263836 grad(U)=0.003284\n",
      "downhill: Adam 239 loss=3.219039 error=2.985680 grad(V)=0.262331 grad(U)=0.003268\n",
      "downhill: Adam 240 loss=3.209581 error=2.976353 grad(V)=0.260835 grad(U)=0.003253\n",
      "downhill: validation 24 loss=3.200158 error=2.967060 grad(V)=0.259347 grad(U)=0.003237 *\n",
      "downhill: Adam 241 loss=3.200158 error=2.967060 grad(V)=0.259347 grad(U)=0.003237\n",
      "downhill: Adam 242 loss=3.190770 error=2.957803 grad(V)=0.257869 grad(U)=0.003222\n",
      "downhill: Adam 243 loss=3.181417 error=2.948580 grad(V)=0.256399 grad(U)=0.003207\n",
      "downhill: Adam 244 loss=3.172098 error=2.939391 grad(V)=0.254937 grad(U)=0.003191\n",
      "downhill: Adam 245 loss=3.162814 error=2.930236 grad(V)=0.253484 grad(U)=0.003176\n",
      "downhill: Adam 246 loss=3.153565 error=2.921115 grad(V)=0.252040 grad(U)=0.003161\n",
      "downhill: Adam 247 loss=3.144349 error=2.912028 grad(V)=0.250604 grad(U)=0.003146\n",
      "downhill: Adam 248 loss=3.135167 error=2.902974 grad(V)=0.249177 grad(U)=0.003131\n",
      "downhill: Adam 249 loss=3.126019 error=2.893953 grad(V)=0.247758 grad(U)=0.003116\n",
      "downhill: Adam 250 loss=3.116904 error=2.884966 grad(V)=0.246347 grad(U)=0.003101\n",
      "downhill: validation 25 loss=3.107823 error=2.876011 grad(V)=0.244944 grad(U)=0.003087 *\n",
      "downhill: Adam 251 loss=3.107823 error=2.876011 grad(V)=0.244944 grad(U)=0.003087\n",
      "downhill: Adam 252 loss=3.098774 error=2.867089 grad(V)=0.243550 grad(U)=0.003072\n",
      "downhill: Adam 253 loss=3.089759 error=2.858200 grad(V)=0.242163 grad(U)=0.003057\n",
      "downhill: Adam 254 loss=3.080776 error=2.849343 grad(V)=0.240785 grad(U)=0.003043\n",
      "downhill: Adam 255 loss=3.071825 error=2.840518 grad(V)=0.239414 grad(U)=0.003029\n",
      "downhill: Adam 256 loss=3.062907 error=2.831725 grad(V)=0.238052 grad(U)=0.003014\n",
      "downhill: Adam 257 loss=3.054021 error=2.822963 grad(V)=0.236697 grad(U)=0.003000\n",
      "downhill: Adam 258 loss=3.045167 error=2.814233 grad(V)=0.235351 grad(U)=0.002986\n",
      "downhill: Adam 259 loss=3.036344 error=2.805535 grad(V)=0.234011 grad(U)=0.002972\n",
      "downhill: Adam 260 loss=3.027553 error=2.796868 grad(V)=0.232680 grad(U)=0.002958\n",
      "downhill: validation 26 loss=3.018793 error=2.788232 grad(V)=0.231356 grad(U)=0.002944 *\n",
      "downhill: Adam 261 loss=3.018793 error=2.788232 grad(V)=0.231356 grad(U)=0.002944\n",
      "downhill: Adam 262 loss=3.010064 error=2.779626 grad(V)=0.230040 grad(U)=0.002930\n",
      "downhill: Adam 263 loss=3.001366 error=2.771052 grad(V)=0.228731 grad(U)=0.002916\n",
      "downhill: Adam 264 loss=2.992700 error=2.762508 grad(V)=0.227430 grad(U)=0.002902\n",
      "downhill: Adam 265 loss=2.984063 error=2.753994 grad(V)=0.226136 grad(U)=0.002888\n",
      "downhill: Adam 266 loss=2.975458 error=2.745510 grad(V)=0.224850 grad(U)=0.002875\n",
      "downhill: Adam 267 loss=2.966882 error=2.737057 grad(V)=0.223571 grad(U)=0.002861\n",
      "downhill: Adam 268 loss=2.958337 error=2.728633 grad(V)=0.222299 grad(U)=0.002848\n",
      "downhill: Adam 269 loss=2.949822 error=2.720239 grad(V)=0.221034 grad(U)=0.002834\n",
      "downhill: Adam 270 loss=2.941337 error=2.711875 grad(V)=0.219777 grad(U)=0.002821\n",
      "downhill: validation 27 loss=2.932881 error=2.703540 grad(V)=0.218526 grad(U)=0.002808 *\n",
      "downhill: Adam 271 loss=2.932881 error=2.703540 grad(V)=0.218526 grad(U)=0.002808\n",
      "downhill: Adam 272 loss=2.924455 error=2.695234 grad(V)=0.217283 grad(U)=0.002795\n",
      "downhill: Adam 273 loss=2.916059 error=2.686957 grad(V)=0.216047 grad(U)=0.002781\n",
      "downhill: Adam 274 loss=2.907691 error=2.678709 grad(V)=0.214817 grad(U)=0.002768\n",
      "downhill: Adam 275 loss=2.899353 error=2.670490 grad(V)=0.213595 grad(U)=0.002755\n",
      "downhill: Adam 276 loss=2.891043 error=2.662300 grad(V)=0.212379 grad(U)=0.002742\n",
      "downhill: Adam 277 loss=2.882763 error=2.654138 grad(V)=0.211171 grad(U)=0.002729\n",
      "downhill: Adam 278 loss=2.874511 error=2.646005 grad(V)=0.209969 grad(U)=0.002717\n",
      "downhill: Adam 279 loss=2.866288 error=2.637899 grad(V)=0.208774 grad(U)=0.002704\n",
      "downhill: Adam 280 loss=2.858093 error=2.629822 grad(V)=0.207585 grad(U)=0.002691\n",
      "downhill: validation 28 loss=2.849926 error=2.621773 grad(V)=0.206404 grad(U)=0.002678 *\n",
      "downhill: Adam 281 loss=2.849926 error=2.621773 grad(V)=0.206404 grad(U)=0.002678\n",
      "downhill: Adam 282 loss=2.841787 error=2.613751 grad(V)=0.205228 grad(U)=0.002666\n",
      "downhill: Adam 283 loss=2.833677 error=2.605757 grad(V)=0.204060 grad(U)=0.002653\n",
      "downhill: Adam 284 loss=2.825594 error=2.597791 grad(V)=0.202898 grad(U)=0.002641\n",
      "downhill: Adam 285 loss=2.817538 error=2.589852 grad(V)=0.201742 grad(U)=0.002629\n",
      "downhill: Adam 286 loss=2.809510 error=2.581940 grad(V)=0.200593 grad(U)=0.002616\n",
      "downhill: Adam 287 loss=2.801510 error=2.574056 grad(V)=0.199450 grad(U)=0.002604\n",
      "downhill: Adam 288 loss=2.793537 error=2.566198 grad(V)=0.198313 grad(U)=0.002592\n",
      "downhill: Adam 289 loss=2.785591 error=2.558367 grad(V)=0.197183 grad(U)=0.002579\n",
      "downhill: Adam 290 loss=2.777672 error=2.550563 grad(V)=0.196059 grad(U)=0.002567\n",
      "downhill: validation 29 loss=2.769780 error=2.542786 grad(V)=0.194942 grad(U)=0.002555 *\n",
      "downhill: Adam 291 loss=2.769780 error=2.542786 grad(V)=0.194942 grad(U)=0.002555\n",
      "downhill: Adam 292 loss=2.761915 error=2.535035 grad(V)=0.193830 grad(U)=0.002543\n",
      "downhill: Adam 293 loss=2.754076 error=2.527310 grad(V)=0.192725 grad(U)=0.002531\n",
      "downhill: Adam 294 loss=2.746264 error=2.519612 grad(V)=0.191626 grad(U)=0.002519\n",
      "downhill: Adam 295 loss=2.738479 error=2.511940 grad(V)=0.190533 grad(U)=0.002508\n",
      "downhill: Adam 296 loss=2.730720 error=2.504294 grad(V)=0.189446 grad(U)=0.002496\n",
      "downhill: Adam 297 loss=2.722986 error=2.496673 grad(V)=0.188365 grad(U)=0.002484\n",
      "downhill: Adam 298 loss=2.715279 error=2.489079 grad(V)=0.187289 grad(U)=0.002473\n",
      "downhill: Adam 299 loss=2.707598 error=2.481510 grad(V)=0.186220 grad(U)=0.002461\n",
      "downhill: Adam 300 loss=2.699943 error=2.473967 grad(V)=0.185157 grad(U)=0.002449\n",
      "downhill: validation 30 loss=2.692313 error=2.466449 grad(V)=0.184100 grad(U)=0.002438 *\n",
      "downhill: Adam 301 loss=2.692313 error=2.466449 grad(V)=0.184100 grad(U)=0.002438\n",
      "downhill: Adam 302 loss=2.684709 error=2.458956 grad(V)=0.183048 grad(U)=0.002426\n",
      "downhill: Adam 303 loss=2.677131 error=2.451489 grad(V)=0.182002 grad(U)=0.002415\n",
      "downhill: Adam 304 loss=2.669578 error=2.444046 grad(V)=0.180962 grad(U)=0.002404\n",
      "downhill: Adam 305 loss=2.662050 error=2.436629 grad(V)=0.179927 grad(U)=0.002392\n",
      "downhill: Adam 306 loss=2.654547 error=2.429237 grad(V)=0.178899 grad(U)=0.002381\n",
      "downhill: Adam 307 loss=2.647069 error=2.421869 grad(V)=0.177876 grad(U)=0.002370\n",
      "downhill: Adam 308 loss=2.639617 error=2.414526 grad(V)=0.176858 grad(U)=0.002359\n",
      "downhill: Adam 309 loss=2.632189 error=2.407208 grad(V)=0.175846 grad(U)=0.002348\n",
      "downhill: Adam 310 loss=2.624786 error=2.399914 grad(V)=0.174840 grad(U)=0.002337\n",
      "downhill: validation 31 loss=2.617407 error=2.392644 grad(V)=0.173839 grad(U)=0.002326 *\n",
      "downhill: Adam 311 loss=2.617407 error=2.392644 grad(V)=0.173839 grad(U)=0.002326\n",
      "downhill: Adam 312 loss=2.610053 error=2.385399 grad(V)=0.172843 grad(U)=0.002315\n",
      "downhill: Adam 313 loss=2.602724 error=2.378177 grad(V)=0.171853 grad(U)=0.002304\n",
      "downhill: Adam 314 loss=2.595418 error=2.370980 grad(V)=0.170868 grad(U)=0.002293\n",
      "downhill: Adam 315 loss=2.588137 error=2.363807 grad(V)=0.169889 grad(U)=0.002283\n",
      "downhill: Adam 316 loss=2.580880 error=2.356657 grad(V)=0.168915 grad(U)=0.002272\n",
      "downhill: Adam 317 loss=2.573647 error=2.349532 grad(V)=0.167946 grad(U)=0.002261\n",
      "downhill: Adam 318 loss=2.566437 error=2.342430 grad(V)=0.166983 grad(U)=0.002251\n",
      "downhill: Adam 319 loss=2.559252 error=2.335351 grad(V)=0.166025 grad(U)=0.002240\n",
      "downhill: Adam 320 loss=2.552090 error=2.328296 grad(V)=0.165072 grad(U)=0.002230\n",
      "downhill: validation 32 loss=2.544952 error=2.321265 grad(V)=0.164124 grad(U)=0.002219 *\n",
      "downhill: Adam 321 loss=2.544952 error=2.321265 grad(V)=0.164124 grad(U)=0.002219\n",
      "downhill: Adam 322 loss=2.537837 error=2.314256 grad(V)=0.163181 grad(U)=0.002209\n",
      "downhill: Adam 323 loss=2.530746 error=2.307271 grad(V)=0.162244 grad(U)=0.002198\n",
      "downhill: Adam 324 loss=2.523678 error=2.300309 grad(V)=0.161311 grad(U)=0.002188\n",
      "downhill: Adam 325 loss=2.516634 error=2.293369 grad(V)=0.160384 grad(U)=0.002178\n",
      "downhill: Adam 326 loss=2.509612 error=2.286453 grad(V)=0.159462 grad(U)=0.002167\n",
      "downhill: Adam 327 loss=2.502614 error=2.279559 grad(V)=0.158544 grad(U)=0.002157\n",
      "downhill: Adam 328 loss=2.495639 error=2.272689 grad(V)=0.157632 grad(U)=0.002147\n",
      "downhill: Adam 329 loss=2.488687 error=2.265841 grad(V)=0.156724 grad(U)=0.002137\n",
      "downhill: Adam 330 loss=2.481757 error=2.259015 grad(V)=0.155822 grad(U)=0.002127\n",
      "downhill: validation 33 loss=2.474851 error=2.252212 grad(V)=0.154924 grad(U)=0.002117 *\n",
      "downhill: Adam 331 loss=2.474851 error=2.252212 grad(V)=0.154924 grad(U)=0.002117\n",
      "downhill: Adam 332 loss=2.467967 error=2.245431 grad(V)=0.154031 grad(U)=0.002107\n",
      "downhill: Adam 333 loss=2.461105 error=2.238673 grad(V)=0.153143 grad(U)=0.002097\n",
      "downhill: Adam 334 loss=2.454266 error=2.231937 grad(V)=0.152260 grad(U)=0.002087\n",
      "downhill: Adam 335 loss=2.447450 error=2.225223 grad(V)=0.151381 grad(U)=0.002078\n",
      "downhill: Adam 336 loss=2.440656 error=2.218531 grad(V)=0.150507 grad(U)=0.002068\n",
      "downhill: Adam 337 loss=2.433883 error=2.211861 grad(V)=0.149638 grad(U)=0.002058\n",
      "downhill: Adam 338 loss=2.427133 error=2.205212 grad(V)=0.148774 grad(U)=0.002048\n",
      "downhill: Adam 339 loss=2.420405 error=2.198586 grad(V)=0.147914 grad(U)=0.002039\n",
      "downhill: Adam 340 loss=2.413699 error=2.191981 grad(V)=0.147059 grad(U)=0.002029\n",
      "downhill: validation 34 loss=2.407015 error=2.185398 grad(V)=0.146208 grad(U)=0.002020 *\n",
      "downhill: Adam 341 loss=2.407015 error=2.185398 grad(V)=0.146208 grad(U)=0.002020\n",
      "downhill: Adam 342 loss=2.400353 error=2.178837 grad(V)=0.145363 grad(U)=0.002010\n",
      "downhill: Adam 343 loss=2.393712 error=2.172297 grad(V)=0.144521 grad(U)=0.002001\n",
      "downhill: Adam 344 loss=2.387093 error=2.165779 grad(V)=0.143684 grad(U)=0.001991\n",
      "downhill: Adam 345 loss=2.380496 error=2.159281 grad(V)=0.142852 grad(U)=0.001982\n",
      "downhill: Adam 346 loss=2.373920 error=2.152805 grad(V)=0.142024 grad(U)=0.001972\n",
      "downhill: Adam 347 loss=2.367366 error=2.146351 grad(V)=0.141200 grad(U)=0.001963\n",
      "downhill: Adam 348 loss=2.360833 error=2.139917 grad(V)=0.140381 grad(U)=0.001954\n",
      "downhill: Adam 349 loss=2.354321 error=2.133504 grad(V)=0.139567 grad(U)=0.001945\n",
      "downhill: Adam 350 loss=2.347831 error=2.127113 grad(V)=0.138756 grad(U)=0.001936\n",
      "downhill: validation 35 loss=2.341362 error=2.120742 grad(V)=0.137950 grad(U)=0.001926 *\n",
      "downhill: Adam 351 loss=2.341362 error=2.120742 grad(V)=0.137950 grad(U)=0.001926\n",
      "downhill: Adam 352 loss=2.334913 error=2.114392 grad(V)=0.137149 grad(U)=0.001917\n",
      "downhill: Adam 353 loss=2.328486 error=2.108063 grad(V)=0.136351 grad(U)=0.001908\n",
      "downhill: Adam 354 loss=2.322079 error=2.101754 grad(V)=0.135558 grad(U)=0.001899\n",
      "downhill: Adam 355 loss=2.315694 error=2.095466 grad(V)=0.134770 grad(U)=0.001890\n",
      "downhill: Adam 356 loss=2.309329 error=2.089199 grad(V)=0.133985 grad(U)=0.001881\n",
      "downhill: Adam 357 loss=2.302985 error=2.082952 grad(V)=0.133205 grad(U)=0.001872\n",
      "downhill: Adam 358 loss=2.296661 error=2.076725 grad(V)=0.132428 grad(U)=0.001864\n",
      "downhill: Adam 359 loss=2.290358 error=2.070519 grad(V)=0.131656 grad(U)=0.001855\n",
      "downhill: Adam 360 loss=2.284076 error=2.064333 grad(V)=0.130888 grad(U)=0.001846\n",
      "downhill: validation 36 loss=2.277814 error=2.058167 grad(V)=0.130124 grad(U)=0.001837 *\n",
      "downhill: Adam 361 loss=2.277814 error=2.058167 grad(V)=0.130124 grad(U)=0.001837\n",
      "downhill: Adam 362 loss=2.271572 error=2.052021 grad(V)=0.129365 grad(U)=0.001829\n",
      "downhill: Adam 363 loss=2.265350 error=2.045895 grad(V)=0.128609 grad(U)=0.001820\n",
      "downhill: Adam 364 loss=2.259149 error=2.039789 grad(V)=0.127857 grad(U)=0.001811\n",
      "downhill: Adam 365 loss=2.252967 error=2.033703 grad(V)=0.127109 grad(U)=0.001803\n",
      "downhill: Adam 366 loss=2.246806 error=2.027637 grad(V)=0.126366 grad(U)=0.001794\n",
      "downhill: Adam 367 loss=2.240665 error=2.021591 grad(V)=0.125626 grad(U)=0.001786\n",
      "downhill: Adam 368 loss=2.234543 error=2.015564 grad(V)=0.124890 grad(U)=0.001777\n",
      "downhill: Adam 369 loss=2.228442 error=2.009557 grad(V)=0.124158 grad(U)=0.001769\n",
      "downhill: Adam 370 loss=2.222360 error=2.003570 grad(V)=0.123430 grad(U)=0.001760\n",
      "downhill: validation 37 loss=2.216298 error=1.997602 grad(V)=0.122706 grad(U)=0.001752 *\n",
      "downhill: Adam 371 loss=2.216298 error=1.997602 grad(V)=0.122706 grad(U)=0.001752\n",
      "downhill: Adam 372 loss=2.210256 error=1.991654 grad(V)=0.121986 grad(U)=0.001744\n",
      "downhill: Adam 373 loss=2.204233 error=1.985725 grad(V)=0.121270 grad(U)=0.001736\n",
      "downhill: Adam 374 loss=2.198230 error=1.979815 grad(V)=0.120557 grad(U)=0.001727\n",
      "downhill: Adam 375 loss=2.192246 error=1.973924 grad(V)=0.119848 grad(U)=0.001719\n",
      "downhill: Adam 376 loss=2.186282 error=1.968053 grad(V)=0.119143 grad(U)=0.001711\n",
      "downhill: Adam 377 loss=2.180337 error=1.962201 grad(V)=0.118442 grad(U)=0.001703\n",
      "downhill: Adam 378 loss=2.174411 error=1.956368 grad(V)=0.117744 grad(U)=0.001695\n",
      "downhill: Adam 379 loss=2.168505 error=1.950554 grad(V)=0.117051 grad(U)=0.001687\n",
      "downhill: Adam 380 loss=2.162617 error=1.944759 grad(V)=0.116361 grad(U)=0.001679\n",
      "downhill: validation 38 loss=2.156749 error=1.938982 grad(V)=0.115674 grad(U)=0.001671 *\n",
      "downhill: Adam 381 loss=2.156749 error=1.938982 grad(V)=0.115674 grad(U)=0.001671\n",
      "downhill: Adam 382 loss=2.150900 error=1.933225 grad(V)=0.114991 grad(U)=0.001663\n",
      "downhill: Adam 383 loss=2.145070 error=1.927486 grad(V)=0.114312 grad(U)=0.001655\n",
      "downhill: Adam 384 loss=2.139259 error=1.921766 grad(V)=0.113637 grad(U)=0.001647\n",
      "downhill: Adam 385 loss=2.133466 error=1.916065 grad(V)=0.112965 grad(U)=0.001639\n",
      "downhill: Adam 386 loss=2.127693 error=1.910382 grad(V)=0.112296 grad(U)=0.001631\n",
      "downhill: Adam 387 loss=2.121938 error=1.904718 grad(V)=0.111631 grad(U)=0.001623\n",
      "downhill: Adam 388 loss=2.116202 error=1.899072 grad(V)=0.110970 grad(U)=0.001616\n",
      "downhill: Adam 389 loss=2.110485 error=1.893445 grad(V)=0.110312 grad(U)=0.001608\n",
      "downhill: Adam 390 loss=2.104786 error=1.887836 grad(V)=0.109658 grad(U)=0.001600\n",
      "downhill: validation 39 loss=2.099106 error=1.882246 grad(V)=0.109007 grad(U)=0.001593 *\n",
      "downhill: Adam 391 loss=2.099106 error=1.882246 grad(V)=0.109007 grad(U)=0.001593\n",
      "downhill: Adam 392 loss=2.093444 error=1.876674 grad(V)=0.108360 grad(U)=0.001585\n",
      "downhill: Adam 393 loss=2.087801 error=1.871120 grad(V)=0.107716 grad(U)=0.001577\n",
      "downhill: Adam 394 loss=2.082176 error=1.865584 grad(V)=0.107075 grad(U)=0.001570\n",
      "downhill: Adam 395 loss=2.076570 error=1.860066 grad(V)=0.106438 grad(U)=0.001562\n",
      "downhill: Adam 396 loss=2.070981 error=1.854566 grad(V)=0.105804 grad(U)=0.001555\n",
      "downhill: Adam 397 loss=2.065411 error=1.849085 grad(V)=0.105174 grad(U)=0.001548\n",
      "downhill: Adam 398 loss=2.059859 error=1.843621 grad(V)=0.104547 grad(U)=0.001540\n",
      "downhill: Adam 399 loss=2.054324 error=1.838175 grad(V)=0.103923 grad(U)=0.001533\n",
      "downhill: Adam 400 loss=2.048808 error=1.832747 grad(V)=0.103303 grad(U)=0.001525\n",
      "downhill: validation 40 loss=2.043310 error=1.827336 grad(V)=0.102686 grad(U)=0.001518 *\n",
      "downhill: Adam 401 loss=2.043310 error=1.827336 grad(V)=0.102686 grad(U)=0.001518\n",
      "downhill: Adam 402 loss=2.037829 error=1.821943 grad(V)=0.102072 grad(U)=0.001511\n",
      "downhill: Adam 403 loss=2.032367 error=1.816568 grad(V)=0.101461 grad(U)=0.001504\n",
      "downhill: Adam 404 loss=2.026922 error=1.811211 grad(V)=0.100854 grad(U)=0.001496\n",
      "downhill: Adam 405 loss=2.021495 error=1.805871 grad(V)=0.100250 grad(U)=0.001489\n",
      "downhill: Adam 406 loss=2.016086 error=1.800548 grad(V)=0.099649 grad(U)=0.001482\n",
      "downhill: Adam 407 loss=2.010694 error=1.795243 grad(V)=0.099051 grad(U)=0.001475\n",
      "downhill: Adam 408 loss=2.005320 error=1.789956 grad(V)=0.098457 grad(U)=0.001468\n",
      "downhill: Adam 409 loss=1.999964 error=1.784686 grad(V)=0.097865 grad(U)=0.001461\n",
      "downhill: Adam 410 loss=1.994625 error=1.779433 grad(V)=0.097277 grad(U)=0.001454\n",
      "downhill: validation 41 loss=1.989304 error=1.774197 grad(V)=0.096692 grad(U)=0.001447 *\n",
      "downhill: Adam 411 loss=1.989304 error=1.774197 grad(V)=0.096692 grad(U)=0.001447\n",
      "downhill: Adam 412 loss=1.983999 error=1.768979 grad(V)=0.096110 grad(U)=0.001440\n",
      "downhill: Adam 413 loss=1.978713 error=1.763777 grad(V)=0.095531 grad(U)=0.001433\n",
      "downhill: Adam 414 loss=1.973443 error=1.758593 grad(V)=0.094955 grad(U)=0.001426\n",
      "downhill: Adam 415 loss=1.968191 error=1.753426 grad(V)=0.094382 grad(U)=0.001419\n",
      "downhill: Adam 416 loss=1.962956 error=1.748276 grad(V)=0.093813 grad(U)=0.001412\n",
      "downhill: Adam 417 loss=1.957739 error=1.743143 grad(V)=0.093246 grad(U)=0.001405\n",
      "downhill: Adam 418 loss=1.952538 error=1.738026 grad(V)=0.092682 grad(U)=0.001399\n",
      "downhill: Adam 419 loss=1.947354 error=1.732927 grad(V)=0.092121 grad(U)=0.001392\n",
      "downhill: Adam 420 loss=1.942187 error=1.727844 grad(V)=0.091564 grad(U)=0.001385\n",
      "downhill: validation 42 loss=1.937038 error=1.722778 grad(V)=0.091009 grad(U)=0.001378 *\n",
      "downhill: Adam 421 loss=1.937038 error=1.722778 grad(V)=0.091009 grad(U)=0.001378\n",
      "downhill: Adam 422 loss=1.931905 error=1.717729 grad(V)=0.090457 grad(U)=0.001372\n",
      "downhill: Adam 423 loss=1.926789 error=1.712697 grad(V)=0.089908 grad(U)=0.001365\n",
      "downhill: Adam 424 loss=1.921690 error=1.707681 grad(V)=0.089362 grad(U)=0.001358\n",
      "downhill: Adam 425 loss=1.916608 error=1.702682 grad(V)=0.088819 grad(U)=0.001352\n",
      "downhill: Adam 426 loss=1.911543 error=1.697699 grad(V)=0.088279 grad(U)=0.001345\n",
      "downhill: Adam 427 loss=1.906494 error=1.692733 grad(V)=0.087741 grad(U)=0.001339\n",
      "downhill: Adam 428 loss=1.901462 error=1.687783 grad(V)=0.087207 grad(U)=0.001332\n",
      "downhill: Adam 429 loss=1.896446 error=1.682849 grad(V)=0.086675 grad(U)=0.001326\n",
      "downhill: Adam 430 loss=1.891447 error=1.677932 grad(V)=0.086146 grad(U)=0.001319\n",
      "downhill: validation 43 loss=1.886464 error=1.673031 grad(V)=0.085620 grad(U)=0.001313 *\n",
      "downhill: Adam 431 loss=1.886464 error=1.673031 grad(V)=0.085620 grad(U)=0.001313\n",
      "downhill: Adam 432 loss=1.881498 error=1.668147 grad(V)=0.085097 grad(U)=0.001307\n",
      "downhill: Adam 433 loss=1.876548 error=1.663279 grad(V)=0.084576 grad(U)=0.001300\n",
      "downhill: Adam 434 loss=1.871615 error=1.658426 grad(V)=0.084059 grad(U)=0.001294\n",
      "downhill: Adam 435 loss=1.866697 error=1.653590 grad(V)=0.083544 grad(U)=0.001288\n",
      "downhill: Adam 436 loss=1.861797 error=1.648770 grad(V)=0.083032 grad(U)=0.001281\n",
      "downhill: Adam 437 loss=1.856912 error=1.643966 grad(V)=0.082522 grad(U)=0.001275\n",
      "downhill: Adam 438 loss=1.852043 error=1.639178 grad(V)=0.082015 grad(U)=0.001269\n",
      "downhill: Adam 439 loss=1.847191 error=1.634406 grad(V)=0.081511 grad(U)=0.001263\n",
      "downhill: Adam 440 loss=1.842355 error=1.629650 grad(V)=0.081010 grad(U)=0.001257\n",
      "downhill: validation 44 loss=1.837535 error=1.624910 grad(V)=0.080511 grad(U)=0.001250 *\n",
      "downhill: Adam 441 loss=1.837535 error=1.624910 grad(V)=0.080511 grad(U)=0.001250\n",
      "downhill: Adam 442 loss=1.832731 error=1.620185 grad(V)=0.080015 grad(U)=0.001244\n",
      "downhill: Adam 443 loss=1.827943 error=1.615476 grad(V)=0.079521 grad(U)=0.001238\n",
      "downhill: Adam 444 loss=1.823170 error=1.610783 grad(V)=0.079031 grad(U)=0.001232\n",
      "downhill: Adam 445 loss=1.818414 error=1.606106 grad(V)=0.078542 grad(U)=0.001226\n",
      "downhill: Adam 446 loss=1.813674 error=1.601444 grad(V)=0.078057 grad(U)=0.001220\n",
      "downhill: Adam 447 loss=1.808949 error=1.596798 grad(V)=0.077574 grad(U)=0.001214\n",
      "downhill: Adam 448 loss=1.804240 error=1.592168 grad(V)=0.077093 grad(U)=0.001208\n",
      "downhill: Adam 449 loss=1.799547 error=1.587553 grad(V)=0.076615 grad(U)=0.001202\n",
      "downhill: Adam 450 loss=1.794869 error=1.582953 grad(V)=0.076140 grad(U)=0.001196\n",
      "downhill: validation 45 loss=1.790208 error=1.578369 grad(V)=0.075667 grad(U)=0.001191 *\n",
      "downhill: Adam 451 loss=1.790208 error=1.578369 grad(V)=0.075667 grad(U)=0.001191\n",
      "downhill: Adam 452 loss=1.785561 error=1.573801 grad(V)=0.075197 grad(U)=0.001185\n",
      "downhill: Adam 453 loss=1.780931 error=1.569247 grad(V)=0.074729 grad(U)=0.001179\n",
      "downhill: Adam 454 loss=1.776315 error=1.564709 grad(V)=0.074264 grad(U)=0.001173\n",
      "downhill: Adam 455 loss=1.771715 error=1.560187 grad(V)=0.073801 grad(U)=0.001167\n",
      "downhill: Adam 456 loss=1.767131 error=1.555679 grad(V)=0.073341 grad(U)=0.001162\n",
      "downhill: Adam 457 loss=1.762562 error=1.551187 grad(V)=0.072883 grad(U)=0.001156\n",
      "downhill: Adam 458 loss=1.758008 error=1.546710 grad(V)=0.072427 grad(U)=0.001150\n",
      "downhill: Adam 459 loss=1.753469 error=1.542248 grad(V)=0.071974 grad(U)=0.001145\n",
      "downhill: Adam 460 loss=1.748946 error=1.537801 grad(V)=0.071523 grad(U)=0.001139\n",
      "downhill: validation 46 loss=1.744438 error=1.533369 grad(V)=0.071075 grad(U)=0.001133 *\n",
      "downhill: Adam 461 loss=1.744438 error=1.533369 grad(V)=0.071075 grad(U)=0.001133\n",
      "downhill: Adam 462 loss=1.739945 error=1.528952 grad(V)=0.070629 grad(U)=0.001128\n",
      "downhill: Adam 463 loss=1.735467 error=1.524550 grad(V)=0.070186 grad(U)=0.001122\n",
      "downhill: Adam 464 loss=1.731004 error=1.520163 grad(V)=0.069745 grad(U)=0.001117\n",
      "downhill: Adam 465 loss=1.726556 error=1.515790 grad(V)=0.069306 grad(U)=0.001111\n",
      "downhill: Adam 466 loss=1.722123 error=1.511433 grad(V)=0.068869 grad(U)=0.001106\n",
      "downhill: Adam 467 loss=1.717705 error=1.507090 grad(V)=0.068435 grad(U)=0.001100\n",
      "downhill: Adam 468 loss=1.713302 error=1.502762 grad(V)=0.068004 grad(U)=0.001095\n",
      "downhill: Adam 469 loss=1.708913 error=1.498449 grad(V)=0.067574 grad(U)=0.001089\n",
      "downhill: Adam 470 loss=1.704540 error=1.494150 grad(V)=0.067147 grad(U)=0.001084\n",
      "downhill: validation 47 loss=1.700182 error=1.489866 grad(V)=0.066722 grad(U)=0.001079 *\n",
      "downhill: Adam 471 loss=1.700182 error=1.489866 grad(V)=0.066722 grad(U)=0.001079\n",
      "downhill: Adam 472 loss=1.695838 error=1.485597 grad(V)=0.066300 grad(U)=0.001073\n",
      "downhill: Adam 473 loss=1.691508 error=1.481342 grad(V)=0.065879 grad(U)=0.001068\n",
      "downhill: Adam 474 loss=1.687194 error=1.477102 grad(V)=0.065461 grad(U)=0.001063\n",
      "downhill: Adam 475 loss=1.682894 error=1.472876 grad(V)=0.065046 grad(U)=0.001057\n",
      "downhill: Adam 476 loss=1.678609 error=1.468664 grad(V)=0.064632 grad(U)=0.001052\n",
      "downhill: Adam 477 loss=1.674338 error=1.464467 grad(V)=0.064221 grad(U)=0.001047\n",
      "downhill: Adam 478 loss=1.670082 error=1.460284 grad(V)=0.063812 grad(U)=0.001042\n",
      "downhill: Adam 479 loss=1.665840 error=1.456116 grad(V)=0.063405 grad(U)=0.001036\n",
      "downhill: Adam 480 loss=1.661613 error=1.451962 grad(V)=0.063000 grad(U)=0.001031\n",
      "downhill: validation 48 loss=1.657400 error=1.447822 grad(V)=0.062597 grad(U)=0.001026 *\n",
      "downhill: Adam 481 loss=1.657400 error=1.447822 grad(V)=0.062597 grad(U)=0.001026\n",
      "downhill: Adam 482 loss=1.653202 error=1.443697 grad(V)=0.062197 grad(U)=0.001021\n",
      "downhill: Adam 483 loss=1.649018 error=1.439585 grad(V)=0.061799 grad(U)=0.001016\n",
      "downhill: Adam 484 loss=1.644848 error=1.435488 grad(V)=0.061403 grad(U)=0.001011\n",
      "downhill: Adam 485 loss=1.640693 error=1.431405 grad(V)=0.061009 grad(U)=0.001006\n",
      "downhill: Adam 486 loss=1.636552 error=1.427335 grad(V)=0.060617 grad(U)=0.001001\n",
      "downhill: Adam 487 loss=1.632425 error=1.423280 grad(V)=0.060227 grad(U)=0.000996\n",
      "downhill: Adam 488 loss=1.628312 error=1.419239 grad(V)=0.059839 grad(U)=0.000991\n",
      "downhill: Adam 489 loss=1.624213 error=1.415212 grad(V)=0.059454 grad(U)=0.000986\n",
      "downhill: Adam 490 loss=1.620128 error=1.411198 grad(V)=0.059070 grad(U)=0.000981\n",
      "downhill: validation 49 loss=1.616057 error=1.407199 grad(V)=0.058689 grad(U)=0.000976 *\n",
      "downhill: Adam 491 loss=1.616057 error=1.407199 grad(V)=0.058689 grad(U)=0.000976\n",
      "downhill: Adam 492 loss=1.612001 error=1.403213 grad(V)=0.058310 grad(U)=0.000971\n",
      "downhill: Adam 493 loss=1.607958 error=1.399242 grad(V)=0.057932 grad(U)=0.000966\n",
      "downhill: Adam 494 loss=1.603929 error=1.395284 grad(V)=0.057557 grad(U)=0.000961\n",
      "downhill: Adam 495 loss=1.599914 error=1.391339 grad(V)=0.057184 grad(U)=0.000957\n",
      "downhill: Adam 496 loss=1.595913 error=1.387409 grad(V)=0.056813 grad(U)=0.000952\n",
      "downhill: Adam 497 loss=1.591926 error=1.383492 grad(V)=0.056444 grad(U)=0.000947\n",
      "downhill: Adam 498 loss=1.587952 error=1.379588 grad(V)=0.056077 grad(U)=0.000942\n",
      "downhill: Adam 499 loss=1.583992 error=1.375698 grad(V)=0.055712 grad(U)=0.000938\n",
      "downhill: Adam 500 loss=1.580046 error=1.371822 grad(V)=0.055349 grad(U)=0.000933\n",
      "downhill: validation 50 loss=1.576114 error=1.367959 grad(V)=0.054987 grad(U)=0.000928 *\n",
      "downhill: Adam 501 loss=1.576114 error=1.367959 grad(V)=0.054987 grad(U)=0.000928\n",
      "downhill: Adam 502 loss=1.572195 error=1.364110 grad(V)=0.054628 grad(U)=0.000923\n",
      "downhill: Adam 503 loss=1.568290 error=1.360274 grad(V)=0.054271 grad(U)=0.000919\n",
      "downhill: Adam 504 loss=1.564398 error=1.356452 grad(V)=0.053916 grad(U)=0.000914\n",
      "downhill: Adam 505 loss=1.560519 error=1.352643 grad(V)=0.053563 grad(U)=0.000910\n",
      "downhill: Adam 506 loss=1.556655 error=1.348847 grad(V)=0.053211 grad(U)=0.000905\n",
      "downhill: Adam 507 loss=1.552803 error=1.345065 grad(V)=0.052862 grad(U)=0.000900\n",
      "downhill: Adam 508 loss=1.548965 error=1.341296 grad(V)=0.052514 grad(U)=0.000896\n",
      "downhill: Adam 509 loss=1.545141 error=1.337540 grad(V)=0.052168 grad(U)=0.000891\n",
      "downhill: Adam 510 loss=1.541329 error=1.333797 grad(V)=0.051825 grad(U)=0.000887\n",
      "downhill: validation 51 loss=1.537531 error=1.330068 grad(V)=0.051483 grad(U)=0.000882 *\n",
      "downhill: Adam 511 loss=1.537531 error=1.330068 grad(V)=0.051483 grad(U)=0.000882\n",
      "downhill: Adam 512 loss=1.533747 error=1.326351 grad(V)=0.051143 grad(U)=0.000878\n",
      "downhill: Adam 513 loss=1.529975 error=1.322648 grad(V)=0.050805 grad(U)=0.000873\n",
      "downhill: Adam 514 loss=1.526217 error=1.318958 grad(V)=0.050468 grad(U)=0.000869\n",
      "downhill: Adam 515 loss=1.522472 error=1.315280 grad(V)=0.050134 grad(U)=0.000865\n",
      "downhill: Adam 516 loss=1.518740 error=1.311616 grad(V)=0.049801 grad(U)=0.000860\n",
      "downhill: Adam 517 loss=1.515021 error=1.307965 grad(V)=0.049470 grad(U)=0.000856\n",
      "downhill: Adam 518 loss=1.511315 error=1.304326 grad(V)=0.049142 grad(U)=0.000852\n",
      "downhill: Adam 519 loss=1.507622 error=1.300701 grad(V)=0.048814 grad(U)=0.000847\n",
      "downhill: Adam 520 loss=1.503942 error=1.297088 grad(V)=0.048489 grad(U)=0.000843\n",
      "downhill: validation 52 loss=1.500275 error=1.293489 grad(V)=0.048165 grad(U)=0.000839 *\n",
      "downhill: Adam 521 loss=1.500275 error=1.293489 grad(V)=0.048165 grad(U)=0.000839\n",
      "downhill: Adam 522 loss=1.496621 error=1.289902 grad(V)=0.047844 grad(U)=0.000834\n",
      "downhill: Adam 523 loss=1.492980 error=1.286327 grad(V)=0.047524 grad(U)=0.000830\n",
      "downhill: Adam 524 loss=1.489352 error=1.282766 grad(V)=0.047205 grad(U)=0.000826\n",
      "downhill: Adam 525 loss=1.485737 error=1.279217 grad(V)=0.046889 grad(U)=0.000822\n",
      "downhill: Adam 526 loss=1.482134 error=1.275681 grad(V)=0.046574 grad(U)=0.000817\n",
      "downhill: Adam 527 loss=1.478544 error=1.272157 grad(V)=0.046261 grad(U)=0.000813\n",
      "downhill: Adam 528 loss=1.474968 error=1.268646 grad(V)=0.045950 grad(U)=0.000809\n",
      "downhill: Adam 529 loss=1.471403 error=1.265148 grad(V)=0.045640 grad(U)=0.000805\n",
      "downhill: Adam 530 loss=1.467852 error=1.261662 grad(V)=0.045333 grad(U)=0.000801\n",
      "downhill: validation 53 loss=1.464313 error=1.258188 grad(V)=0.045026 grad(U)=0.000797 *\n",
      "downhill: Adam 531 loss=1.464313 error=1.258188 grad(V)=0.045026 grad(U)=0.000797\n",
      "downhill: Adam 532 loss=1.460787 error=1.254728 grad(V)=0.044722 grad(U)=0.000793\n",
      "downhill: Adam 533 loss=1.457273 error=1.251279 grad(V)=0.044419 grad(U)=0.000789\n",
      "downhill: Adam 534 loss=1.453772 error=1.247843 grad(V)=0.044118 grad(U)=0.000784\n",
      "downhill: Adam 535 loss=1.450284 error=1.244420 grad(V)=0.043819 grad(U)=0.000780\n",
      "downhill: Adam 536 loss=1.446808 error=1.241008 grad(V)=0.043521 grad(U)=0.000776\n",
      "downhill: Adam 537 loss=1.443344 error=1.237609 grad(V)=0.043225 grad(U)=0.000772\n",
      "downhill: Adam 538 loss=1.439893 error=1.234222 grad(V)=0.042931 grad(U)=0.000768\n",
      "downhill: Adam 539 loss=1.436454 error=1.230848 grad(V)=0.042638 grad(U)=0.000764\n",
      "downhill: Adam 540 loss=1.433027 error=1.227486 grad(V)=0.042347 grad(U)=0.000761\n",
      "downhill: validation 54 loss=1.429613 error=1.224136 grad(V)=0.042057 grad(U)=0.000757 *\n",
      "downhill: Adam 541 loss=1.429613 error=1.224136 grad(V)=0.042057 grad(U)=0.000757\n",
      "downhill: Adam 542 loss=1.426211 error=1.220798 grad(V)=0.041770 grad(U)=0.000753\n",
      "downhill: Adam 543 loss=1.422821 error=1.217472 grad(V)=0.041483 grad(U)=0.000749\n",
      "downhill: Adam 544 loss=1.419443 error=1.214158 grad(V)=0.041199 grad(U)=0.000745\n",
      "downhill: Adam 545 loss=1.416078 error=1.210857 grad(V)=0.040916 grad(U)=0.000741\n",
      "downhill: Adam 546 loss=1.412725 error=1.207567 grad(V)=0.040635 grad(U)=0.000737\n",
      "downhill: Adam 547 loss=1.409383 error=1.204289 grad(V)=0.040355 grad(U)=0.000734\n",
      "downhill: Adam 548 loss=1.406054 error=1.201023 grad(V)=0.040077 grad(U)=0.000730\n",
      "downhill: Adam 549 loss=1.402737 error=1.197769 grad(V)=0.039800 grad(U)=0.000726\n",
      "downhill: Adam 550 loss=1.399432 error=1.194528 grad(V)=0.039525 grad(U)=0.000722\n",
      "downhill: validation 55 loss=1.396139 error=1.191297 grad(V)=0.039251 grad(U)=0.000718 *\n",
      "downhill: Adam 551 loss=1.396139 error=1.191297 grad(V)=0.039251 grad(U)=0.000718\n",
      "downhill: Adam 552 loss=1.392858 error=1.188079 grad(V)=0.038979 grad(U)=0.000715\n",
      "downhill: Adam 553 loss=1.389588 error=1.184873 grad(V)=0.038709 grad(U)=0.000711\n",
      "downhill: Adam 554 loss=1.386331 error=1.181678 grad(V)=0.038440 grad(U)=0.000707\n",
      "downhill: Adam 555 loss=1.383085 error=1.178495 grad(V)=0.038173 grad(U)=0.000704\n",
      "downhill: Adam 556 loss=1.379852 error=1.175323 grad(V)=0.037907 grad(U)=0.000700\n",
      "downhill: Adam 557 loss=1.376629 error=1.172163 grad(V)=0.037642 grad(U)=0.000696\n",
      "downhill: Adam 558 loss=1.373419 error=1.169015 grad(V)=0.037380 grad(U)=0.000693\n",
      "downhill: Adam 559 loss=1.370220 error=1.165879 grad(V)=0.037118 grad(U)=0.000689\n",
      "downhill: Adam 560 loss=1.367033 error=1.162754 grad(V)=0.036858 grad(U)=0.000686\n",
      "downhill: validation 56 loss=1.363858 error=1.159640 grad(V)=0.036600 grad(U)=0.000682 *\n",
      "downhill: Adam 561 loss=1.363858 error=1.159640 grad(V)=0.036600 grad(U)=0.000682\n",
      "downhill: Adam 562 loss=1.360694 error=1.156538 grad(V)=0.036343 grad(U)=0.000678\n",
      "downhill: Adam 563 loss=1.357542 error=1.153448 grad(V)=0.036088 grad(U)=0.000675\n",
      "downhill: Adam 564 loss=1.354401 error=1.150369 grad(V)=0.035834 grad(U)=0.000671\n",
      "downhill: Adam 565 loss=1.351272 error=1.147301 grad(V)=0.035581 grad(U)=0.000668\n",
      "downhill: Adam 566 loss=1.348154 error=1.144245 grad(V)=0.035330 grad(U)=0.000664\n",
      "downhill: Adam 567 loss=1.345048 error=1.141200 grad(V)=0.035081 grad(U)=0.000661\n",
      "downhill: Adam 568 loss=1.341953 error=1.138166 grad(V)=0.034833 grad(U)=0.000657\n",
      "downhill: Adam 569 loss=1.338870 error=1.135144 grad(V)=0.034586 grad(U)=0.000654\n",
      "downhill: Adam 570 loss=1.335798 error=1.132133 grad(V)=0.034341 grad(U)=0.000651\n",
      "downhill: validation 57 loss=1.332737 error=1.129133 grad(V)=0.034097 grad(U)=0.000647 *\n",
      "downhill: Adam 571 loss=1.332737 error=1.129133 grad(V)=0.034097 grad(U)=0.000647\n",
      "downhill: Adam 572 loss=1.329688 error=1.126144 grad(V)=0.033854 grad(U)=0.000644\n",
      "downhill: Adam 573 loss=1.326650 error=1.123167 grad(V)=0.033613 grad(U)=0.000640\n",
      "downhill: Adam 574 loss=1.323623 error=1.120201 grad(V)=0.033374 grad(U)=0.000637\n",
      "downhill: Adam 575 loss=1.320607 error=1.117245 grad(V)=0.033136 grad(U)=0.000634\n",
      "downhill: Adam 576 loss=1.317602 error=1.114301 grad(V)=0.032899 grad(U)=0.000630\n",
      "downhill: Adam 577 loss=1.314609 error=1.111368 grad(V)=0.032663 grad(U)=0.000627\n",
      "downhill: Adam 578 loss=1.311626 error=1.108446 grad(V)=0.032429 grad(U)=0.000624\n",
      "downhill: Adam 579 loss=1.308655 error=1.105534 grad(V)=0.032197 grad(U)=0.000620\n",
      "downhill: Adam 580 loss=1.305695 error=1.102634 grad(V)=0.031965 grad(U)=0.000617\n",
      "downhill: validation 58 loss=1.302745 error=1.099745 grad(V)=0.031735 grad(U)=0.000614 *\n",
      "downhill: Adam 581 loss=1.302745 error=1.099745 grad(V)=0.031735 grad(U)=0.000614\n",
      "downhill: Adam 582 loss=1.299807 error=1.096866 grad(V)=0.031507 grad(U)=0.000611\n",
      "downhill: Adam 583 loss=1.296880 error=1.093998 grad(V)=0.031280 grad(U)=0.000607\n",
      "downhill: Adam 584 loss=1.293963 error=1.091141 grad(V)=0.031054 grad(U)=0.000604\n",
      "downhill: Adam 585 loss=1.291058 error=1.088295 grad(V)=0.030829 grad(U)=0.000601\n",
      "downhill: Adam 586 loss=1.288163 error=1.085460 grad(V)=0.030606 grad(U)=0.000598\n",
      "downhill: Adam 587 loss=1.285279 error=1.082636 grad(V)=0.030384 grad(U)=0.000595\n",
      "downhill: Adam 588 loss=1.282407 error=1.079822 grad(V)=0.030163 grad(U)=0.000592\n",
      "downhill: Adam 589 loss=1.279544 error=1.077018 grad(V)=0.029944 grad(U)=0.000588\n",
      "downhill: Adam 590 loss=1.276693 error=1.074226 grad(V)=0.029726 grad(U)=0.000585\n",
      "downhill: validation 59 loss=1.273852 error=1.071444 grad(V)=0.029509 grad(U)=0.000582 *\n",
      "downhill: Adam 591 loss=1.273852 error=1.071444 grad(V)=0.029509 grad(U)=0.000582\n",
      "downhill: Adam 592 loss=1.271022 error=1.068673 grad(V)=0.029294 grad(U)=0.000579\n",
      "downhill: Adam 593 loss=1.268203 error=1.065912 grad(V)=0.029080 grad(U)=0.000576\n",
      "downhill: Adam 594 loss=1.265394 error=1.063161 grad(V)=0.028867 grad(U)=0.000573\n",
      "downhill: Adam 595 loss=1.262596 error=1.060422 grad(V)=0.028655 grad(U)=0.000570\n",
      "downhill: Adam 596 loss=1.259809 error=1.057692 grad(V)=0.028445 grad(U)=0.000567\n",
      "downhill: Adam 597 loss=1.257032 error=1.054973 grad(V)=0.028235 grad(U)=0.000564\n",
      "downhill: Adam 598 loss=1.254266 error=1.052265 grad(V)=0.028028 grad(U)=0.000561\n",
      "downhill: Adam 599 loss=1.251510 error=1.049567 grad(V)=0.027821 grad(U)=0.000558\n",
      "downhill: Adam 600 loss=1.248764 error=1.046879 grad(V)=0.027616 grad(U)=0.000555\n",
      "downhill: validation 60 loss=1.246029 error=1.044202 grad(V)=0.027411 grad(U)=0.000552 *\n",
      "downhill: Adam 601 loss=1.246029 error=1.044202 grad(V)=0.027411 grad(U)=0.000552\n",
      "downhill: Adam 602 loss=1.243305 error=1.041534 grad(V)=0.027208 grad(U)=0.000549\n",
      "downhill: Adam 603 loss=1.240590 error=1.038878 grad(V)=0.027007 grad(U)=0.000546\n",
      "downhill: Adam 604 loss=1.237886 error=1.036231 grad(V)=0.026806 grad(U)=0.000543\n",
      "downhill: Adam 605 loss=1.235193 error=1.033594 grad(V)=0.026607 grad(U)=0.000540\n",
      "downhill: Adam 606 loss=1.232509 error=1.030968 grad(V)=0.026409 grad(U)=0.000537\n",
      "downhill: Adam 607 loss=1.229836 error=1.028352 grad(V)=0.026212 grad(U)=0.000534\n",
      "downhill: Adam 608 loss=1.227173 error=1.025746 grad(V)=0.026016 grad(U)=0.000532\n",
      "downhill: Adam 609 loss=1.224520 error=1.023150 grad(V)=0.025821 grad(U)=0.000529\n",
      "downhill: Adam 610 loss=1.221877 error=1.020564 grad(V)=0.025628 grad(U)=0.000526\n",
      "downhill: validation 61 loss=1.219245 error=1.017988 grad(V)=0.025436 grad(U)=0.000523 *\n",
      "downhill: Adam 611 loss=1.219245 error=1.017988 grad(V)=0.025436 grad(U)=0.000523\n",
      "downhill: Adam 612 loss=1.216622 error=1.015422 grad(V)=0.025245 grad(U)=0.000520\n",
      "downhill: Adam 613 loss=1.214010 error=1.012866 grad(V)=0.025055 grad(U)=0.000517\n",
      "downhill: Adam 614 loss=1.211407 error=1.010320 grad(V)=0.024867 grad(U)=0.000515\n",
      "downhill: Adam 615 loss=1.208815 error=1.007784 grad(V)=0.024679 grad(U)=0.000512\n",
      "downhill: Adam 616 loss=1.206232 error=1.005258 grad(V)=0.024493 grad(U)=0.000509\n",
      "downhill: Adam 617 loss=1.203660 error=1.002742 grad(V)=0.024308 grad(U)=0.000506\n",
      "downhill: Adam 618 loss=1.201097 error=1.000235 grad(V)=0.024124 grad(U)=0.000504\n",
      "downhill: Adam 619 loss=1.198545 error=0.997738 grad(V)=0.023941 grad(U)=0.000501\n",
      "downhill: Adam 620 loss=1.196002 error=0.995251 grad(V)=0.023759 grad(U)=0.000498\n",
      "downhill: validation 62 loss=1.193468 error=0.992774 grad(V)=0.023578 grad(U)=0.000496 *\n",
      "downhill: Adam 621 loss=1.193468 error=0.992774 grad(V)=0.023578 grad(U)=0.000496\n",
      "downhill: Adam 622 loss=1.190945 error=0.990306 grad(V)=0.023399 grad(U)=0.000493\n",
      "downhill: Adam 623 loss=1.188431 error=0.987848 grad(V)=0.023220 grad(U)=0.000490\n",
      "downhill: Adam 624 loss=1.185927 error=0.985400 grad(V)=0.023043 grad(U)=0.000488\n",
      "downhill: Adam 625 loss=1.183433 error=0.982961 grad(V)=0.022867 grad(U)=0.000485\n",
      "downhill: Adam 626 loss=1.180948 error=0.980532 grad(V)=0.022692 grad(U)=0.000482\n",
      "downhill: Adam 627 loss=1.178473 error=0.978112 grad(V)=0.022518 grad(U)=0.000480\n",
      "downhill: Adam 628 loss=1.176008 error=0.975702 grad(V)=0.022345 grad(U)=0.000477\n",
      "downhill: Adam 629 loss=1.173551 error=0.973301 grad(V)=0.022173 grad(U)=0.000475\n",
      "downhill: Adam 630 loss=1.171105 error=0.970910 grad(V)=0.022002 grad(U)=0.000472\n",
      "downhill: validation 63 loss=1.168668 error=0.968528 grad(V)=0.021833 grad(U)=0.000469 *\n",
      "downhill: Adam 631 loss=1.168668 error=0.968528 grad(V)=0.021833 grad(U)=0.000469\n",
      "downhill: Adam 632 loss=1.166240 error=0.966156 grad(V)=0.021664 grad(U)=0.000467\n",
      "downhill: Adam 633 loss=1.163822 error=0.963793 grad(V)=0.021497 grad(U)=0.000464\n",
      "downhill: Adam 634 loss=1.161414 error=0.961439 grad(V)=0.021330 grad(U)=0.000462\n",
      "downhill: Adam 635 loss=1.159014 error=0.959095 grad(V)=0.021165 grad(U)=0.000459\n",
      "downhill: Adam 636 loss=1.156625 error=0.956760 grad(V)=0.021001 grad(U)=0.000457\n",
      "downhill: Adam 637 loss=1.154244 error=0.954434 grad(V)=0.020837 grad(U)=0.000454\n",
      "downhill: Adam 638 loss=1.151873 error=0.952117 grad(V)=0.020675 grad(U)=0.000452\n",
      "downhill: Adam 639 loss=1.149511 error=0.949810 grad(V)=0.020514 grad(U)=0.000449\n",
      "downhill: Adam 640 loss=1.147159 error=0.947511 grad(V)=0.020354 grad(U)=0.000447\n",
      "downhill: validation 64 loss=1.144815 error=0.945222 grad(V)=0.020194 grad(U)=0.000444 *\n",
      "downhill: Adam 641 loss=1.144815 error=0.945222 grad(V)=0.020194 grad(U)=0.000444\n",
      "downhill: Adam 642 loss=1.142481 error=0.942942 grad(V)=0.020036 grad(U)=0.000442\n",
      "downhill: Adam 643 loss=1.140156 error=0.940671 grad(V)=0.019879 grad(U)=0.000440\n",
      "downhill: Adam 644 loss=1.137841 error=0.938409 grad(V)=0.019723 grad(U)=0.000437\n",
      "downhill: Adam 645 loss=1.135534 error=0.936156 grad(V)=0.019568 grad(U)=0.000435\n",
      "downhill: Adam 646 loss=1.133236 error=0.933912 grad(V)=0.019414 grad(U)=0.000432\n",
      "downhill: Adam 647 loss=1.130948 error=0.931677 grad(V)=0.019261 grad(U)=0.000430\n",
      "downhill: Adam 648 loss=1.128668 error=0.929451 grad(V)=0.019109 grad(U)=0.000428\n",
      "downhill: Adam 649 loss=1.126397 error=0.927234 grad(V)=0.018957 grad(U)=0.000425\n",
      "downhill: Adam 650 loss=1.124136 error=0.925026 grad(V)=0.018807 grad(U)=0.000423\n",
      "downhill: validation 65 loss=1.121883 error=0.922827 grad(V)=0.018658 grad(U)=0.000421 *\n",
      "downhill: Adam 651 loss=1.121883 error=0.922827 grad(V)=0.018658 grad(U)=0.000421\n",
      "downhill: Adam 652 loss=1.119639 error=0.920636 grad(V)=0.018510 grad(U)=0.000418\n",
      "downhill: Adam 653 loss=1.117404 error=0.918454 grad(V)=0.018363 grad(U)=0.000416\n",
      "downhill: Adam 654 loss=1.115178 error=0.916281 grad(V)=0.018216 grad(U)=0.000414\n",
      "downhill: Adam 655 loss=1.112961 error=0.914117 grad(V)=0.018071 grad(U)=0.000411\n",
      "downhill: Adam 656 loss=1.110752 error=0.911962 grad(V)=0.017927 grad(U)=0.000409\n",
      "downhill: Adam 657 loss=1.108552 error=0.909815 grad(V)=0.017783 grad(U)=0.000407\n",
      "downhill: Adam 658 loss=1.106361 error=0.907676 grad(V)=0.017641 grad(U)=0.000405\n",
      "downhill: Adam 659 loss=1.104179 error=0.905547 grad(V)=0.017499 grad(U)=0.000402\n",
      "downhill: Adam 660 loss=1.102005 error=0.903426 grad(V)=0.017358 grad(U)=0.000400\n",
      "downhill: validation 66 loss=1.099840 error=0.901313 grad(V)=0.017219 grad(U)=0.000398 *\n",
      "downhill: Adam 661 loss=1.099840 error=0.901313 grad(V)=0.017219 grad(U)=0.000398\n",
      "downhill: Adam 662 loss=1.097684 error=0.899209 grad(V)=0.017080 grad(U)=0.000396\n",
      "downhill: Adam 663 loss=1.095536 error=0.897114 grad(V)=0.016942 grad(U)=0.000394\n",
      "downhill: Adam 664 loss=1.093397 error=0.895027 grad(V)=0.016805 grad(U)=0.000391\n",
      "downhill: Adam 665 loss=1.091266 error=0.892948 grad(V)=0.016669 grad(U)=0.000389\n",
      "downhill: Adam 666 loss=1.089143 error=0.890878 grad(V)=0.016534 grad(U)=0.000387\n",
      "downhill: Adam 667 loss=1.087029 error=0.888816 grad(V)=0.016400 grad(U)=0.000385\n",
      "downhill: Adam 668 loss=1.084923 error=0.886763 grad(V)=0.016267 grad(U)=0.000383\n",
      "downhill: Adam 669 loss=1.082826 error=0.884718 grad(V)=0.016134 grad(U)=0.000381\n",
      "downhill: Adam 670 loss=1.080737 error=0.882681 grad(V)=0.016003 grad(U)=0.000379\n",
      "downhill: validation 67 loss=1.078656 error=0.880652 grad(V)=0.015872 grad(U)=0.000376 *\n",
      "downhill: Adam 671 loss=1.078656 error=0.880652 grad(V)=0.015872 grad(U)=0.000376\n",
      "downhill: Adam 672 loss=1.076584 error=0.878632 grad(V)=0.015743 grad(U)=0.000374\n",
      "downhill: Adam 673 loss=1.074520 error=0.876620 grad(V)=0.015614 grad(U)=0.000372\n",
      "downhill: Adam 674 loss=1.072464 error=0.874616 grad(V)=0.015486 grad(U)=0.000370\n",
      "downhill: Adam 675 loss=1.070417 error=0.872620 grad(V)=0.015359 grad(U)=0.000368\n",
      "downhill: Adam 676 loss=1.068377 error=0.870632 grad(V)=0.015232 grad(U)=0.000366\n",
      "downhill: Adam 677 loss=1.066346 error=0.868653 grad(V)=0.015107 grad(U)=0.000364\n",
      "downhill: Adam 678 loss=1.064322 error=0.866681 grad(V)=0.014983 grad(U)=0.000362\n",
      "downhill: Adam 679 loss=1.062307 error=0.864717 grad(V)=0.014859 grad(U)=0.000360\n",
      "downhill: Adam 680 loss=1.060300 error=0.862762 grad(V)=0.014736 grad(U)=0.000358\n",
      "downhill: validation 68 loss=1.058301 error=0.860814 grad(V)=0.014614 grad(U)=0.000356 *\n",
      "downhill: Adam 681 loss=1.058301 error=0.860814 grad(V)=0.014614 grad(U)=0.000356\n",
      "downhill: Adam 682 loss=1.056310 error=0.858874 grad(V)=0.014493 grad(U)=0.000354\n",
      "downhill: Adam 683 loss=1.054327 error=0.856943 grad(V)=0.014373 grad(U)=0.000352\n",
      "downhill: Adam 684 loss=1.052352 error=0.855019 grad(V)=0.014254 grad(U)=0.000350\n",
      "downhill: Adam 685 loss=1.050385 error=0.853103 grad(V)=0.014135 grad(U)=0.000348\n",
      "downhill: Adam 686 loss=1.048425 error=0.851194 grad(V)=0.014017 grad(U)=0.000346\n",
      "downhill: Adam 687 loss=1.046474 error=0.849294 grad(V)=0.013900 grad(U)=0.000344\n",
      "downhill: Adam 688 loss=1.044530 error=0.847401 grad(V)=0.013784 grad(U)=0.000342\n",
      "downhill: Adam 689 loss=1.042594 error=0.845516 grad(V)=0.013669 grad(U)=0.000340\n",
      "downhill: Adam 690 loss=1.040665 error=0.843639 grad(V)=0.013554 grad(U)=0.000339\n",
      "downhill: validation 69 loss=1.038744 error=0.841769 grad(V)=0.013441 grad(U)=0.000337 *\n",
      "downhill: Adam 691 loss=1.038744 error=0.841769 grad(V)=0.013441 grad(U)=0.000337\n",
      "downhill: Adam 692 loss=1.036831 error=0.839907 grad(V)=0.013328 grad(U)=0.000335\n",
      "downhill: Adam 693 loss=1.034926 error=0.838053 grad(V)=0.013216 grad(U)=0.000333\n",
      "downhill: Adam 694 loss=1.033029 error=0.836206 grad(V)=0.013104 grad(U)=0.000331\n",
      "downhill: Adam 695 loss=1.031139 error=0.834367 grad(V)=0.012994 grad(U)=0.000329\n",
      "downhill: Adam 696 loss=1.029256 error=0.832535 grad(V)=0.012884 grad(U)=0.000327\n",
      "downhill: Adam 697 loss=1.027381 error=0.830711 grad(V)=0.012775 grad(U)=0.000326\n",
      "downhill: Adam 698 loss=1.025513 error=0.828894 grad(V)=0.012667 grad(U)=0.000324\n",
      "downhill: Adam 699 loss=1.023653 error=0.827085 grad(V)=0.012560 grad(U)=0.000322\n",
      "downhill: Adam 700 loss=1.021801 error=0.825283 grad(V)=0.012453 grad(U)=0.000320\n",
      "downhill: validation 70 loss=1.019955 error=0.823488 grad(V)=0.012347 grad(U)=0.000318 *\n",
      "downhill: Adam 701 loss=1.019955 error=0.823488 grad(V)=0.012347 grad(U)=0.000318\n",
      "downhill: Adam 702 loss=1.018118 error=0.821701 grad(V)=0.012242 grad(U)=0.000316\n",
      "downhill: Adam 703 loss=1.016287 error=0.819921 grad(V)=0.012138 grad(U)=0.000315\n",
      "downhill: Adam 704 loss=1.014464 error=0.818149 grad(V)=0.012034 grad(U)=0.000313\n",
      "downhill: Adam 705 loss=1.012648 error=0.816383 grad(V)=0.011931 grad(U)=0.000311\n",
      "downhill: Adam 706 loss=1.010840 error=0.814625 grad(V)=0.011829 grad(U)=0.000309\n",
      "downhill: Adam 707 loss=1.009039 error=0.812874 grad(V)=0.011728 grad(U)=0.000308\n",
      "downhill: Adam 708 loss=1.007245 error=0.811131 grad(V)=0.011627 grad(U)=0.000306\n",
      "downhill: Adam 709 loss=1.005458 error=0.809394 grad(V)=0.011528 grad(U)=0.000304\n",
      "downhill: Adam 710 loss=1.003679 error=0.807665 grad(V)=0.011428 grad(U)=0.000302\n",
      "downhill: validation 71 loss=1.001907 error=0.805942 grad(V)=0.011330 grad(U)=0.000301 *\n",
      "downhill: Adam 711 loss=1.001907 error=0.805942 grad(V)=0.011330 grad(U)=0.000301\n",
      "downhill: Adam 712 loss=1.000141 error=0.804227 grad(V)=0.011232 grad(U)=0.000299\n",
      "downhill: Adam 713 loss=0.998383 error=0.802519 grad(V)=0.011135 grad(U)=0.000297\n",
      "downhill: Adam 714 loss=0.996632 error=0.800818 grad(V)=0.011039 grad(U)=0.000296\n",
      "downhill: Adam 715 loss=0.994888 error=0.799124 grad(V)=0.010943 grad(U)=0.000294\n",
      "downhill: Adam 716 loss=0.993151 error=0.797437 grad(V)=0.010849 grad(U)=0.000292\n",
      "downhill: Adam 717 loss=0.991421 error=0.795756 grad(V)=0.010755 grad(U)=0.000291\n",
      "downhill: Adam 718 loss=0.989698 error=0.794083 grad(V)=0.010661 grad(U)=0.000289\n",
      "downhill: Adam 719 loss=0.987982 error=0.792417 grad(V)=0.010568 grad(U)=0.000287\n",
      "downhill: Adam 720 loss=0.986272 error=0.790757 grad(V)=0.010476 grad(U)=0.000286\n",
      "downhill: validation 72 loss=0.984570 error=0.789104 grad(V)=0.010385 grad(U)=0.000284 *\n",
      "downhill: Adam 721 loss=0.984570 error=0.789104 grad(V)=0.010385 grad(U)=0.000284\n",
      "downhill: Adam 722 loss=0.982874 error=0.787458 grad(V)=0.010294 grad(U)=0.000283\n",
      "downhill: Adam 723 loss=0.981186 error=0.785818 grad(V)=0.010204 grad(U)=0.000281\n",
      "downhill: Adam 724 loss=0.979503 error=0.784186 grad(V)=0.010115 grad(U)=0.000279\n",
      "downhill: Adam 725 loss=0.977828 error=0.782560 grad(V)=0.010027 grad(U)=0.000278\n",
      "downhill: Adam 726 loss=0.976160 error=0.780941 grad(V)=0.009939 grad(U)=0.000276\n",
      "downhill: Adam 727 loss=0.974498 error=0.779328 grad(V)=0.009851 grad(U)=0.000275\n",
      "downhill: Adam 728 loss=0.972842 error=0.777722 grad(V)=0.009765 grad(U)=0.000273\n",
      "downhill: Adam 729 loss=0.971194 error=0.776123 grad(V)=0.009679 grad(U)=0.000272\n",
      "downhill: Adam 730 loss=0.969552 error=0.774530 grad(V)=0.009593 grad(U)=0.000270\n",
      "downhill: validation 73 loss=0.967916 error=0.772944 grad(V)=0.009509 grad(U)=0.000268 *\n",
      "downhill: Adam 731 loss=0.967916 error=0.772944 grad(V)=0.009509 grad(U)=0.000268\n",
      "downhill: Adam 732 loss=0.966287 error=0.771364 grad(V)=0.009425 grad(U)=0.000267\n",
      "downhill: Adam 733 loss=0.964665 error=0.769791 grad(V)=0.009341 grad(U)=0.000265\n",
      "downhill: Adam 734 loss=0.963049 error=0.768224 grad(V)=0.009259 grad(U)=0.000264\n",
      "downhill: Adam 735 loss=0.961440 error=0.766663 grad(V)=0.009176 grad(U)=0.000262\n",
      "downhill: Adam 736 loss=0.959837 error=0.765109 grad(V)=0.009095 grad(U)=0.000261\n",
      "downhill: Adam 737 loss=0.958240 error=0.763561 grad(V)=0.009014 grad(U)=0.000259\n",
      "downhill: Adam 738 loss=0.956650 error=0.762020 grad(V)=0.008934 grad(U)=0.000258\n",
      "downhill: Adam 739 loss=0.955066 error=0.760485 grad(V)=0.008854 grad(U)=0.000256\n",
      "downhill: Adam 740 loss=0.953488 error=0.758956 grad(V)=0.008775 grad(U)=0.000255\n",
      "downhill: validation 74 loss=0.951917 error=0.757433 grad(V)=0.008697 grad(U)=0.000254 *\n",
      "downhill: Adam 741 loss=0.951917 error=0.757433 grad(V)=0.008697 grad(U)=0.000254\n",
      "downhill: Adam 742 loss=0.950352 error=0.755917 grad(V)=0.008619 grad(U)=0.000252\n",
      "downhill: Adam 743 loss=0.948793 error=0.754407 grad(V)=0.008542 grad(U)=0.000251\n",
      "downhill: Adam 744 loss=0.947240 error=0.752903 grad(V)=0.008466 grad(U)=0.000249\n",
      "downhill: Adam 745 loss=0.945694 error=0.751405 grad(V)=0.008390 grad(U)=0.000248\n",
      "downhill: Adam 746 loss=0.944153 error=0.749913 grad(V)=0.008315 grad(U)=0.000246\n",
      "downhill: Adam 747 loss=0.942619 error=0.748427 grad(V)=0.008240 grad(U)=0.000245\n",
      "downhill: Adam 748 loss=0.941091 error=0.746947 grad(V)=0.008166 grad(U)=0.000244\n",
      "downhill: Adam 749 loss=0.939568 error=0.745473 grad(V)=0.008092 grad(U)=0.000242\n",
      "downhill: Adam 750 loss=0.938052 error=0.744006 grad(V)=0.008019 grad(U)=0.000241\n",
      "downhill: validation 75 loss=0.936542 error=0.742544 grad(V)=0.007947 grad(U)=0.000239 *\n",
      "downhill: Adam 751 loss=0.936542 error=0.742544 grad(V)=0.007947 grad(U)=0.000239\n",
      "downhill: Adam 752 loss=0.935037 error=0.741088 grad(V)=0.007875 grad(U)=0.000238\n",
      "downhill: Adam 753 loss=0.933539 error=0.739638 grad(V)=0.007804 grad(U)=0.000237\n",
      "downhill: Adam 754 loss=0.932046 error=0.738194 grad(V)=0.007733 grad(U)=0.000235\n",
      "downhill: Adam 755 loss=0.930560 error=0.736756 grad(V)=0.007663 grad(U)=0.000234\n",
      "downhill: Adam 756 loss=0.929079 error=0.735323 grad(V)=0.007594 grad(U)=0.000233\n",
      "downhill: Adam 757 loss=0.927604 error=0.733897 grad(V)=0.007525 grad(U)=0.000231\n",
      "downhill: Adam 758 loss=0.926135 error=0.732476 grad(V)=0.007457 grad(U)=0.000230\n",
      "downhill: Adam 759 loss=0.924671 error=0.731061 grad(V)=0.007389 grad(U)=0.000229\n",
      "downhill: Adam 760 loss=0.923214 error=0.729651 grad(V)=0.007321 grad(U)=0.000227\n",
      "downhill: validation 76 loss=0.921762 error=0.728247 grad(V)=0.007255 grad(U)=0.000226 *\n",
      "downhill: Adam 761 loss=0.921762 error=0.728247 grad(V)=0.007255 grad(U)=0.000226\n",
      "downhill: Adam 762 loss=0.920315 error=0.726849 grad(V)=0.007189 grad(U)=0.000225\n",
      "downhill: Adam 763 loss=0.918875 error=0.725457 grad(V)=0.007123 grad(U)=0.000224\n",
      "downhill: Adam 764 loss=0.917440 error=0.724070 grad(V)=0.007058 grad(U)=0.000222\n",
      "downhill: Adam 765 loss=0.916010 error=0.722688 grad(V)=0.006993 grad(U)=0.000221\n",
      "downhill: Adam 766 loss=0.914587 error=0.721313 grad(V)=0.006930 grad(U)=0.000220\n",
      "downhill: Adam 767 loss=0.913169 error=0.719942 grad(V)=0.006866 grad(U)=0.000219\n",
      "downhill: Adam 768 loss=0.911756 error=0.718577 grad(V)=0.006803 grad(U)=0.000217\n",
      "downhill: Adam 769 loss=0.910349 error=0.717218 grad(V)=0.006741 grad(U)=0.000216\n",
      "downhill: Adam 770 loss=0.908947 error=0.715864 grad(V)=0.006679 grad(U)=0.000215\n",
      "downhill: validation 77 loss=0.907551 error=0.714515 grad(V)=0.006618 grad(U)=0.000214 *\n",
      "downhill: Adam 771 loss=0.907551 error=0.714515 grad(V)=0.006618 grad(U)=0.000214\n",
      "downhill: Adam 772 loss=0.906160 error=0.713172 grad(V)=0.006557 grad(U)=0.000212\n",
      "downhill: Adam 773 loss=0.904775 error=0.711834 grad(V)=0.006496 grad(U)=0.000211\n",
      "downhill: Adam 774 loss=0.903395 error=0.710502 grad(V)=0.006437 grad(U)=0.000210\n",
      "downhill: Adam 775 loss=0.902020 error=0.709175 grad(V)=0.006377 grad(U)=0.000209\n",
      "downhill: Adam 776 loss=0.900651 error=0.707853 grad(V)=0.006318 grad(U)=0.000208\n",
      "downhill: Adam 777 loss=0.899287 error=0.706536 grad(V)=0.006260 grad(U)=0.000206\n",
      "downhill: Adam 778 loss=0.897928 error=0.705225 grad(V)=0.006202 grad(U)=0.000205\n",
      "downhill: Adam 779 loss=0.896574 error=0.703919 grad(V)=0.006145 grad(U)=0.000204\n",
      "downhill: Adam 780 loss=0.895225 error=0.702617 grad(V)=0.006088 grad(U)=0.000203\n",
      "downhill: validation 78 loss=0.893882 error=0.701321 grad(V)=0.006032 grad(U)=0.000202 *\n",
      "downhill: Adam 781 loss=0.893882 error=0.701321 grad(V)=0.006032 grad(U)=0.000202\n",
      "downhill: Adam 782 loss=0.892544 error=0.700031 grad(V)=0.005976 grad(U)=0.000201\n",
      "downhill: Adam 783 loss=0.891210 error=0.698745 grad(V)=0.005921 grad(U)=0.000199\n",
      "downhill: Adam 784 loss=0.889882 error=0.697464 grad(V)=0.005866 grad(U)=0.000198\n",
      "downhill: Adam 785 loss=0.888559 error=0.696188 grad(V)=0.005811 grad(U)=0.000197\n",
      "downhill: Adam 786 loss=0.887241 error=0.694918 grad(V)=0.005757 grad(U)=0.000196\n",
      "downhill: Adam 787 loss=0.885929 error=0.693652 grad(V)=0.005704 grad(U)=0.000195\n",
      "downhill: Adam 788 loss=0.884621 error=0.692391 grad(V)=0.005651 grad(U)=0.000194\n",
      "downhill: Adam 789 loss=0.883318 error=0.691135 grad(V)=0.005598 grad(U)=0.000193\n",
      "downhill: Adam 790 loss=0.882020 error=0.689884 grad(V)=0.005546 grad(U)=0.000191\n",
      "downhill: validation 79 loss=0.880727 error=0.688638 grad(V)=0.005495 grad(U)=0.000190 *\n",
      "downhill: Adam 791 loss=0.880727 error=0.688638 grad(V)=0.005495 grad(U)=0.000190\n",
      "downhill: Adam 792 loss=0.879438 error=0.687396 grad(V)=0.005444 grad(U)=0.000189\n",
      "downhill: Adam 793 loss=0.878155 error=0.686160 grad(V)=0.005393 grad(U)=0.000188\n",
      "downhill: Adam 794 loss=0.876876 error=0.684928 grad(V)=0.005343 grad(U)=0.000187\n",
      "downhill: Adam 795 loss=0.875602 error=0.683701 grad(V)=0.005293 grad(U)=0.000186\n",
      "downhill: Adam 796 loss=0.874333 error=0.682479 grad(V)=0.005243 grad(U)=0.000185\n",
      "downhill: Adam 797 loss=0.873068 error=0.681261 grad(V)=0.005195 grad(U)=0.000184\n",
      "downhill: Adam 798 loss=0.871808 error=0.680048 grad(V)=0.005146 grad(U)=0.000183\n",
      "downhill: Adam 799 loss=0.870553 error=0.678840 grad(V)=0.005098 grad(U)=0.000182\n",
      "downhill: Adam 800 loss=0.869302 error=0.677636 grad(V)=0.005050 grad(U)=0.000181\n",
      "downhill: validation 80 loss=0.868056 error=0.676437 grad(V)=0.005003 grad(U)=0.000180 *\n",
      "downhill: Adam 801 loss=0.868056 error=0.676437 grad(V)=0.005003 grad(U)=0.000180\n",
      "downhill: Adam 802 loss=0.866815 error=0.675243 grad(V)=0.004956 grad(U)=0.000179\n",
      "downhill: Adam 803 loss=0.865578 error=0.674053 grad(V)=0.004910 grad(U)=0.000178\n",
      "downhill: Adam 804 loss=0.864345 error=0.672867 grad(V)=0.004864 grad(U)=0.000177\n",
      "downhill: Adam 805 loss=0.863117 error=0.671686 grad(V)=0.004819 grad(U)=0.000176\n",
      "downhill: Adam 806 loss=0.861894 error=0.670509 grad(V)=0.004773 grad(U)=0.000175\n",
      "downhill: Adam 807 loss=0.860675 error=0.669337 grad(V)=0.004729 grad(U)=0.000174\n",
      "downhill: Adam 808 loss=0.859460 error=0.668169 grad(V)=0.004684 grad(U)=0.000173\n",
      "downhill: Adam 809 loss=0.858250 error=0.667006 grad(V)=0.004641 grad(U)=0.000172\n",
      "downhill: Adam 810 loss=0.857045 error=0.665847 grad(V)=0.004597 grad(U)=0.000171\n",
      "downhill: validation 81 loss=0.855844 error=0.664692 grad(V)=0.004554 grad(U)=0.000170 *\n",
      "downhill: Adam 811 loss=0.855844 error=0.664692 grad(V)=0.004554 grad(U)=0.000170\n",
      "downhill: Adam 812 loss=0.854647 error=0.663542 grad(V)=0.004511 grad(U)=0.000169\n",
      "downhill: Adam 813 loss=0.853454 error=0.662396 grad(V)=0.004469 grad(U)=0.000168\n",
      "downhill: Adam 814 loss=0.852265 error=0.661254 grad(V)=0.004427 grad(U)=0.000167\n",
      "downhill: Adam 815 loss=0.851081 error=0.660116 grad(V)=0.004386 grad(U)=0.000166\n",
      "downhill: Adam 816 loss=0.849902 error=0.658982 grad(V)=0.004344 grad(U)=0.000165\n",
      "downhill: Adam 817 loss=0.848726 error=0.657853 grad(V)=0.004304 grad(U)=0.000164\n",
      "downhill: Adam 818 loss=0.847554 error=0.656728 grad(V)=0.004263 grad(U)=0.000163\n",
      "downhill: Adam 819 loss=0.846387 error=0.655607 grad(V)=0.004223 grad(U)=0.000162\n",
      "downhill: Adam 820 loss=0.845224 error=0.654490 grad(V)=0.004184 grad(U)=0.000161\n",
      "downhill: validation 82 loss=0.844065 error=0.653377 grad(V)=0.004144 grad(U)=0.000161 *\n",
      "downhill: Adam 821 loss=0.844065 error=0.653377 grad(V)=0.004144 grad(U)=0.000161\n",
      "downhill: Adam 822 loss=0.842910 error=0.652269 grad(V)=0.004106 grad(U)=0.000160\n",
      "downhill: Adam 823 loss=0.841759 error=0.651164 grad(V)=0.004067 grad(U)=0.000159\n",
      "downhill: Adam 824 loss=0.840613 error=0.650063 grad(V)=0.004029 grad(U)=0.000158\n",
      "downhill: Adam 825 loss=0.839470 error=0.648966 grad(V)=0.003991 grad(U)=0.000157\n",
      "downhill: Adam 826 loss=0.838332 error=0.647874 grad(V)=0.003954 grad(U)=0.000156\n",
      "downhill: Adam 827 loss=0.837197 error=0.646785 grad(V)=0.003917 grad(U)=0.000155\n",
      "downhill: Adam 828 loss=0.836066 error=0.645700 grad(V)=0.003880 grad(U)=0.000154\n",
      "downhill: Adam 829 loss=0.834939 error=0.644619 grad(V)=0.003844 grad(U)=0.000153\n",
      "downhill: Adam 830 loss=0.833817 error=0.643542 grad(V)=0.003808 grad(U)=0.000152\n",
      "downhill: validation 83 loss=0.832698 error=0.642468 grad(V)=0.003772 grad(U)=0.000152 *\n",
      "downhill: Adam 831 loss=0.832698 error=0.642468 grad(V)=0.003772 grad(U)=0.000152\n",
      "downhill: Adam 832 loss=0.831583 error=0.641399 grad(V)=0.003737 grad(U)=0.000151\n",
      "downhill: Adam 833 loss=0.830471 error=0.640333 grad(V)=0.003702 grad(U)=0.000150\n",
      "downhill: Adam 834 loss=0.829364 error=0.639272 grad(V)=0.003667 grad(U)=0.000149\n",
      "downhill: Adam 835 loss=0.828260 error=0.638214 grad(V)=0.003633 grad(U)=0.000148\n",
      "downhill: Adam 836 loss=0.827160 error=0.637159 grad(V)=0.003599 grad(U)=0.000147\n",
      "downhill: Adam 837 loss=0.826064 error=0.636108 grad(V)=0.003565 grad(U)=0.000147\n",
      "downhill: Adam 838 loss=0.824971 error=0.635061 grad(V)=0.003532 grad(U)=0.000146\n",
      "downhill: Adam 839 loss=0.823882 error=0.634018 grad(V)=0.003499 grad(U)=0.000145\n",
      "downhill: Adam 840 loss=0.822797 error=0.632978 grad(V)=0.003466 grad(U)=0.000144\n",
      "downhill: validation 84 loss=0.821716 error=0.631942 grad(V)=0.003434 grad(U)=0.000143 *\n",
      "downhill: Adam 841 loss=0.821716 error=0.631942 grad(V)=0.003434 grad(U)=0.000143\n",
      "downhill: Adam 842 loss=0.820638 error=0.630910 grad(V)=0.003402 grad(U)=0.000143\n",
      "downhill: Adam 843 loss=0.819563 error=0.629881 grad(V)=0.003370 grad(U)=0.000142\n",
      "downhill: Adam 844 loss=0.818493 error=0.628855 grad(V)=0.003339 grad(U)=0.000141\n",
      "downhill: Adam 845 loss=0.817426 error=0.627834 grad(V)=0.003308 grad(U)=0.000140\n",
      "downhill: Adam 846 loss=0.816362 error=0.626815 grad(V)=0.003277 grad(U)=0.000139\n",
      "downhill: Adam 847 loss=0.815302 error=0.625800 grad(V)=0.003246 grad(U)=0.000139\n",
      "downhill: Adam 848 loss=0.814245 error=0.624789 grad(V)=0.003216 grad(U)=0.000138\n",
      "downhill: Adam 849 loss=0.813192 error=0.623781 grad(V)=0.003186 grad(U)=0.000137\n",
      "downhill: Adam 850 loss=0.812143 error=0.622776 grad(V)=0.003157 grad(U)=0.000136\n",
      "downhill: validation 85 loss=0.811097 error=0.621775 grad(V)=0.003128 grad(U)=0.000135 *\n",
      "downhill: Adam 851 loss=0.811097 error=0.621775 grad(V)=0.003128 grad(U)=0.000135\n",
      "downhill: Adam 852 loss=0.810054 error=0.620777 grad(V)=0.003099 grad(U)=0.000135\n",
      "downhill: Adam 853 loss=0.809015 error=0.619783 grad(V)=0.003070 grad(U)=0.000134\n",
      "downhill: Adam 854 loss=0.807979 error=0.618792 grad(V)=0.003042 grad(U)=0.000133\n",
      "downhill: Adam 855 loss=0.806946 error=0.617804 grad(V)=0.003014 grad(U)=0.000132\n",
      "downhill: Adam 856 loss=0.805917 error=0.616819 grad(V)=0.002986 grad(U)=0.000132\n",
      "downhill: Adam 857 loss=0.804890 error=0.615838 grad(V)=0.002959 grad(U)=0.000131\n",
      "downhill: Adam 858 loss=0.803868 error=0.614860 grad(V)=0.002931 grad(U)=0.000130\n",
      "downhill: Adam 859 loss=0.802848 error=0.613885 grad(V)=0.002904 grad(U)=0.000130\n",
      "downhill: Adam 860 loss=0.801831 error=0.612913 grad(V)=0.002878 grad(U)=0.000129\n",
      "downhill: validation 86 loss=0.800818 error=0.611945 grad(V)=0.002851 grad(U)=0.000128 *\n",
      "downhill: Adam 861 loss=0.800818 error=0.611945 grad(V)=0.002851 grad(U)=0.000128\n",
      "downhill: Adam 862 loss=0.799808 error=0.610979 grad(V)=0.002825 grad(U)=0.000127\n",
      "downhill: Adam 863 loss=0.798801 error=0.610017 grad(V)=0.002799 grad(U)=0.000127\n",
      "downhill: Adam 864 loss=0.797797 error=0.609058 grad(V)=0.002774 grad(U)=0.000126\n",
      "downhill: Adam 865 loss=0.796796 error=0.608102 grad(V)=0.002749 grad(U)=0.000125\n",
      "downhill: Adam 866 loss=0.795798 error=0.607149 grad(V)=0.002724 grad(U)=0.000125\n",
      "downhill: Adam 867 loss=0.794803 error=0.606199 grad(V)=0.002699 grad(U)=0.000124\n",
      "downhill: Adam 868 loss=0.793812 error=0.605252 grad(V)=0.002674 grad(U)=0.000123\n",
      "downhill: Adam 869 loss=0.792823 error=0.604308 grad(V)=0.002650 grad(U)=0.000123\n",
      "downhill: Adam 870 loss=0.791837 error=0.603367 grad(V)=0.002626 grad(U)=0.000122\n",
      "downhill: validation 87 loss=0.790855 error=0.602429 grad(V)=0.002602 grad(U)=0.000121 *\n",
      "downhill: Adam 871 loss=0.790855 error=0.602429 grad(V)=0.002602 grad(U)=0.000121\n",
      "downhill: Adam 872 loss=0.789875 error=0.601494 grad(V)=0.002579 grad(U)=0.000121\n",
      "downhill: Adam 873 loss=0.788898 error=0.600562 grad(V)=0.002556 grad(U)=0.000120\n",
      "downhill: Adam 874 loss=0.787924 error=0.599633 grad(V)=0.002532 grad(U)=0.000119\n",
      "downhill: Adam 875 loss=0.786953 error=0.598706 grad(V)=0.002510 grad(U)=0.000119\n",
      "downhill: Adam 876 loss=0.785985 error=0.597783 grad(V)=0.002487 grad(U)=0.000118\n",
      "downhill: Adam 877 loss=0.785019 error=0.596862 grad(V)=0.002465 grad(U)=0.000117\n",
      "downhill: Adam 878 loss=0.784056 error=0.595944 grad(V)=0.002443 grad(U)=0.000117\n",
      "downhill: Adam 879 loss=0.783097 error=0.595029 grad(V)=0.002421 grad(U)=0.000116\n",
      "downhill: Adam 880 loss=0.782140 error=0.594117 grad(V)=0.002399 grad(U)=0.000115\n",
      "downhill: validation 88 loss=0.781185 error=0.593208 grad(V)=0.002378 grad(U)=0.000115 *\n",
      "downhill: Adam 881 loss=0.781185 error=0.593208 grad(V)=0.002378 grad(U)=0.000115\n",
      "downhill: Adam 882 loss=0.780234 error=0.592301 grad(V)=0.002357 grad(U)=0.000114\n",
      "downhill: Adam 883 loss=0.779285 error=0.591397 grad(V)=0.002336 grad(U)=0.000114\n",
      "downhill: Adam 884 loss=0.778339 error=0.590496 grad(V)=0.002315 grad(U)=0.000113\n",
      "downhill: Adam 885 loss=0.777396 error=0.589597 grad(V)=0.002295 grad(U)=0.000112\n",
      "downhill: Adam 886 loss=0.776455 error=0.588701 grad(V)=0.002275 grad(U)=0.000112\n",
      "downhill: Adam 887 loss=0.775518 error=0.587808 grad(V)=0.002255 grad(U)=0.000111\n",
      "downhill: Adam 888 loss=0.774583 error=0.586917 grad(V)=0.002235 grad(U)=0.000110\n",
      "downhill: Adam 889 loss=0.773650 error=0.586029 grad(V)=0.002215 grad(U)=0.000110\n",
      "downhill: Adam 890 loss=0.772720 error=0.585144 grad(V)=0.002196 grad(U)=0.000109\n",
      "downhill: validation 89 loss=0.771793 error=0.584261 grad(V)=0.002177 grad(U)=0.000109 *\n",
      "downhill: Adam 891 loss=0.771793 error=0.584261 grad(V)=0.002177 grad(U)=0.000109\n",
      "downhill: Adam 892 loss=0.770868 error=0.583380 grad(V)=0.002158 grad(U)=0.000108\n",
      "downhill: Adam 893 loss=0.769946 error=0.582503 grad(V)=0.002139 grad(U)=0.000108\n",
      "downhill: Adam 894 loss=0.769026 error=0.581628 grad(V)=0.002121 grad(U)=0.000107\n",
      "downhill: Adam 895 loss=0.768109 error=0.580755 grad(V)=0.002102 grad(U)=0.000106\n",
      "downhill: Adam 896 loss=0.767194 error=0.579885 grad(V)=0.002084 grad(U)=0.000106\n",
      "downhill: Adam 897 loss=0.766282 error=0.579017 grad(V)=0.002066 grad(U)=0.000105\n",
      "downhill: Adam 898 loss=0.765372 error=0.578152 grad(V)=0.002048 grad(U)=0.000105\n",
      "downhill: Adam 899 loss=0.764465 error=0.577289 grad(V)=0.002031 grad(U)=0.000104\n",
      "downhill: Adam 900 loss=0.763560 error=0.576429 grad(V)=0.002013 grad(U)=0.000104\n",
      "downhill: validation 90 loss=0.762658 error=0.575571 grad(V)=0.001996 grad(U)=0.000103 *\n",
      "downhill: Adam 901 loss=0.762658 error=0.575571 grad(V)=0.001996 grad(U)=0.000103\n",
      "downhill: Adam 902 loss=0.761757 error=0.574715 grad(V)=0.001979 grad(U)=0.000102\n",
      "downhill: Adam 903 loss=0.760860 error=0.573862 grad(V)=0.001962 grad(U)=0.000102\n",
      "downhill: Adam 904 loss=0.759964 error=0.573011 grad(V)=0.001946 grad(U)=0.000101\n",
      "downhill: Adam 905 loss=0.759071 error=0.572162 grad(V)=0.001929 grad(U)=0.000101\n",
      "downhill: Adam 906 loss=0.758181 error=0.571316 grad(V)=0.001913 grad(U)=0.000100\n",
      "downhill: Adam 907 loss=0.757292 error=0.570472 grad(V)=0.001897 grad(U)=0.000100\n",
      "downhill: Adam 908 loss=0.756406 error=0.569630 grad(V)=0.001881 grad(U)=0.000099\n",
      "downhill: Adam 909 loss=0.755522 error=0.568791 grad(V)=0.001866 grad(U)=0.000099\n",
      "downhill: Adam 910 loss=0.754640 error=0.567954 grad(V)=0.001850 grad(U)=0.000098\n",
      "downhill: validation 91 loss=0.753761 error=0.567119 grad(V)=0.001835 grad(U)=0.000098 *\n",
      "downhill: Adam 911 loss=0.753761 error=0.567119 grad(V)=0.001835 grad(U)=0.000098\n",
      "downhill: Adam 912 loss=0.752883 error=0.566286 grad(V)=0.001819 grad(U)=0.000097\n",
      "downhill: Adam 913 loss=0.752008 error=0.565456 grad(V)=0.001804 grad(U)=0.000097\n",
      "downhill: Adam 914 loss=0.751135 error=0.564627 grad(V)=0.001790 grad(U)=0.000096\n",
      "downhill: Adam 915 loss=0.750264 error=0.563801 grad(V)=0.001775 grad(U)=0.000096\n",
      "downhill: Adam 916 loss=0.749396 error=0.562977 grad(V)=0.001760 grad(U)=0.000095\n",
      "downhill: Adam 917 loss=0.748529 error=0.562155 grad(V)=0.001746 grad(U)=0.000095\n",
      "downhill: Adam 918 loss=0.747665 error=0.561336 grad(V)=0.001732 grad(U)=0.000094\n",
      "downhill: Adam 919 loss=0.746803 error=0.560518 grad(V)=0.001718 grad(U)=0.000094\n",
      "downhill: Adam 920 loss=0.745943 error=0.559702 grad(V)=0.001704 grad(U)=0.000093\n",
      "downhill: validation 92 loss=0.745085 error=0.558889 grad(V)=0.001690 grad(U)=0.000093 *\n",
      "downhill: Adam 921 loss=0.745085 error=0.558889 grad(V)=0.001690 grad(U)=0.000093\n",
      "downhill: Adam 922 loss=0.744229 error=0.558078 grad(V)=0.001677 grad(U)=0.000092\n",
      "downhill: Adam 923 loss=0.743375 error=0.557268 grad(V)=0.001663 grad(U)=0.000092\n",
      "downhill: Adam 924 loss=0.742524 error=0.556461 grad(V)=0.001650 grad(U)=0.000091\n",
      "downhill: Adam 925 loss=0.741674 error=0.555656 grad(V)=0.001637 grad(U)=0.000091\n",
      "downhill: Adam 926 loss=0.740827 error=0.554853 grad(V)=0.001624 grad(U)=0.000090\n",
      "downhill: Adam 927 loss=0.739981 error=0.554052 grad(V)=0.001611 grad(U)=0.000090\n",
      "downhill: Adam 928 loss=0.739138 error=0.553253 grad(V)=0.001598 grad(U)=0.000089\n",
      "downhill: Adam 929 loss=0.738296 error=0.552456 grad(V)=0.001586 grad(U)=0.000089\n",
      "downhill: Adam 930 loss=0.737457 error=0.551660 grad(V)=0.001574 grad(U)=0.000088\n",
      "downhill: validation 93 loss=0.736619 error=0.550867 grad(V)=0.001561 grad(U)=0.000088 *\n",
      "downhill: Adam 931 loss=0.736619 error=0.550867 grad(V)=0.001561 grad(U)=0.000088\n",
      "downhill: Adam 932 loss=0.735783 error=0.550076 grad(V)=0.001549 grad(U)=0.000088\n",
      "downhill: Adam 933 loss=0.734950 error=0.549287 grad(V)=0.001537 grad(U)=0.000087\n",
      "downhill: Adam 934 loss=0.734118 error=0.548499 grad(V)=0.001525 grad(U)=0.000087\n",
      "downhill: Adam 935 loss=0.733288 error=0.547714 grad(V)=0.001514 grad(U)=0.000086\n",
      "downhill: Adam 936 loss=0.732460 error=0.546930 grad(V)=0.001502 grad(U)=0.000086\n",
      "downhill: Adam 937 loss=0.731634 error=0.546149 grad(V)=0.001491 grad(U)=0.000085\n",
      "downhill: Adam 938 loss=0.730810 error=0.545369 grad(V)=0.001479 grad(U)=0.000085\n",
      "downhill: Adam 939 loss=0.729987 error=0.544591 grad(V)=0.001468 grad(U)=0.000085\n",
      "downhill: Adam 940 loss=0.729167 error=0.543815 grad(V)=0.001457 grad(U)=0.000084\n",
      "downhill: validation 94 loss=0.728348 error=0.543040 grad(V)=0.001446 grad(U)=0.000084 *\n",
      "downhill: Adam 941 loss=0.728348 error=0.543040 grad(V)=0.001446 grad(U)=0.000084\n",
      "downhill: Adam 942 loss=0.727531 error=0.542268 grad(V)=0.001435 grad(U)=0.000083\n",
      "downhill: Adam 943 loss=0.726715 error=0.541497 grad(V)=0.001425 grad(U)=0.000083\n",
      "downhill: Adam 944 loss=0.725902 error=0.540728 grad(V)=0.001414 grad(U)=0.000082\n",
      "downhill: Adam 945 loss=0.725090 error=0.539961 grad(V)=0.001404 grad(U)=0.000082\n",
      "downhill: Adam 946 loss=0.724280 error=0.539196 grad(V)=0.001393 grad(U)=0.000082\n",
      "downhill: Adam 947 loss=0.723471 error=0.538432 grad(V)=0.001383 grad(U)=0.000081\n",
      "downhill: Adam 948 loss=0.722665 error=0.537671 grad(V)=0.001373 grad(U)=0.000081\n",
      "downhill: Adam 949 loss=0.721860 error=0.536910 grad(V)=0.001363 grad(U)=0.000080\n",
      "downhill: Adam 950 loss=0.721057 error=0.536152 grad(V)=0.001353 grad(U)=0.000080\n",
      "downhill: validation 95 loss=0.720255 error=0.535395 grad(V)=0.001343 grad(U)=0.000080 *\n",
      "downhill: Adam 951 loss=0.720255 error=0.535395 grad(V)=0.001343 grad(U)=0.000080\n",
      "downhill: Adam 952 loss=0.719456 error=0.534640 grad(V)=0.001334 grad(U)=0.000079\n",
      "downhill: Adam 953 loss=0.718657 error=0.533887 grad(V)=0.001324 grad(U)=0.000079\n",
      "downhill: Adam 954 loss=0.717861 error=0.533135 grad(V)=0.001315 grad(U)=0.000078\n",
      "downhill: Adam 955 loss=0.717066 error=0.532385 grad(V)=0.001305 grad(U)=0.000078\n",
      "downhill: Adam 956 loss=0.716273 error=0.531636 grad(V)=0.001296 grad(U)=0.000078\n",
      "downhill: Adam 957 loss=0.715482 error=0.530890 grad(V)=0.001287 grad(U)=0.000077\n",
      "downhill: Adam 958 loss=0.714692 error=0.530145 grad(V)=0.001278 grad(U)=0.000077\n",
      "downhill: Adam 959 loss=0.713903 error=0.529401 grad(V)=0.001269 grad(U)=0.000077\n",
      "downhill: Adam 960 loss=0.713116 error=0.528659 grad(V)=0.001260 grad(U)=0.000076\n",
      "downhill: validation 96 loss=0.712331 error=0.527919 grad(V)=0.001252 grad(U)=0.000076 *\n",
      "downhill: Adam 961 loss=0.712331 error=0.527919 grad(V)=0.001252 grad(U)=0.000076\n",
      "downhill: Adam 962 loss=0.711547 error=0.527180 grad(V)=0.001243 grad(U)=0.000075\n",
      "downhill: Adam 963 loss=0.710765 error=0.526443 grad(V)=0.001234 grad(U)=0.000075\n",
      "downhill: Adam 964 loss=0.709985 error=0.525708 grad(V)=0.001226 grad(U)=0.000075\n",
      "downhill: Adam 965 loss=0.709206 error=0.524974 grad(V)=0.001218 grad(U)=0.000074\n",
      "downhill: Adam 966 loss=0.708429 error=0.524242 grad(V)=0.001209 grad(U)=0.000074\n",
      "downhill: Adam 967 loss=0.707653 error=0.523511 grad(V)=0.001201 grad(U)=0.000074\n",
      "downhill: Adam 968 loss=0.706878 error=0.522782 grad(V)=0.001193 grad(U)=0.000073\n",
      "downhill: Adam 969 loss=0.706105 error=0.522054 grad(V)=0.001185 grad(U)=0.000073\n",
      "downhill: Adam 970 loss=0.705334 error=0.521328 grad(V)=0.001177 grad(U)=0.000073\n",
      "downhill: validation 97 loss=0.704564 error=0.520603 grad(V)=0.001169 grad(U)=0.000072 *\n",
      "downhill: Adam 971 loss=0.704564 error=0.520603 grad(V)=0.001169 grad(U)=0.000072\n",
      "downhill: Adam 972 loss=0.703796 error=0.519880 grad(V)=0.001162 grad(U)=0.000072\n",
      "downhill: Adam 973 loss=0.703029 error=0.519158 grad(V)=0.001154 grad(U)=0.000072\n",
      "downhill: Adam 974 loss=0.702263 error=0.518438 grad(V)=0.001147 grad(U)=0.000071\n",
      "downhill: Adam 975 loss=0.701499 error=0.517720 grad(V)=0.001139 grad(U)=0.000071\n",
      "downhill: Adam 976 loss=0.700736 error=0.517003 grad(V)=0.001132 grad(U)=0.000070\n",
      "downhill: Adam 977 loss=0.699975 error=0.516287 grad(V)=0.001124 grad(U)=0.000070\n",
      "downhill: Adam 978 loss=0.699215 error=0.515573 grad(V)=0.001117 grad(U)=0.000070\n",
      "downhill: Adam 979 loss=0.698457 error=0.514860 grad(V)=0.001110 grad(U)=0.000070\n",
      "downhill: Adam 980 loss=0.697699 error=0.514149 grad(V)=0.001103 grad(U)=0.000069\n",
      "downhill: validation 98 loss=0.696944 error=0.513439 grad(V)=0.001096 grad(U)=0.000069 *\n",
      "downhill: Adam 981 loss=0.696944 error=0.513439 grad(V)=0.001096 grad(U)=0.000069\n",
      "downhill: Adam 982 loss=0.696189 error=0.512730 grad(V)=0.001089 grad(U)=0.000069\n",
      "downhill: Adam 983 loss=0.695436 error=0.512023 grad(V)=0.001082 grad(U)=0.000068\n",
      "downhill: Adam 984 loss=0.694685 error=0.511318 grad(V)=0.001075 grad(U)=0.000068\n",
      "downhill: Adam 985 loss=0.693935 error=0.510613 grad(V)=0.001069 grad(U)=0.000068\n",
      "downhill: Adam 986 loss=0.693186 error=0.509911 grad(V)=0.001062 grad(U)=0.000067\n",
      "downhill: Adam 987 loss=0.692439 error=0.509209 grad(V)=0.001055 grad(U)=0.000067\n",
      "downhill: Adam 988 loss=0.691693 error=0.508509 grad(V)=0.001049 grad(U)=0.000067\n",
      "downhill: Adam 989 loss=0.690948 error=0.507810 grad(V)=0.001043 grad(U)=0.000066\n",
      "downhill: Adam 990 loss=0.690205 error=0.507113 grad(V)=0.001036 grad(U)=0.000066\n",
      "downhill: validation 99 loss=0.689463 error=0.506417 grad(V)=0.001030 grad(U)=0.000066 *\n",
      "downhill: Adam 991 loss=0.689463 error=0.506417 grad(V)=0.001030 grad(U)=0.000066\n",
      "downhill: Adam 992 loss=0.688723 error=0.505722 grad(V)=0.001024 grad(U)=0.000065\n",
      "downhill: Adam 993 loss=0.687984 error=0.505029 grad(V)=0.001017 grad(U)=0.000065\n",
      "downhill: Adam 994 loss=0.687246 error=0.504338 grad(V)=0.001011 grad(U)=0.000065\n",
      "downhill: Adam 995 loss=0.686510 error=0.503647 grad(V)=0.001005 grad(U)=0.000064\n",
      "downhill: Adam 996 loss=0.685774 error=0.502958 grad(V)=0.000999 grad(U)=0.000064\n",
      "downhill: Adam 997 loss=0.685040 error=0.502270 grad(V)=0.000993 grad(U)=0.000064\n",
      "downhill: Adam 998 loss=0.684308 error=0.501584 grad(V)=0.000988 grad(U)=0.000064\n",
      "downhill: Adam 999 loss=0.683577 error=0.500899 grad(V)=0.000982 grad(U)=0.000063\n",
      "downhill: Adam 1000 loss=0.682847 error=0.500215 grad(V)=0.000976 grad(U)=0.000063\n",
      "downhill: validation 100 loss=0.682118 error=0.499533 grad(V)=0.000970 grad(U)=0.000063 *\n",
      "downhill: Adam 1001 loss=0.682118 error=0.499533 grad(V)=0.000970 grad(U)=0.000063\n",
      "downhill: Adam 1002 loss=0.681390 error=0.498852 grad(V)=0.000965 grad(U)=0.000062\n",
      "downhill: Adam 1003 loss=0.680664 error=0.498172 grad(V)=0.000959 grad(U)=0.000062\n",
      "downhill: Adam 1004 loss=0.679939 error=0.497493 grad(V)=0.000954 grad(U)=0.000062\n",
      "downhill: Adam 1005 loss=0.679215 error=0.496816 grad(V)=0.000948 grad(U)=0.000062\n",
      "downhill: Adam 1006 loss=0.678493 error=0.496140 grad(V)=0.000943 grad(U)=0.000061\n",
      "downhill: Adam 1007 loss=0.677772 error=0.495465 grad(V)=0.000937 grad(U)=0.000061\n",
      "downhill: Adam 1008 loss=0.677052 error=0.494792 grad(V)=0.000932 grad(U)=0.000061\n",
      "downhill: Adam 1009 loss=0.676333 error=0.494120 grad(V)=0.000927 grad(U)=0.000061\n",
      "downhill: Adam 1010 loss=0.675616 error=0.493449 grad(V)=0.000922 grad(U)=0.000060\n",
      "downhill: validation 101 loss=0.674899 error=0.492780 grad(V)=0.000916 grad(U)=0.000060 *\n",
      "downhill: Adam 1011 loss=0.674899 error=0.492780 grad(V)=0.000916 grad(U)=0.000060\n",
      "downhill: Adam 1012 loss=0.674184 error=0.492111 grad(V)=0.000911 grad(U)=0.000060\n",
      "downhill: Adam 1013 loss=0.673470 error=0.491445 grad(V)=0.000906 grad(U)=0.000059\n",
      "downhill: Adam 1014 loss=0.672757 error=0.490779 grad(V)=0.000901 grad(U)=0.000059\n",
      "downhill: Adam 1015 loss=0.672046 error=0.490115 grad(V)=0.000896 grad(U)=0.000059\n",
      "downhill: Adam 1016 loss=0.671335 error=0.489451 grad(V)=0.000891 grad(U)=0.000059\n",
      "downhill: Adam 1017 loss=0.670626 error=0.488789 grad(V)=0.000886 grad(U)=0.000058\n",
      "downhill: Adam 1018 loss=0.669918 error=0.488129 grad(V)=0.000882 grad(U)=0.000058\n",
      "downhill: Adam 1019 loss=0.669211 error=0.487469 grad(V)=0.000877 grad(U)=0.000058\n",
      "downhill: Adam 1020 loss=0.668506 error=0.486811 grad(V)=0.000872 grad(U)=0.000058\n",
      "downhill: validation 102 loss=0.667801 error=0.486154 grad(V)=0.000867 grad(U)=0.000057 *\n",
      "downhill: Adam 1021 loss=0.667801 error=0.486154 grad(V)=0.000867 grad(U)=0.000057\n",
      "downhill: Adam 1022 loss=0.667098 error=0.485498 grad(V)=0.000863 grad(U)=0.000057\n",
      "downhill: Adam 1023 loss=0.666396 error=0.484844 grad(V)=0.000858 grad(U)=0.000057\n",
      "downhill: Adam 1024 loss=0.665695 error=0.484190 grad(V)=0.000853 grad(U)=0.000057\n",
      "downhill: Adam 1025 loss=0.664995 error=0.483538 grad(V)=0.000849 grad(U)=0.000056\n",
      "downhill: Adam 1026 loss=0.664297 error=0.482887 grad(V)=0.000844 grad(U)=0.000056\n",
      "downhill: Adam 1027 loss=0.663599 error=0.482237 grad(V)=0.000840 grad(U)=0.000056\n",
      "downhill: Adam 1028 loss=0.662903 error=0.481589 grad(V)=0.000835 grad(U)=0.000056\n",
      "downhill: Adam 1029 loss=0.662208 error=0.480941 grad(V)=0.000831 grad(U)=0.000055\n",
      "downhill: Adam 1030 loss=0.661514 error=0.480295 grad(V)=0.000827 grad(U)=0.000055\n",
      "downhill: validation 103 loss=0.660821 error=0.479650 grad(V)=0.000822 grad(U)=0.000055 *\n",
      "downhill: Adam 1031 loss=0.660821 error=0.479650 grad(V)=0.000822 grad(U)=0.000055\n",
      "downhill: Adam 1032 loss=0.660129 error=0.479006 grad(V)=0.000818 grad(U)=0.000055\n",
      "downhill: Adam 1033 loss=0.659439 error=0.478364 grad(V)=0.000814 grad(U)=0.000055\n",
      "downhill: Adam 1034 loss=0.658749 error=0.477723 grad(V)=0.000810 grad(U)=0.000054\n",
      "downhill: Adam 1035 loss=0.658060 error=0.477082 grad(V)=0.000805 grad(U)=0.000054\n",
      "downhill: Adam 1036 loss=0.657373 error=0.476443 grad(V)=0.000801 grad(U)=0.000054\n",
      "downhill: Adam 1037 loss=0.656687 error=0.475805 grad(V)=0.000797 grad(U)=0.000054\n",
      "downhill: Adam 1038 loss=0.656002 error=0.475169 grad(V)=0.000793 grad(U)=0.000053\n",
      "downhill: Adam 1039 loss=0.655318 error=0.474533 grad(V)=0.000789 grad(U)=0.000053\n",
      "downhill: Adam 1040 loss=0.654635 error=0.473899 grad(V)=0.000785 grad(U)=0.000053\n",
      "downhill: validation 104 loss=0.653953 error=0.473266 grad(V)=0.000781 grad(U)=0.000053 *\n",
      "downhill: Adam 1041 loss=0.653953 error=0.473266 grad(V)=0.000781 grad(U)=0.000053\n",
      "downhill: Adam 1042 loss=0.653272 error=0.472634 grad(V)=0.000777 grad(U)=0.000052\n",
      "downhill: Adam 1043 loss=0.652593 error=0.472003 grad(V)=0.000773 grad(U)=0.000052\n",
      "downhill: Adam 1044 loss=0.651915 error=0.471374 grad(V)=0.000769 grad(U)=0.000052\n",
      "downhill: Adam 1045 loss=0.651237 error=0.470745 grad(V)=0.000765 grad(U)=0.000052\n",
      "downhill: Adam 1046 loss=0.650561 error=0.470118 grad(V)=0.000762 grad(U)=0.000052\n",
      "downhill: Adam 1047 loss=0.649886 error=0.469492 grad(V)=0.000758 grad(U)=0.000051\n",
      "downhill: Adam 1048 loss=0.649212 error=0.468867 grad(V)=0.000754 grad(U)=0.000051\n",
      "downhill: Adam 1049 loss=0.648540 error=0.468243 grad(V)=0.000750 grad(U)=0.000051\n",
      "downhill: Adam 1050 loss=0.647868 error=0.467621 grad(V)=0.000747 grad(U)=0.000051\n",
      "downhill: validation 105 loss=0.647197 error=0.467000 grad(V)=0.000743 grad(U)=0.000050 *\n",
      "downhill: Adam 1051 loss=0.647197 error=0.467000 grad(V)=0.000743 grad(U)=0.000050\n",
      "downhill: Adam 1052 loss=0.646528 error=0.466379 grad(V)=0.000739 grad(U)=0.000050\n",
      "downhill: Adam 1053 loss=0.645859 error=0.465760 grad(V)=0.000736 grad(U)=0.000050\n",
      "downhill: Adam 1054 loss=0.645192 error=0.465142 grad(V)=0.000732 grad(U)=0.000050\n",
      "downhill: Adam 1055 loss=0.644526 error=0.464526 grad(V)=0.000728 grad(U)=0.000050\n",
      "downhill: Adam 1056 loss=0.643861 error=0.463910 grad(V)=0.000725 grad(U)=0.000049\n",
      "downhill: Adam 1057 loss=0.643198 error=0.463296 grad(V)=0.000721 grad(U)=0.000049\n",
      "downhill: Adam 1058 loss=0.642535 error=0.462683 grad(V)=0.000718 grad(U)=0.000049\n",
      "downhill: Adam 1059 loss=0.641873 error=0.462071 grad(V)=0.000714 grad(U)=0.000049\n",
      "downhill: Adam 1060 loss=0.641213 error=0.461460 grad(V)=0.000711 grad(U)=0.000049\n",
      "downhill: validation 106 loss=0.640553 error=0.460850 grad(V)=0.000707 grad(U)=0.000048 *\n",
      "downhill: Adam 1061 loss=0.640553 error=0.460850 grad(V)=0.000707 grad(U)=0.000048\n",
      "downhill: Adam 1062 loss=0.639895 error=0.460242 grad(V)=0.000704 grad(U)=0.000048\n",
      "downhill: Adam 1063 loss=0.639238 error=0.459634 grad(V)=0.000701 grad(U)=0.000048\n",
      "downhill: Adam 1064 loss=0.638582 error=0.459028 grad(V)=0.000697 grad(U)=0.000048\n",
      "downhill: Adam 1065 loss=0.637927 error=0.458423 grad(V)=0.000694 grad(U)=0.000048\n",
      "downhill: Adam 1066 loss=0.637273 error=0.457819 grad(V)=0.000690 grad(U)=0.000047\n",
      "downhill: Adam 1067 loss=0.636621 error=0.457216 grad(V)=0.000687 grad(U)=0.000047\n",
      "downhill: Adam 1068 loss=0.635969 error=0.456615 grad(V)=0.000684 grad(U)=0.000047\n",
      "downhill: Adam 1069 loss=0.635318 error=0.456014 grad(V)=0.000681 grad(U)=0.000047\n",
      "downhill: Adam 1070 loss=0.634669 error=0.455415 grad(V)=0.000677 grad(U)=0.000047\n",
      "downhill: validation 107 loss=0.634020 error=0.454817 grad(V)=0.000674 grad(U)=0.000047 *\n",
      "downhill: Adam 1071 loss=0.634020 error=0.454817 grad(V)=0.000674 grad(U)=0.000047\n",
      "downhill: Adam 1072 loss=0.633373 error=0.454220 grad(V)=0.000671 grad(U)=0.000046\n",
      "downhill: Adam 1073 loss=0.632726 error=0.453624 grad(V)=0.000668 grad(U)=0.000046\n",
      "downhill: Adam 1074 loss=0.632081 error=0.453029 grad(V)=0.000665 grad(U)=0.000046\n",
      "downhill: Adam 1075 loss=0.631437 error=0.452436 grad(V)=0.000661 grad(U)=0.000046\n",
      "downhill: Adam 1076 loss=0.630793 error=0.451843 grad(V)=0.000658 grad(U)=0.000046\n",
      "downhill: Adam 1077 loss=0.630151 error=0.451252 grad(V)=0.000655 grad(U)=0.000045\n",
      "downhill: Adam 1078 loss=0.629510 error=0.450662 grad(V)=0.000652 grad(U)=0.000045\n",
      "downhill: Adam 1079 loss=0.628870 error=0.450073 grad(V)=0.000649 grad(U)=0.000045\n",
      "downhill: Adam 1080 loss=0.628231 error=0.449485 grad(V)=0.000646 grad(U)=0.000045\n",
      "downhill: validation 108 loss=0.627593 error=0.448898 grad(V)=0.000643 grad(U)=0.000045 *\n",
      "downhill: Adam 1081 loss=0.627593 error=0.448898 grad(V)=0.000643 grad(U)=0.000045\n",
      "downhill: Adam 1082 loss=0.626956 error=0.448313 grad(V)=0.000640 grad(U)=0.000045\n",
      "downhill: Adam 1083 loss=0.626320 error=0.447728 grad(V)=0.000637 grad(U)=0.000044\n",
      "downhill: Adam 1084 loss=0.625685 error=0.447145 grad(V)=0.000634 grad(U)=0.000044\n",
      "downhill: Adam 1085 loss=0.625052 error=0.446563 grad(V)=0.000631 grad(U)=0.000044\n",
      "downhill: Adam 1086 loss=0.624419 error=0.445982 grad(V)=0.000628 grad(U)=0.000044\n",
      "downhill: Adam 1087 loss=0.623787 error=0.445402 grad(V)=0.000625 grad(U)=0.000044\n",
      "downhill: Adam 1088 loss=0.623156 error=0.444823 grad(V)=0.000622 grad(U)=0.000044\n",
      "downhill: Adam 1089 loss=0.622527 error=0.444246 grad(V)=0.000619 grad(U)=0.000043\n",
      "downhill: Adam 1090 loss=0.621898 error=0.443669 grad(V)=0.000616 grad(U)=0.000043\n",
      "downhill: validation 109 loss=0.621270 error=0.443094 grad(V)=0.000614 grad(U)=0.000043 *\n",
      "downhill: Adam 1091 loss=0.621270 error=0.443094 grad(V)=0.000614 grad(U)=0.000043\n",
      "downhill: Adam 1092 loss=0.620644 error=0.442520 grad(V)=0.000611 grad(U)=0.000043\n",
      "downhill: Adam 1093 loss=0.620018 error=0.441947 grad(V)=0.000608 grad(U)=0.000043\n",
      "downhill: Adam 1094 loss=0.619394 error=0.441375 grad(V)=0.000605 grad(U)=0.000042\n",
      "downhill: Adam 1095 loss=0.618770 error=0.440804 grad(V)=0.000602 grad(U)=0.000042\n",
      "downhill: Adam 1096 loss=0.618148 error=0.440235 grad(V)=0.000599 grad(U)=0.000042\n",
      "downhill: Adam 1097 loss=0.617526 error=0.439666 grad(V)=0.000597 grad(U)=0.000042\n",
      "downhill: Adam 1098 loss=0.616906 error=0.439099 grad(V)=0.000594 grad(U)=0.000042\n",
      "downhill: Adam 1099 loss=0.616287 error=0.438533 grad(V)=0.000591 grad(U)=0.000042\n",
      "downhill: Adam 1100 loss=0.615668 error=0.437967 grad(V)=0.000588 grad(U)=0.000042\n",
      "downhill: validation 110 loss=0.615051 error=0.437403 grad(V)=0.000586 grad(U)=0.000041 *\n",
      "downhill: Adam 1101 loss=0.615051 error=0.437403 grad(V)=0.000586 grad(U)=0.000041\n",
      "downhill: Adam 1102 loss=0.614435 error=0.436841 grad(V)=0.000583 grad(U)=0.000041\n",
      "downhill: Adam 1103 loss=0.613819 error=0.436279 grad(V)=0.000580 grad(U)=0.000041\n",
      "downhill: Adam 1104 loss=0.613205 error=0.435718 grad(V)=0.000578 grad(U)=0.000041\n",
      "downhill: Adam 1105 loss=0.612592 error=0.435159 grad(V)=0.000575 grad(U)=0.000041\n",
      "downhill: Adam 1106 loss=0.611979 error=0.434600 grad(V)=0.000572 grad(U)=0.000041\n",
      "downhill: Adam 1107 loss=0.611368 error=0.434043 grad(V)=0.000570 grad(U)=0.000040\n",
      "downhill: Adam 1108 loss=0.610758 error=0.433487 grad(V)=0.000567 grad(U)=0.000040\n",
      "downhill: Adam 1109 loss=0.610150 error=0.432932 grad(V)=0.000564 grad(U)=0.000040\n",
      "downhill: Adam 1110 loss=0.609542 error=0.432378 grad(V)=0.000562 grad(U)=0.000040\n",
      "downhill: validation 111 loss=0.608935 error=0.431825 grad(V)=0.000559 grad(U)=0.000040 *\n",
      "downhill: Adam 1111 loss=0.608935 error=0.431825 grad(V)=0.000559 grad(U)=0.000040\n",
      "downhill: Adam 1112 loss=0.608329 error=0.431273 grad(V)=0.000557 grad(U)=0.000040\n",
      "downhill: Adam 1113 loss=0.607725 error=0.430723 grad(V)=0.000554 grad(U)=0.000039\n",
      "downhill: Adam 1114 loss=0.607121 error=0.430174 grad(V)=0.000551 grad(U)=0.000039\n",
      "downhill: Adam 1115 loss=0.606518 error=0.429625 grad(V)=0.000549 grad(U)=0.000039\n",
      "downhill: Adam 1116 loss=0.605917 error=0.429078 grad(V)=0.000546 grad(U)=0.000039\n",
      "downhill: Adam 1117 loss=0.605316 error=0.428532 grad(V)=0.000544 grad(U)=0.000039\n",
      "downhill: Adam 1118 loss=0.604716 error=0.427988 grad(V)=0.000541 grad(U)=0.000039\n",
      "downhill: Adam 1119 loss=0.604118 error=0.427444 grad(V)=0.000539 grad(U)=0.000039\n",
      "downhill: Adam 1120 loss=0.603521 error=0.426901 grad(V)=0.000536 grad(U)=0.000038\n",
      "downhill: validation 112 loss=0.602924 error=0.426360 grad(V)=0.000534 grad(U)=0.000038 *\n",
      "downhill: Adam 1121 loss=0.602924 error=0.426360 grad(V)=0.000534 grad(U)=0.000038\n",
      "downhill: Adam 1122 loss=0.602329 error=0.425819 grad(V)=0.000531 grad(U)=0.000038\n",
      "downhill: Adam 1123 loss=0.601734 error=0.425280 grad(V)=0.000529 grad(U)=0.000038\n",
      "downhill: Adam 1124 loss=0.601141 error=0.424742 grad(V)=0.000526 grad(U)=0.000038\n",
      "downhill: Adam 1125 loss=0.600548 error=0.424205 grad(V)=0.000524 grad(U)=0.000038\n",
      "downhill: Adam 1126 loss=0.599957 error=0.423669 grad(V)=0.000521 grad(U)=0.000038\n",
      "downhill: Adam 1127 loss=0.599366 error=0.423135 grad(V)=0.000519 grad(U)=0.000037\n",
      "downhill: Adam 1128 loss=0.598777 error=0.422601 grad(V)=0.000516 grad(U)=0.000037\n",
      "downhill: Adam 1129 loss=0.598188 error=0.422068 grad(V)=0.000514 grad(U)=0.000037\n",
      "downhill: Adam 1130 loss=0.597601 error=0.421537 grad(V)=0.000511 grad(U)=0.000037\n",
      "downhill: validation 113 loss=0.597015 error=0.421007 grad(V)=0.000509 grad(U)=0.000037 *\n",
      "downhill: Adam 1131 loss=0.597015 error=0.421007 grad(V)=0.000509 grad(U)=0.000037\n",
      "downhill: Adam 1132 loss=0.596429 error=0.420478 grad(V)=0.000507 grad(U)=0.000037\n",
      "downhill: Adam 1133 loss=0.595845 error=0.419950 grad(V)=0.000504 grad(U)=0.000037\n",
      "downhill: Adam 1134 loss=0.595262 error=0.419423 grad(V)=0.000502 grad(U)=0.000037\n",
      "downhill: Adam 1135 loss=0.594680 error=0.418897 grad(V)=0.000499 grad(U)=0.000036\n",
      "downhill: Adam 1136 loss=0.594098 error=0.418372 grad(V)=0.000497 grad(U)=0.000036\n",
      "downhill: Adam 1137 loss=0.593518 error=0.417849 grad(V)=0.000495 grad(U)=0.000036\n",
      "downhill: Adam 1138 loss=0.592939 error=0.417327 grad(V)=0.000492 grad(U)=0.000036\n",
      "downhill: Adam 1139 loss=0.592361 error=0.416805 grad(V)=0.000490 grad(U)=0.000036\n",
      "downhill: Adam 1140 loss=0.591784 error=0.416285 grad(V)=0.000488 grad(U)=0.000036\n",
      "downhill: validation 114 loss=0.591208 error=0.415766 grad(V)=0.000485 grad(U)=0.000036 *\n",
      "downhill: Adam 1141 loss=0.591208 error=0.415766 grad(V)=0.000485 grad(U)=0.000036\n",
      "downhill: Adam 1142 loss=0.590633 error=0.415248 grad(V)=0.000483 grad(U)=0.000035\n",
      "downhill: Adam 1143 loss=0.590059 error=0.414731 grad(V)=0.000481 grad(U)=0.000035\n",
      "downhill: Adam 1144 loss=0.589486 error=0.414215 grad(V)=0.000478 grad(U)=0.000035\n",
      "downhill: Adam 1145 loss=0.588914 error=0.413701 grad(V)=0.000476 grad(U)=0.000035\n",
      "downhill: Adam 1146 loss=0.588344 error=0.413187 grad(V)=0.000474 grad(U)=0.000035\n",
      "downhill: Adam 1147 loss=0.587774 error=0.412675 grad(V)=0.000472 grad(U)=0.000035\n",
      "downhill: Adam 1148 loss=0.587205 error=0.412164 grad(V)=0.000469 grad(U)=0.000035\n",
      "downhill: Adam 1149 loss=0.586638 error=0.411654 grad(V)=0.000467 grad(U)=0.000035\n",
      "downhill: Adam 1150 loss=0.586071 error=0.411145 grad(V)=0.000465 grad(U)=0.000034\n",
      "downhill: validation 115 loss=0.585505 error=0.410638 grad(V)=0.000463 grad(U)=0.000034 *\n",
      "downhill: Adam 1151 loss=0.585505 error=0.410638 grad(V)=0.000463 grad(U)=0.000034\n",
      "downhill: Adam 1152 loss=0.584941 error=0.410131 grad(V)=0.000460 grad(U)=0.000034\n",
      "downhill: Adam 1153 loss=0.584377 error=0.409626 grad(V)=0.000458 grad(U)=0.000034\n",
      "downhill: Adam 1154 loss=0.583815 error=0.409122 grad(V)=0.000456 grad(U)=0.000034\n",
      "downhill: Adam 1155 loss=0.583254 error=0.408619 grad(V)=0.000454 grad(U)=0.000034\n",
      "downhill: Adam 1156 loss=0.582693 error=0.408117 grad(V)=0.000452 grad(U)=0.000034\n",
      "downhill: Adam 1157 loss=0.582134 error=0.407616 grad(V)=0.000449 grad(U)=0.000034\n",
      "downhill: Adam 1158 loss=0.581576 error=0.407116 grad(V)=0.000447 grad(U)=0.000033\n",
      "downhill: Adam 1159 loss=0.581018 error=0.406617 grad(V)=0.000445 grad(U)=0.000033\n",
      "downhill: Adam 1160 loss=0.580462 error=0.406120 grad(V)=0.000443 grad(U)=0.000033\n",
      "downhill: validation 116 loss=0.579907 error=0.405623 grad(V)=0.000441 grad(U)=0.000033 *\n",
      "downhill: Adam 1161 loss=0.579907 error=0.405623 grad(V)=0.000441 grad(U)=0.000033\n",
      "downhill: Adam 1162 loss=0.579353 error=0.405128 grad(V)=0.000439 grad(U)=0.000033\n",
      "downhill: Adam 1163 loss=0.578800 error=0.404634 grad(V)=0.000436 grad(U)=0.000033\n",
      "downhill: Adam 1164 loss=0.578248 error=0.404141 grad(V)=0.000434 grad(U)=0.000033\n",
      "downhill: Adam 1165 loss=0.577697 error=0.403649 grad(V)=0.000432 grad(U)=0.000033\n",
      "downhill: Adam 1166 loss=0.577147 error=0.403158 grad(V)=0.000430 grad(U)=0.000032\n",
      "downhill: Adam 1167 loss=0.576598 error=0.402668 grad(V)=0.000428 grad(U)=0.000032\n",
      "downhill: Adam 1168 loss=0.576050 error=0.402179 grad(V)=0.000426 grad(U)=0.000032\n",
      "downhill: Adam 1169 loss=0.575503 error=0.401692 grad(V)=0.000424 grad(U)=0.000032\n",
      "downhill: Adam 1170 loss=0.574958 error=0.401206 grad(V)=0.000422 grad(U)=0.000032\n",
      "downhill: validation 117 loss=0.574413 error=0.400720 grad(V)=0.000420 grad(U)=0.000032 *\n",
      "downhill: Adam 1171 loss=0.574413 error=0.400720 grad(V)=0.000420 grad(U)=0.000032\n",
      "downhill: Adam 1172 loss=0.573870 error=0.400236 grad(V)=0.000417 grad(U)=0.000032\n",
      "downhill: Adam 1173 loss=0.573327 error=0.399753 grad(V)=0.000415 grad(U)=0.000032\n",
      "downhill: Adam 1174 loss=0.572786 error=0.399271 grad(V)=0.000413 grad(U)=0.000032\n",
      "downhill: Adam 1175 loss=0.572245 error=0.398791 grad(V)=0.000411 grad(U)=0.000031\n",
      "downhill: Adam 1176 loss=0.571706 error=0.398311 grad(V)=0.000409 grad(U)=0.000031\n",
      "downhill: Adam 1177 loss=0.571168 error=0.397833 grad(V)=0.000407 grad(U)=0.000031\n",
      "downhill: Adam 1178 loss=0.570630 error=0.397355 grad(V)=0.000405 grad(U)=0.000031\n",
      "downhill: Adam 1179 loss=0.570094 error=0.396879 grad(V)=0.000403 grad(U)=0.000031\n",
      "downhill: Adam 1180 loss=0.569558 error=0.396404 grad(V)=0.000401 grad(U)=0.000031\n",
      "downhill: validation 118 loss=0.569024 error=0.395930 grad(V)=0.000399 grad(U)=0.000031 *\n",
      "downhill: Adam 1181 loss=0.569024 error=0.395930 grad(V)=0.000399 grad(U)=0.000031\n",
      "downhill: Adam 1182 loss=0.568491 error=0.395457 grad(V)=0.000397 grad(U)=0.000031\n",
      "downhill: Adam 1183 loss=0.567959 error=0.394986 grad(V)=0.000395 grad(U)=0.000031\n",
      "downhill: Adam 1184 loss=0.567427 error=0.394515 grad(V)=0.000393 grad(U)=0.000030\n",
      "downhill: Adam 1185 loss=0.566897 error=0.394045 grad(V)=0.000391 grad(U)=0.000030\n",
      "downhill: Adam 1186 loss=0.566368 error=0.393577 grad(V)=0.000389 grad(U)=0.000030\n",
      "downhill: Adam 1187 loss=0.565839 error=0.393109 grad(V)=0.000387 grad(U)=0.000030\n",
      "downhill: Adam 1188 loss=0.565312 error=0.392643 grad(V)=0.000385 grad(U)=0.000030\n",
      "downhill: Adam 1189 loss=0.564786 error=0.392178 grad(V)=0.000383 grad(U)=0.000030\n",
      "downhill: Adam 1190 loss=0.564261 error=0.391714 grad(V)=0.000381 grad(U)=0.000030\n",
      "downhill: validation 119 loss=0.563736 error=0.391251 grad(V)=0.000379 grad(U)=0.000030 *\n",
      "downhill: Adam 1191 loss=0.563736 error=0.391251 grad(V)=0.000379 grad(U)=0.000030\n",
      "downhill: Adam 1192 loss=0.563213 error=0.390789 grad(V)=0.000378 grad(U)=0.000030\n",
      "downhill: Adam 1193 loss=0.562690 error=0.390329 grad(V)=0.000376 grad(U)=0.000030\n",
      "downhill: Adam 1194 loss=0.562169 error=0.389869 grad(V)=0.000374 grad(U)=0.000029\n",
      "downhill: Adam 1195 loss=0.561649 error=0.389411 grad(V)=0.000372 grad(U)=0.000029\n",
      "downhill: Adam 1196 loss=0.561129 error=0.388953 grad(V)=0.000370 grad(U)=0.000029\n",
      "downhill: Adam 1197 loss=0.560611 error=0.388497 grad(V)=0.000368 grad(U)=0.000029\n",
      "downhill: Adam 1198 loss=0.560094 error=0.388041 grad(V)=0.000366 grad(U)=0.000029\n",
      "downhill: Adam 1199 loss=0.559577 error=0.387587 grad(V)=0.000364 grad(U)=0.000029\n",
      "downhill: Adam 1200 loss=0.559062 error=0.387134 grad(V)=0.000362 grad(U)=0.000029\n",
      "downhill: validation 120 loss=0.558548 error=0.386682 grad(V)=0.000360 grad(U)=0.000029 *\n",
      "downhill: Adam 1201 loss=0.558548 error=0.386682 grad(V)=0.000360 grad(U)=0.000029\n",
      "downhill: Adam 1202 loss=0.558035 error=0.386231 grad(V)=0.000359 grad(U)=0.000029\n",
      "downhill: Adam 1203 loss=0.557522 error=0.385781 grad(V)=0.000357 grad(U)=0.000028\n",
      "downhill: Adam 1204 loss=0.557011 error=0.385332 grad(V)=0.000355 grad(U)=0.000028\n",
      "downhill: Adam 1205 loss=0.556501 error=0.384885 grad(V)=0.000353 grad(U)=0.000028\n",
      "downhill: Adam 1206 loss=0.555991 error=0.384438 grad(V)=0.000351 grad(U)=0.000028\n",
      "downhill: Adam 1207 loss=0.555483 error=0.383993 grad(V)=0.000349 grad(U)=0.000028\n",
      "downhill: Adam 1208 loss=0.554976 error=0.383548 grad(V)=0.000348 grad(U)=0.000028\n",
      "downhill: Adam 1209 loss=0.554469 error=0.383105 grad(V)=0.000346 grad(U)=0.000028\n",
      "downhill: Adam 1210 loss=0.553964 error=0.382662 grad(V)=0.000344 grad(U)=0.000028\n",
      "downhill: validation 121 loss=0.553460 error=0.382221 grad(V)=0.000342 grad(U)=0.000028 *\n",
      "downhill: Adam 1211 loss=0.553460 error=0.382221 grad(V)=0.000342 grad(U)=0.000028\n",
      "downhill: Adam 1212 loss=0.552957 error=0.381781 grad(V)=0.000340 grad(U)=0.000028\n",
      "downhill: Adam 1213 loss=0.552454 error=0.381342 grad(V)=0.000339 grad(U)=0.000027\n",
      "downhill: Adam 1214 loss=0.551953 error=0.380904 grad(V)=0.000337 grad(U)=0.000027\n",
      "downhill: Adam 1215 loss=0.551453 error=0.380466 grad(V)=0.000335 grad(U)=0.000027\n",
      "downhill: Adam 1216 loss=0.550953 error=0.380030 grad(V)=0.000333 grad(U)=0.000027\n",
      "downhill: Adam 1217 loss=0.550455 error=0.379595 grad(V)=0.000332 grad(U)=0.000027\n",
      "downhill: Adam 1218 loss=0.549958 error=0.379162 grad(V)=0.000330 grad(U)=0.000027\n",
      "downhill: Adam 1219 loss=0.549461 error=0.378729 grad(V)=0.000328 grad(U)=0.000027\n",
      "downhill: Adam 1220 loss=0.548966 error=0.378297 grad(V)=0.000326 grad(U)=0.000027\n",
      "downhill: validation 122 loss=0.548471 error=0.377866 grad(V)=0.000325 grad(U)=0.000027 *\n",
      "downhill: Adam 1221 loss=0.548471 error=0.377866 grad(V)=0.000325 grad(U)=0.000027\n",
      "downhill: Adam 1222 loss=0.547978 error=0.377437 grad(V)=0.000323 grad(U)=0.000027\n",
      "downhill: Adam 1223 loss=0.547485 error=0.377008 grad(V)=0.000321 grad(U)=0.000027\n",
      "downhill: Adam 1224 loss=0.546994 error=0.376581 grad(V)=0.000319 grad(U)=0.000026\n",
      "downhill: Adam 1225 loss=0.546503 error=0.376154 grad(V)=0.000318 grad(U)=0.000026\n",
      "downhill: Adam 1226 loss=0.546014 error=0.375729 grad(V)=0.000316 grad(U)=0.000026\n",
      "downhill: Adam 1227 loss=0.545525 error=0.375304 grad(V)=0.000314 grad(U)=0.000026\n",
      "downhill: Adam 1228 loss=0.545037 error=0.374881 grad(V)=0.000313 grad(U)=0.000026\n",
      "downhill: Adam 1229 loss=0.544550 error=0.374458 grad(V)=0.000311 grad(U)=0.000026\n",
      "downhill: Adam 1230 loss=0.544065 error=0.374037 grad(V)=0.000309 grad(U)=0.000026\n",
      "downhill: validation 123 loss=0.543580 error=0.373616 grad(V)=0.000308 grad(U)=0.000026 *\n",
      "downhill: Adam 1231 loss=0.543580 error=0.373616 grad(V)=0.000308 grad(U)=0.000026\n",
      "downhill: Adam 1232 loss=0.543096 error=0.373197 grad(V)=0.000306 grad(U)=0.000026\n",
      "downhill: Adam 1233 loss=0.542613 error=0.372778 grad(V)=0.000304 grad(U)=0.000026\n",
      "downhill: Adam 1234 loss=0.542131 error=0.372361 grad(V)=0.000303 grad(U)=0.000026\n",
      "downhill: Adam 1235 loss=0.541650 error=0.371945 grad(V)=0.000301 grad(U)=0.000025\n",
      "downhill: Adam 1236 loss=0.541169 error=0.371529 grad(V)=0.000300 grad(U)=0.000025\n",
      "downhill: Adam 1237 loss=0.540690 error=0.371115 grad(V)=0.000298 grad(U)=0.000025\n",
      "downhill: Adam 1238 loss=0.540212 error=0.370702 grad(V)=0.000296 grad(U)=0.000025\n",
      "downhill: Adam 1239 loss=0.539734 error=0.370290 grad(V)=0.000295 grad(U)=0.000025\n",
      "downhill: Adam 1240 loss=0.539258 error=0.369879 grad(V)=0.000293 grad(U)=0.000025\n",
      "downhill: validation 124 loss=0.538782 error=0.369468 grad(V)=0.000292 grad(U)=0.000025 *\n",
      "downhill: Adam 1241 loss=0.538782 error=0.369468 grad(V)=0.000292 grad(U)=0.000025\n",
      "downhill: Adam 1242 loss=0.538307 error=0.369059 grad(V)=0.000290 grad(U)=0.000025\n",
      "downhill: Adam 1243 loss=0.537834 error=0.368651 grad(V)=0.000288 grad(U)=0.000025\n",
      "downhill: Adam 1244 loss=0.537361 error=0.368244 grad(V)=0.000287 grad(U)=0.000025\n",
      "downhill: Adam 1245 loss=0.536889 error=0.367838 grad(V)=0.000285 grad(U)=0.000025\n",
      "downhill: Adam 1246 loss=0.536418 error=0.367432 grad(V)=0.000284 grad(U)=0.000024\n",
      "downhill: Adam 1247 loss=0.535947 error=0.367028 grad(V)=0.000282 grad(U)=0.000024\n",
      "downhill: Adam 1248 loss=0.535478 error=0.366625 grad(V)=0.000281 grad(U)=0.000024\n",
      "downhill: Adam 1249 loss=0.535009 error=0.366222 grad(V)=0.000279 grad(U)=0.000024\n",
      "downhill: Adam 1250 loss=0.534542 error=0.365821 grad(V)=0.000278 grad(U)=0.000024\n",
      "downhill: validation 125 loss=0.534075 error=0.365420 grad(V)=0.000276 grad(U)=0.000024 *\n",
      "downhill: Adam 1251 loss=0.534075 error=0.365420 grad(V)=0.000276 grad(U)=0.000024\n",
      "downhill: Adam 1252 loss=0.533610 error=0.365021 grad(V)=0.000275 grad(U)=0.000024\n",
      "downhill: Adam 1253 loss=0.533146 error=0.364622 grad(V)=0.000273 grad(U)=0.000024\n",
      "downhill: Adam 1254 loss=0.532682 error=0.364224 grad(V)=0.000272 grad(U)=0.000024\n",
      "downhill: Adam 1255 loss=0.532219 error=0.363827 grad(V)=0.000270 grad(U)=0.000024\n",
      "downhill: Adam 1256 loss=0.531757 error=0.363432 grad(V)=0.000269 grad(U)=0.000024\n",
      "downhill: Adam 1257 loss=0.531296 error=0.363037 grad(V)=0.000267 grad(U)=0.000024\n",
      "downhill: Adam 1258 loss=0.530836 error=0.362643 grad(V)=0.000266 grad(U)=0.000024\n",
      "downhill: Adam 1259 loss=0.530377 error=0.362250 grad(V)=0.000264 grad(U)=0.000023\n",
      "downhill: Adam 1260 loss=0.529918 error=0.361858 grad(V)=0.000263 grad(U)=0.000023\n",
      "downhill: validation 126 loss=0.529461 error=0.361467 grad(V)=0.000261 grad(U)=0.000023 *\n",
      "downhill: Adam 1261 loss=0.529461 error=0.361467 grad(V)=0.000261 grad(U)=0.000023\n",
      "downhill: Adam 1262 loss=0.529004 error=0.361077 grad(V)=0.000260 grad(U)=0.000023\n",
      "downhill: Adam 1263 loss=0.528548 error=0.360688 grad(V)=0.000258 grad(U)=0.000023\n",
      "downhill: Adam 1264 loss=0.528093 error=0.360300 grad(V)=0.000257 grad(U)=0.000023\n",
      "downhill: Adam 1265 loss=0.527639 error=0.359912 grad(V)=0.000256 grad(U)=0.000023\n",
      "downhill: Adam 1266 loss=0.527186 error=0.359526 grad(V)=0.000254 grad(U)=0.000023\n",
      "downhill: Adam 1267 loss=0.526734 error=0.359141 grad(V)=0.000253 grad(U)=0.000023\n",
      "downhill: Adam 1268 loss=0.526283 error=0.358756 grad(V)=0.000251 grad(U)=0.000023\n",
      "downhill: Adam 1269 loss=0.525832 error=0.358373 grad(V)=0.000250 grad(U)=0.000023\n",
      "downhill: Adam 1270 loss=0.525383 error=0.357990 grad(V)=0.000249 grad(U)=0.000023\n",
      "downhill: validation 127 loss=0.524934 error=0.357609 grad(V)=0.000247 grad(U)=0.000022 *\n",
      "downhill: Adam 1271 loss=0.524934 error=0.357609 grad(V)=0.000247 grad(U)=0.000022\n",
      "downhill: Adam 1272 loss=0.524486 error=0.357228 grad(V)=0.000246 grad(U)=0.000022\n",
      "downhill: Adam 1273 loss=0.524039 error=0.356849 grad(V)=0.000244 grad(U)=0.000022\n",
      "downhill: Adam 1274 loss=0.523593 error=0.356470 grad(V)=0.000243 grad(U)=0.000022\n",
      "downhill: Adam 1275 loss=0.523148 error=0.356092 grad(V)=0.000242 grad(U)=0.000022\n",
      "downhill: Adam 1276 loss=0.522703 error=0.355715 grad(V)=0.000240 grad(U)=0.000022\n",
      "downhill: Adam 1277 loss=0.522260 error=0.355339 grad(V)=0.000239 grad(U)=0.000022\n",
      "downhill: Adam 1278 loss=0.521817 error=0.354963 grad(V)=0.000238 grad(U)=0.000022\n",
      "downhill: Adam 1279 loss=0.521375 error=0.354589 grad(V)=0.000236 grad(U)=0.000022\n",
      "downhill: Adam 1280 loss=0.520933 error=0.354215 grad(V)=0.000235 grad(U)=0.000022\n",
      "downhill: validation 128 loss=0.520493 error=0.353843 grad(V)=0.000234 grad(U)=0.000022 *\n",
      "downhill: Adam 1281 loss=0.520493 error=0.353843 grad(V)=0.000234 grad(U)=0.000022\n",
      "downhill: Adam 1282 loss=0.520053 error=0.353471 grad(V)=0.000232 grad(U)=0.000022\n",
      "downhill: Adam 1283 loss=0.519614 error=0.353100 grad(V)=0.000231 grad(U)=0.000022\n",
      "downhill: Adam 1284 loss=0.519176 error=0.352730 grad(V)=0.000230 grad(U)=0.000022\n",
      "downhill: Adam 1285 loss=0.518739 error=0.352361 grad(V)=0.000228 grad(U)=0.000021\n",
      "downhill: Adam 1286 loss=0.518303 error=0.351993 grad(V)=0.000227 grad(U)=0.000021\n",
      "downhill: Adam 1287 loss=0.517867 error=0.351626 grad(V)=0.000226 grad(U)=0.000021\n",
      "downhill: Adam 1288 loss=0.517432 error=0.351259 grad(V)=0.000225 grad(U)=0.000021\n",
      "downhill: Adam 1289 loss=0.516999 error=0.350894 grad(V)=0.000223 grad(U)=0.000021\n",
      "downhill: Adam 1290 loss=0.516565 error=0.350529 grad(V)=0.000222 grad(U)=0.000021\n",
      "downhill: validation 129 loss=0.516133 error=0.350165 grad(V)=0.000221 grad(U)=0.000021 *\n",
      "downhill: Adam 1291 loss=0.516133 error=0.350165 grad(V)=0.000221 grad(U)=0.000021\n",
      "downhill: Adam 1292 loss=0.515702 error=0.349802 grad(V)=0.000220 grad(U)=0.000021\n",
      "downhill: Adam 1293 loss=0.515271 error=0.349440 grad(V)=0.000218 grad(U)=0.000021\n",
      "downhill: Adam 1294 loss=0.514841 error=0.349078 grad(V)=0.000217 grad(U)=0.000021\n",
      "downhill: Adam 1295 loss=0.514412 error=0.348718 grad(V)=0.000216 grad(U)=0.000021\n",
      "downhill: Adam 1296 loss=0.513984 error=0.348358 grad(V)=0.000215 grad(U)=0.000021\n",
      "downhill: Adam 1297 loss=0.513556 error=0.347999 grad(V)=0.000213 grad(U)=0.000021\n",
      "downhill: Adam 1298 loss=0.513129 error=0.347641 grad(V)=0.000212 grad(U)=0.000021\n",
      "downhill: Adam 1299 loss=0.512703 error=0.347284 grad(V)=0.000211 grad(U)=0.000020\n",
      "downhill: Adam 1300 loss=0.512278 error=0.346927 grad(V)=0.000210 grad(U)=0.000020\n",
      "downhill: validation 130 loss=0.511854 error=0.346572 grad(V)=0.000209 grad(U)=0.000020 *\n",
      "downhill: Adam 1301 loss=0.511854 error=0.346572 grad(V)=0.000209 grad(U)=0.000020\n",
      "downhill: Adam 1302 loss=0.511430 error=0.346217 grad(V)=0.000207 grad(U)=0.000020\n",
      "downhill: Adam 1303 loss=0.511007 error=0.345863 grad(V)=0.000206 grad(U)=0.000020\n",
      "downhill: Adam 1304 loss=0.510586 error=0.345510 grad(V)=0.000205 grad(U)=0.000020\n",
      "downhill: Adam 1305 loss=0.510164 error=0.345157 grad(V)=0.000204 grad(U)=0.000020\n",
      "downhill: Adam 1306 loss=0.509744 error=0.344806 grad(V)=0.000203 grad(U)=0.000020\n",
      "downhill: Adam 1307 loss=0.509325 error=0.344455 grad(V)=0.000202 grad(U)=0.000020\n",
      "downhill: Adam 1308 loss=0.508906 error=0.344105 grad(V)=0.000200 grad(U)=0.000020\n",
      "downhill: Adam 1309 loss=0.508487 error=0.343756 grad(V)=0.000199 grad(U)=0.000020\n",
      "downhill: Adam 1310 loss=0.508070 error=0.343408 grad(V)=0.000198 grad(U)=0.000020\n",
      "downhill: validation 131 loss=0.507653 error=0.343060 grad(V)=0.000197 grad(U)=0.000020 *\n",
      "downhill: Adam 1311 loss=0.507653 error=0.343060 grad(V)=0.000197 grad(U)=0.000020\n",
      "downhill: Adam 1312 loss=0.507237 error=0.342713 grad(V)=0.000196 grad(U)=0.000020\n",
      "downhill: Adam 1313 loss=0.506822 error=0.342368 grad(V)=0.000195 grad(U)=0.000020\n",
      "downhill: Adam 1314 loss=0.506407 error=0.342022 grad(V)=0.000194 grad(U)=0.000019\n",
      "downhill: Adam 1315 loss=0.505993 error=0.341678 grad(V)=0.000193 grad(U)=0.000019\n",
      "downhill: Adam 1316 loss=0.505580 error=0.341334 grad(V)=0.000191 grad(U)=0.000019\n",
      "downhill: Adam 1317 loss=0.505168 error=0.340991 grad(V)=0.000190 grad(U)=0.000019\n",
      "downhill: Adam 1318 loss=0.504756 error=0.340649 grad(V)=0.000189 grad(U)=0.000019\n",
      "downhill: Adam 1319 loss=0.504345 error=0.340308 grad(V)=0.000188 grad(U)=0.000019\n",
      "downhill: Adam 1320 loss=0.503934 error=0.339968 grad(V)=0.000187 grad(U)=0.000019\n",
      "downhill: validation 132 loss=0.503525 error=0.339628 grad(V)=0.000186 grad(U)=0.000019 *\n",
      "downhill: Adam 1321 loss=0.503525 error=0.339628 grad(V)=0.000186 grad(U)=0.000019\n",
      "downhill: Adam 1322 loss=0.503116 error=0.339289 grad(V)=0.000185 grad(U)=0.000019\n",
      "downhill: Adam 1323 loss=0.502708 error=0.338951 grad(V)=0.000184 grad(U)=0.000019\n",
      "downhill: Adam 1324 loss=0.502301 error=0.338613 grad(V)=0.000183 grad(U)=0.000019\n",
      "downhill: Adam 1325 loss=0.501895 error=0.338276 grad(V)=0.000182 grad(U)=0.000019\n",
      "downhill: Adam 1326 loss=0.501489 error=0.337940 grad(V)=0.000181 grad(U)=0.000019\n",
      "downhill: Adam 1327 loss=0.501085 error=0.337605 grad(V)=0.000180 grad(U)=0.000019\n",
      "downhill: Adam 1328 loss=0.500681 error=0.337270 grad(V)=0.000179 grad(U)=0.000019\n",
      "downhill: Adam 1329 loss=0.500277 error=0.336936 grad(V)=0.000178 grad(U)=0.000019\n",
      "downhill: Adam 1330 loss=0.499874 error=0.336603 grad(V)=0.000177 grad(U)=0.000019\n",
      "downhill: validation 133 loss=0.499472 error=0.336271 grad(V)=0.000176 grad(U)=0.000018 *\n",
      "downhill: Adam 1331 loss=0.499472 error=0.336271 grad(V)=0.000176 grad(U)=0.000018\n",
      "downhill: Adam 1332 loss=0.499071 error=0.335939 grad(V)=0.000175 grad(U)=0.000018\n",
      "downhill: Adam 1333 loss=0.498671 error=0.335608 grad(V)=0.000174 grad(U)=0.000018\n",
      "downhill: Adam 1334 loss=0.498271 error=0.335278 grad(V)=0.000173 grad(U)=0.000018\n",
      "downhill: Adam 1335 loss=0.497872 error=0.334948 grad(V)=0.000172 grad(U)=0.000018\n",
      "downhill: Adam 1336 loss=0.497473 error=0.334619 grad(V)=0.000171 grad(U)=0.000018\n",
      "downhill: Adam 1337 loss=0.497075 error=0.334291 grad(V)=0.000170 grad(U)=0.000018\n",
      "downhill: Adam 1338 loss=0.496678 error=0.333964 grad(V)=0.000169 grad(U)=0.000018\n",
      "downhill: Adam 1339 loss=0.496282 error=0.333637 grad(V)=0.000168 grad(U)=0.000018\n",
      "downhill: Adam 1340 loss=0.495886 error=0.333312 grad(V)=0.000167 grad(U)=0.000018\n",
      "downhill: validation 134 loss=0.495491 error=0.332986 grad(V)=0.000166 grad(U)=0.000018 *\n",
      "downhill: Adam 1341 loss=0.495491 error=0.332986 grad(V)=0.000166 grad(U)=0.000018\n",
      "downhill: Adam 1342 loss=0.495097 error=0.332662 grad(V)=0.000165 grad(U)=0.000018\n",
      "downhill: Adam 1343 loss=0.494703 error=0.332338 grad(V)=0.000164 grad(U)=0.000018\n",
      "downhill: Adam 1344 loss=0.494310 error=0.332015 grad(V)=0.000163 grad(U)=0.000018\n",
      "downhill: Adam 1345 loss=0.493918 error=0.331692 grad(V)=0.000162 grad(U)=0.000018\n",
      "downhill: Adam 1346 loss=0.493526 error=0.331370 grad(V)=0.000161 grad(U)=0.000018\n",
      "downhill: Adam 1347 loss=0.493135 error=0.331049 grad(V)=0.000160 grad(U)=0.000018\n",
      "downhill: Adam 1348 loss=0.492745 error=0.330728 grad(V)=0.000159 grad(U)=0.000017\n",
      "downhill: Adam 1349 loss=0.492355 error=0.330408 grad(V)=0.000158 grad(U)=0.000017\n",
      "downhill: Adam 1350 loss=0.491966 error=0.330089 grad(V)=0.000157 grad(U)=0.000017\n",
      "downhill: validation 135 loss=0.491578 error=0.329771 grad(V)=0.000156 grad(U)=0.000017 *\n",
      "downhill: Adam 1351 loss=0.491578 error=0.329771 grad(V)=0.000156 grad(U)=0.000017\n",
      "downhill: Adam 1352 loss=0.491190 error=0.329453 grad(V)=0.000155 grad(U)=0.000017\n",
      "downhill: Adam 1353 loss=0.490803 error=0.329136 grad(V)=0.000155 grad(U)=0.000017\n",
      "downhill: Adam 1354 loss=0.490417 error=0.328819 grad(V)=0.000154 grad(U)=0.000017\n",
      "downhill: Adam 1355 loss=0.490031 error=0.328503 grad(V)=0.000153 grad(U)=0.000017\n",
      "downhill: Adam 1356 loss=0.489646 error=0.328188 grad(V)=0.000152 grad(U)=0.000017\n",
      "downhill: Adam 1357 loss=0.489262 error=0.327874 grad(V)=0.000151 grad(U)=0.000017\n",
      "downhill: Adam 1358 loss=0.488878 error=0.327560 grad(V)=0.000150 grad(U)=0.000017\n",
      "downhill: Adam 1359 loss=0.488495 error=0.327246 grad(V)=0.000149 grad(U)=0.000017\n",
      "downhill: Adam 1360 loss=0.488112 error=0.326934 grad(V)=0.000148 grad(U)=0.000017\n",
      "downhill: validation 136 loss=0.487730 error=0.326622 grad(V)=0.000147 grad(U)=0.000017 *\n",
      "downhill: Adam 1361 loss=0.487730 error=0.326622 grad(V)=0.000147 grad(U)=0.000017\n",
      "downhill: Adam 1362 loss=0.487349 error=0.326310 grad(V)=0.000147 grad(U)=0.000017\n",
      "downhill: Adam 1363 loss=0.486968 error=0.326000 grad(V)=0.000146 grad(U)=0.000017\n",
      "downhill: Adam 1364 loss=0.486588 error=0.325689 grad(V)=0.000145 grad(U)=0.000017\n",
      "downhill: Adam 1365 loss=0.486208 error=0.325380 grad(V)=0.000144 grad(U)=0.000017\n",
      "downhill: Adam 1366 loss=0.485829 error=0.325071 grad(V)=0.000143 grad(U)=0.000017\n",
      "downhill: Adam 1367 loss=0.485450 error=0.324763 grad(V)=0.000142 grad(U)=0.000017\n",
      "downhill: Adam 1368 loss=0.485073 error=0.324455 grad(V)=0.000142 grad(U)=0.000016\n",
      "downhill: Adam 1369 loss=0.484695 error=0.324148 grad(V)=0.000141 grad(U)=0.000016\n",
      "downhill: Adam 1370 loss=0.484319 error=0.323841 grad(V)=0.000140 grad(U)=0.000016\n",
      "downhill: validation 137 loss=0.483943 error=0.323535 grad(V)=0.000139 grad(U)=0.000016 *\n",
      "downhill: Adam 1371 loss=0.483943 error=0.323535 grad(V)=0.000139 grad(U)=0.000016\n",
      "downhill: Adam 1372 loss=0.483568 error=0.323230 grad(V)=0.000138 grad(U)=0.000016\n",
      "downhill: Adam 1373 loss=0.483193 error=0.322925 grad(V)=0.000138 grad(U)=0.000016\n",
      "downhill: Adam 1374 loss=0.482819 error=0.322621 grad(V)=0.000137 grad(U)=0.000016\n",
      "downhill: Adam 1375 loss=0.482445 error=0.322317 grad(V)=0.000136 grad(U)=0.000016\n",
      "downhill: Adam 1376 loss=0.482072 error=0.322014 grad(V)=0.000135 grad(U)=0.000016\n",
      "downhill: Adam 1377 loss=0.481699 error=0.321712 grad(V)=0.000134 grad(U)=0.000016\n",
      "downhill: Adam 1378 loss=0.481328 error=0.321410 grad(V)=0.000134 grad(U)=0.000016\n",
      "downhill: Adam 1379 loss=0.480956 error=0.321109 grad(V)=0.000133 grad(U)=0.000016\n",
      "downhill: Adam 1380 loss=0.480586 error=0.320808 grad(V)=0.000132 grad(U)=0.000016\n",
      "downhill: validation 138 loss=0.480216 error=0.320508 grad(V)=0.000131 grad(U)=0.000016 *\n",
      "downhill: Adam 1381 loss=0.480216 error=0.320508 grad(V)=0.000131 grad(U)=0.000016\n",
      "downhill: Adam 1382 loss=0.479847 error=0.320208 grad(V)=0.000130 grad(U)=0.000016\n",
      "downhill: Adam 1383 loss=0.479478 error=0.319909 grad(V)=0.000130 grad(U)=0.000016\n",
      "downhill: Adam 1384 loss=0.479110 error=0.319611 grad(V)=0.000129 grad(U)=0.000016\n",
      "downhill: Adam 1385 loss=0.478743 error=0.319313 grad(V)=0.000128 grad(U)=0.000016\n",
      "downhill: Adam 1386 loss=0.478376 error=0.319016 grad(V)=0.000127 grad(U)=0.000016\n",
      "downhill: Adam 1387 loss=0.478009 error=0.318719 grad(V)=0.000127 grad(U)=0.000016\n",
      "downhill: Adam 1388 loss=0.477644 error=0.318423 grad(V)=0.000126 grad(U)=0.000015\n",
      "downhill: Adam 1389 loss=0.477279 error=0.318127 grad(V)=0.000125 grad(U)=0.000015\n",
      "downhill: Adam 1390 loss=0.476914 error=0.317832 grad(V)=0.000124 grad(U)=0.000015\n",
      "downhill: validation 139 loss=0.476550 error=0.317537 grad(V)=0.000124 grad(U)=0.000015 *\n",
      "downhill: Adam 1391 loss=0.476550 error=0.317537 grad(V)=0.000124 grad(U)=0.000015\n",
      "downhill: Adam 1392 loss=0.476187 error=0.317243 grad(V)=0.000123 grad(U)=0.000015\n",
      "downhill: Adam 1393 loss=0.475824 error=0.316950 grad(V)=0.000122 grad(U)=0.000015\n",
      "downhill: Adam 1394 loss=0.475462 error=0.316657 grad(V)=0.000122 grad(U)=0.000015\n",
      "downhill: Adam 1395 loss=0.475100 error=0.316364 grad(V)=0.000121 grad(U)=0.000015\n",
      "downhill: Adam 1396 loss=0.474738 error=0.316072 grad(V)=0.000120 grad(U)=0.000015\n",
      "downhill: Adam 1397 loss=0.474378 error=0.315781 grad(V)=0.000119 grad(U)=0.000015\n",
      "downhill: Adam 1398 loss=0.474018 error=0.315490 grad(V)=0.000119 grad(U)=0.000015\n",
      "downhill: Adam 1399 loss=0.473658 error=0.315200 grad(V)=0.000118 grad(U)=0.000015\n",
      "downhill: Adam 1400 loss=0.473299 error=0.314910 grad(V)=0.000117 grad(U)=0.000015\n",
      "downhill: validation 140 loss=0.472940 error=0.314621 grad(V)=0.000117 grad(U)=0.000015 *\n",
      "downhill: Adam 1401 loss=0.472940 error=0.314621 grad(V)=0.000117 grad(U)=0.000015\n",
      "downhill: Adam 1402 loss=0.472582 error=0.314332 grad(V)=0.000116 grad(U)=0.000015\n",
      "downhill: Adam 1403 loss=0.472224 error=0.314044 grad(V)=0.000115 grad(U)=0.000015\n",
      "downhill: Adam 1404 loss=0.471867 error=0.313756 grad(V)=0.000115 grad(U)=0.000015\n",
      "downhill: Adam 1405 loss=0.471510 error=0.313469 grad(V)=0.000114 grad(U)=0.000015\n",
      "downhill: Adam 1406 loss=0.471154 error=0.313183 grad(V)=0.000113 grad(U)=0.000015\n",
      "downhill: Adam 1407 loss=0.470799 error=0.312897 grad(V)=0.000113 grad(U)=0.000015\n",
      "downhill: Adam 1408 loss=0.470443 error=0.312611 grad(V)=0.000112 grad(U)=0.000015\n",
      "downhill: Adam 1409 loss=0.470089 error=0.312326 grad(V)=0.000111 grad(U)=0.000015\n",
      "downhill: Adam 1410 loss=0.469735 error=0.312041 grad(V)=0.000111 grad(U)=0.000015\n",
      "downhill: validation 141 loss=0.469382 error=0.311757 grad(V)=0.000110 grad(U)=0.000015 *\n",
      "downhill: Adam 1411 loss=0.469382 error=0.311757 grad(V)=0.000110 grad(U)=0.000015\n",
      "downhill: Adam 1412 loss=0.469029 error=0.311473 grad(V)=0.000109 grad(U)=0.000014\n",
      "downhill: Adam 1413 loss=0.468677 error=0.311190 grad(V)=0.000109 grad(U)=0.000014\n",
      "downhill: Adam 1414 loss=0.468325 error=0.310907 grad(V)=0.000108 grad(U)=0.000014\n",
      "downhill: Adam 1415 loss=0.467974 error=0.310625 grad(V)=0.000107 grad(U)=0.000014\n",
      "downhill: Adam 1416 loss=0.467623 error=0.310343 grad(V)=0.000107 grad(U)=0.000014\n",
      "downhill: Adam 1417 loss=0.467273 error=0.310062 grad(V)=0.000106 grad(U)=0.000014\n",
      "downhill: Adam 1418 loss=0.466923 error=0.309781 grad(V)=0.000106 grad(U)=0.000014\n",
      "downhill: Adam 1419 loss=0.466574 error=0.309501 grad(V)=0.000105 grad(U)=0.000014\n",
      "downhill: Adam 1420 loss=0.466226 error=0.309221 grad(V)=0.000104 grad(U)=0.000014\n",
      "downhill: validation 142 loss=0.465878 error=0.308942 grad(V)=0.000104 grad(U)=0.000014 *\n",
      "downhill: Adam 1421 loss=0.465878 error=0.308942 grad(V)=0.000104 grad(U)=0.000014\n",
      "downhill: Adam 1422 loss=0.465530 error=0.308663 grad(V)=0.000103 grad(U)=0.000014\n",
      "downhill: Adam 1423 loss=0.465184 error=0.308385 grad(V)=0.000103 grad(U)=0.000014\n",
      "downhill: Adam 1424 loss=0.464837 error=0.308107 grad(V)=0.000102 grad(U)=0.000014\n",
      "downhill: Adam 1425 loss=0.464491 error=0.307830 grad(V)=0.000101 grad(U)=0.000014\n",
      "downhill: Adam 1426 loss=0.464145 error=0.307553 grad(V)=0.000101 grad(U)=0.000014\n",
      "downhill: Adam 1427 loss=0.463800 error=0.307277 grad(V)=0.000100 grad(U)=0.000014\n",
      "downhill: Adam 1428 loss=0.463456 error=0.307001 grad(V)=0.000100 grad(U)=0.000014\n",
      "downhill: Adam 1429 loss=0.463112 error=0.306725 grad(V)=0.000099 grad(U)=0.000014\n",
      "downhill: Adam 1430 loss=0.462769 error=0.306450 grad(V)=0.000098 grad(U)=0.000014\n",
      "downhill: validation 143 loss=0.462426 error=0.306176 grad(V)=0.000098 grad(U)=0.000014 *\n",
      "downhill: Adam 1431 loss=0.462426 error=0.306176 grad(V)=0.000098 grad(U)=0.000014\n",
      "downhill: Adam 1432 loss=0.462083 error=0.305902 grad(V)=0.000097 grad(U)=0.000014\n",
      "downhill: Adam 1433 loss=0.461741 error=0.305628 grad(V)=0.000097 grad(U)=0.000014\n",
      "downhill: Adam 1434 loss=0.461400 error=0.305354 grad(V)=0.000096 grad(U)=0.000014\n",
      "downhill: Adam 1435 loss=0.461059 error=0.305082 grad(V)=0.000096 grad(U)=0.000014\n",
      "downhill: Adam 1436 loss=0.460718 error=0.304809 grad(V)=0.000095 grad(U)=0.000014\n",
      "downhill: Adam 1437 loss=0.460378 error=0.304537 grad(V)=0.000094 grad(U)=0.000013\n",
      "downhill: Adam 1438 loss=0.460039 error=0.304265 grad(V)=0.000094 grad(U)=0.000013\n",
      "downhill: Adam 1439 loss=0.459699 error=0.303994 grad(V)=0.000093 grad(U)=0.000013\n",
      "downhill: Adam 1440 loss=0.459361 error=0.303724 grad(V)=0.000093 grad(U)=0.000013\n",
      "downhill: validation 144 loss=0.459023 error=0.303453 grad(V)=0.000092 grad(U)=0.000013 *\n",
      "downhill: Adam 1441 loss=0.459023 error=0.303453 grad(V)=0.000092 grad(U)=0.000013\n",
      "downhill: Adam 1442 loss=0.458685 error=0.303183 grad(V)=0.000092 grad(U)=0.000013\n",
      "downhill: Adam 1443 loss=0.458348 error=0.302914 grad(V)=0.000091 grad(U)=0.000013\n",
      "downhill: Adam 1444 loss=0.458011 error=0.302645 grad(V)=0.000091 grad(U)=0.000013\n",
      "downhill: Adam 1445 loss=0.457675 error=0.302377 grad(V)=0.000090 grad(U)=0.000013\n",
      "downhill: Adam 1446 loss=0.457339 error=0.302108 grad(V)=0.000089 grad(U)=0.000013\n",
      "downhill: Adam 1447 loss=0.457004 error=0.301841 grad(V)=0.000089 grad(U)=0.000013\n",
      "downhill: Adam 1448 loss=0.456669 error=0.301574 grad(V)=0.000088 grad(U)=0.000013\n",
      "downhill: Adam 1449 loss=0.456335 error=0.301307 grad(V)=0.000088 grad(U)=0.000013\n",
      "downhill: Adam 1450 loss=0.456001 error=0.301041 grad(V)=0.000087 grad(U)=0.000013\n",
      "downhill: validation 145 loss=0.455667 error=0.300775 grad(V)=0.000087 grad(U)=0.000013 *\n",
      "downhill: Adam 1451 loss=0.455667 error=0.300775 grad(V)=0.000087 grad(U)=0.000013\n",
      "downhill: Adam 1452 loss=0.455334 error=0.300509 grad(V)=0.000086 grad(U)=0.000013\n",
      "downhill: Adam 1453 loss=0.455002 error=0.300244 grad(V)=0.000086 grad(U)=0.000013\n",
      "downhill: Adam 1454 loss=0.454669 error=0.299980 grad(V)=0.000085 grad(U)=0.000013\n",
      "downhill: Adam 1455 loss=0.454338 error=0.299715 grad(V)=0.000085 grad(U)=0.000013\n",
      "downhill: Adam 1456 loss=0.454006 error=0.299451 grad(V)=0.000084 grad(U)=0.000013\n",
      "downhill: Adam 1457 loss=0.453675 error=0.299188 grad(V)=0.000084 grad(U)=0.000013\n",
      "downhill: Adam 1458 loss=0.453345 error=0.298925 grad(V)=0.000083 grad(U)=0.000013\n",
      "downhill: Adam 1459 loss=0.453015 error=0.298662 grad(V)=0.000083 grad(U)=0.000013\n",
      "downhill: Adam 1460 loss=0.452685 error=0.298399 grad(V)=0.000082 grad(U)=0.000013\n",
      "downhill: validation 146 loss=0.452355 error=0.298137 grad(V)=0.000082 grad(U)=0.000013 *\n",
      "downhill: Adam 1461 loss=0.452355 error=0.298137 grad(V)=0.000082 grad(U)=0.000013\n",
      "downhill: Adam 1462 loss=0.452026 error=0.297876 grad(V)=0.000081 grad(U)=0.000013\n",
      "downhill: Adam 1463 loss=0.451697 error=0.297614 grad(V)=0.000081 grad(U)=0.000013\n",
      "downhill: Adam 1464 loss=0.451369 error=0.297353 grad(V)=0.000080 grad(U)=0.000013\n",
      "downhill: Adam 1465 loss=0.451042 error=0.297093 grad(V)=0.000080 grad(U)=0.000013\n",
      "downhill: Adam 1466 loss=0.450714 error=0.296833 grad(V)=0.000080 grad(U)=0.000013\n",
      "downhill: Adam 1467 loss=0.450387 error=0.296573 grad(V)=0.000079 grad(U)=0.000012\n",
      "downhill: Adam 1468 loss=0.450061 error=0.296313 grad(V)=0.000079 grad(U)=0.000012\n",
      "downhill: Adam 1469 loss=0.449735 error=0.296054 grad(V)=0.000078 grad(U)=0.000012\n",
      "downhill: Adam 1470 loss=0.449409 error=0.295795 grad(V)=0.000078 grad(U)=0.000012\n",
      "downhill: validation 147 loss=0.449084 error=0.295537 grad(V)=0.000077 grad(U)=0.000012 *\n",
      "downhill: Adam 1471 loss=0.449084 error=0.295537 grad(V)=0.000077 grad(U)=0.000012\n",
      "downhill: Adam 1472 loss=0.448759 error=0.295279 grad(V)=0.000077 grad(U)=0.000012\n",
      "downhill: Adam 1473 loss=0.448434 error=0.295021 grad(V)=0.000076 grad(U)=0.000012\n",
      "downhill: Adam 1474 loss=0.448110 error=0.294764 grad(V)=0.000076 grad(U)=0.000012\n",
      "downhill: Adam 1475 loss=0.447786 error=0.294507 grad(V)=0.000075 grad(U)=0.000012\n",
      "downhill: Adam 1476 loss=0.447462 error=0.294250 grad(V)=0.000075 grad(U)=0.000012\n",
      "downhill: Adam 1477 loss=0.447140 error=0.293994 grad(V)=0.000075 grad(U)=0.000012\n",
      "downhill: Adam 1478 loss=0.446817 error=0.293738 grad(V)=0.000074 grad(U)=0.000012\n",
      "downhill: Adam 1479 loss=0.446495 error=0.293483 grad(V)=0.000074 grad(U)=0.000012\n",
      "downhill: Adam 1480 loss=0.446173 error=0.293228 grad(V)=0.000073 grad(U)=0.000012\n",
      "downhill: validation 148 loss=0.445852 error=0.292973 grad(V)=0.000073 grad(U)=0.000012 *\n",
      "downhill: Adam 1481 loss=0.445852 error=0.292973 grad(V)=0.000073 grad(U)=0.000012\n",
      "downhill: Adam 1482 loss=0.445531 error=0.292718 grad(V)=0.000072 grad(U)=0.000012\n",
      "downhill: Adam 1483 loss=0.445210 error=0.292464 grad(V)=0.000072 grad(U)=0.000012\n",
      "downhill: Adam 1484 loss=0.444890 error=0.292210 grad(V)=0.000072 grad(U)=0.000012\n",
      "downhill: Adam 1485 loss=0.444570 error=0.291957 grad(V)=0.000071 grad(U)=0.000012\n",
      "downhill: Adam 1486 loss=0.444250 error=0.291703 grad(V)=0.000071 grad(U)=0.000012\n",
      "downhill: Adam 1487 loss=0.443931 error=0.291450 grad(V)=0.000070 grad(U)=0.000012\n",
      "downhill: Adam 1488 loss=0.443612 error=0.291198 grad(V)=0.000070 grad(U)=0.000012\n",
      "downhill: Adam 1489 loss=0.443294 error=0.290946 grad(V)=0.000069 grad(U)=0.000012\n",
      "downhill: Adam 1490 loss=0.442976 error=0.290694 grad(V)=0.000069 grad(U)=0.000012\n",
      "downhill: validation 149 loss=0.442658 error=0.290442 grad(V)=0.000069 grad(U)=0.000012 *\n",
      "downhill: Adam 1491 loss=0.442658 error=0.290442 grad(V)=0.000069 grad(U)=0.000012\n",
      "downhill: Adam 1492 loss=0.442341 error=0.290191 grad(V)=0.000068 grad(U)=0.000012\n",
      "downhill: Adam 1493 loss=0.442024 error=0.289940 grad(V)=0.000068 grad(U)=0.000012\n",
      "downhill: Adam 1494 loss=0.441708 error=0.289689 grad(V)=0.000067 grad(U)=0.000012\n",
      "downhill: Adam 1495 loss=0.441392 error=0.289439 grad(V)=0.000067 grad(U)=0.000012\n",
      "downhill: Adam 1496 loss=0.441076 error=0.289189 grad(V)=0.000067 grad(U)=0.000012\n",
      "downhill: Adam 1497 loss=0.440761 error=0.288939 grad(V)=0.000066 grad(U)=0.000012\n",
      "downhill: Adam 1498 loss=0.440446 error=0.288690 grad(V)=0.000066 grad(U)=0.000012\n",
      "downhill: Adam 1499 loss=0.440131 error=0.288441 grad(V)=0.000065 grad(U)=0.000012\n",
      "downhill: Adam 1500 loss=0.439817 error=0.288192 grad(V)=0.000065 grad(U)=0.000012\n",
      "downhill: validation 150 loss=0.439503 error=0.287944 grad(V)=0.000065 grad(U)=0.000012 *\n",
      "downhill: Adam 1501 loss=0.439503 error=0.287944 grad(V)=0.000065 grad(U)=0.000012\n",
      "downhill: Adam 1502 loss=0.439190 error=0.287696 grad(V)=0.000064 grad(U)=0.000012\n",
      "downhill: Adam 1503 loss=0.438876 error=0.287448 grad(V)=0.000064 grad(U)=0.000011\n",
      "downhill: Adam 1504 loss=0.438563 error=0.287200 grad(V)=0.000064 grad(U)=0.000011\n",
      "downhill: Adam 1505 loss=0.438250 error=0.286953 grad(V)=0.000063 grad(U)=0.000011\n",
      "downhill: Adam 1506 loss=0.437938 error=0.286706 grad(V)=0.000063 grad(U)=0.000011\n",
      "downhill: Adam 1507 loss=0.437626 error=0.286459 grad(V)=0.000062 grad(U)=0.000011\n",
      "downhill: Adam 1508 loss=0.437314 error=0.286212 grad(V)=0.000062 grad(U)=0.000011\n",
      "downhill: Adam 1509 loss=0.437002 error=0.285966 grad(V)=0.000062 grad(U)=0.000011\n",
      "downhill: Adam 1510 loss=0.436691 error=0.285720 grad(V)=0.000061 grad(U)=0.000011\n",
      "downhill: validation 151 loss=0.436380 error=0.285475 grad(V)=0.000061 grad(U)=0.000011 *\n",
      "downhill: Adam 1511 loss=0.436380 error=0.285475 grad(V)=0.000061 grad(U)=0.000011\n",
      "downhill: Adam 1512 loss=0.436070 error=0.285229 grad(V)=0.000061 grad(U)=0.000011\n",
      "downhill: Adam 1513 loss=0.435759 error=0.284984 grad(V)=0.000060 grad(U)=0.000011\n",
      "downhill: Adam 1514 loss=0.435449 error=0.284740 grad(V)=0.000060 grad(U)=0.000011\n",
      "downhill: Adam 1515 loss=0.435140 error=0.284495 grad(V)=0.000059 grad(U)=0.000011\n",
      "downhill: Adam 1516 loss=0.434830 error=0.284251 grad(V)=0.000059 grad(U)=0.000011\n",
      "downhill: Adam 1517 loss=0.434522 error=0.284007 grad(V)=0.000059 grad(U)=0.000011\n",
      "downhill: Adam 1518 loss=0.434213 error=0.283763 grad(V)=0.000058 grad(U)=0.000011\n",
      "downhill: Adam 1519 loss=0.433905 error=0.283520 grad(V)=0.000058 grad(U)=0.000011\n",
      "downhill: Adam 1520 loss=0.433597 error=0.283277 grad(V)=0.000058 grad(U)=0.000011\n",
      "downhill: validation 152 loss=0.433289 error=0.283034 grad(V)=0.000057 grad(U)=0.000011 *\n",
      "downhill: Adam 1521 loss=0.433289 error=0.283034 grad(V)=0.000057 grad(U)=0.000011\n",
      "downhill: Adam 1522 loss=0.432982 error=0.282791 grad(V)=0.000057 grad(U)=0.000011\n",
      "downhill: Adam 1523 loss=0.432675 error=0.282548 grad(V)=0.000057 grad(U)=0.000011\n",
      "downhill: Adam 1524 loss=0.432368 error=0.282306 grad(V)=0.000056 grad(U)=0.000011\n",
      "downhill: Adam 1525 loss=0.432062 error=0.282064 grad(V)=0.000056 grad(U)=0.000011\n",
      "downhill: Adam 1526 loss=0.431756 error=0.281822 grad(V)=0.000056 grad(U)=0.000011\n",
      "downhill: Adam 1527 loss=0.431450 error=0.281581 grad(V)=0.000055 grad(U)=0.000011\n",
      "downhill: Adam 1528 loss=0.431145 error=0.281340 grad(V)=0.000055 grad(U)=0.000011\n",
      "downhill: Adam 1529 loss=0.430840 error=0.281099 grad(V)=0.000055 grad(U)=0.000011\n",
      "downhill: Adam 1530 loss=0.430535 error=0.280858 grad(V)=0.000054 grad(U)=0.000011\n",
      "downhill: validation 153 loss=0.430230 error=0.280617 grad(V)=0.000054 grad(U)=0.000011 *\n",
      "downhill: Adam 1531 loss=0.430230 error=0.280617 grad(V)=0.000054 grad(U)=0.000011\n",
      "downhill: Adam 1532 loss=0.429925 error=0.280377 grad(V)=0.000054 grad(U)=0.000011\n",
      "downhill: Adam 1533 loss=0.429621 error=0.280137 grad(V)=0.000053 grad(U)=0.000011\n",
      "downhill: Adam 1534 loss=0.429317 error=0.279897 grad(V)=0.000053 grad(U)=0.000011\n",
      "downhill: Adam 1535 loss=0.429014 error=0.279658 grad(V)=0.000053 grad(U)=0.000011\n",
      "downhill: Adam 1536 loss=0.428711 error=0.279418 grad(V)=0.000052 grad(U)=0.000011\n",
      "downhill: Adam 1537 loss=0.428408 error=0.279179 grad(V)=0.000052 grad(U)=0.000011\n",
      "downhill: Adam 1538 loss=0.428105 error=0.278940 grad(V)=0.000052 grad(U)=0.000011\n",
      "downhill: Adam 1539 loss=0.427803 error=0.278702 grad(V)=0.000052 grad(U)=0.000011\n",
      "downhill: Adam 1540 loss=0.427501 error=0.278463 grad(V)=0.000051 grad(U)=0.000011\n",
      "downhill: validation 154 loss=0.427199 error=0.278225 grad(V)=0.000051 grad(U)=0.000011 *\n",
      "downhill: Adam 1541 loss=0.427199 error=0.278225 grad(V)=0.000051 grad(U)=0.000011\n",
      "downhill: Adam 1542 loss=0.426897 error=0.277987 grad(V)=0.000051 grad(U)=0.000011\n",
      "downhill: Adam 1543 loss=0.426596 error=0.277749 grad(V)=0.000050 grad(U)=0.000011\n",
      "downhill: Adam 1544 loss=0.426295 error=0.277512 grad(V)=0.000050 grad(U)=0.000011\n",
      "downhill: Adam 1545 loss=0.425995 error=0.277275 grad(V)=0.000050 grad(U)=0.000011\n",
      "downhill: Adam 1546 loss=0.425694 error=0.277037 grad(V)=0.000049 grad(U)=0.000011\n",
      "downhill: Adam 1547 loss=0.425395 error=0.276801 grad(V)=0.000049 grad(U)=0.000011\n",
      "downhill: Adam 1548 loss=0.425095 error=0.276564 grad(V)=0.000049 grad(U)=0.000011\n",
      "downhill: Adam 1549 loss=0.424795 error=0.276327 grad(V)=0.000048 grad(U)=0.000011\n",
      "downhill: Adam 1550 loss=0.424496 error=0.276091 grad(V)=0.000048 grad(U)=0.000010\n",
      "downhill: validation 155 loss=0.424198 error=0.275855 grad(V)=0.000048 grad(U)=0.000010 *\n",
      "downhill: Adam 1551 loss=0.424198 error=0.275855 grad(V)=0.000048 grad(U)=0.000010\n",
      "downhill: Adam 1552 loss=0.423899 error=0.275619 grad(V)=0.000048 grad(U)=0.000010\n",
      "downhill: Adam 1553 loss=0.423601 error=0.275384 grad(V)=0.000047 grad(U)=0.000010\n",
      "downhill: Adam 1554 loss=0.423303 error=0.275148 grad(V)=0.000047 grad(U)=0.000010\n",
      "downhill: Adam 1555 loss=0.423005 error=0.274913 grad(V)=0.000047 grad(U)=0.000010\n",
      "downhill: Adam 1556 loss=0.422707 error=0.274678 grad(V)=0.000046 grad(U)=0.000010\n",
      "downhill: Adam 1557 loss=0.422410 error=0.274443 grad(V)=0.000046 grad(U)=0.000010\n",
      "downhill: Adam 1558 loss=0.422113 error=0.274209 grad(V)=0.000046 grad(U)=0.000010\n",
      "downhill: Adam 1559 loss=0.421817 error=0.273975 grad(V)=0.000046 grad(U)=0.000010\n",
      "downhill: Adam 1560 loss=0.421520 error=0.273741 grad(V)=0.000045 grad(U)=0.000010\n",
      "downhill: validation 156 loss=0.421224 error=0.273507 grad(V)=0.000045 grad(U)=0.000010 *\n",
      "downhill: Adam 1561 loss=0.421224 error=0.273507 grad(V)=0.000045 grad(U)=0.000010\n",
      "downhill: Adam 1562 loss=0.420929 error=0.273273 grad(V)=0.000045 grad(U)=0.000010\n",
      "downhill: Adam 1563 loss=0.420634 error=0.273040 grad(V)=0.000044 grad(U)=0.000010\n",
      "downhill: Adam 1564 loss=0.420339 error=0.272806 grad(V)=0.000044 grad(U)=0.000010\n",
      "downhill: Adam 1565 loss=0.420044 error=0.272574 grad(V)=0.000044 grad(U)=0.000010\n",
      "downhill: Adam 1566 loss=0.419749 error=0.272341 grad(V)=0.000044 grad(U)=0.000010\n",
      "downhill: Adam 1567 loss=0.419455 error=0.272109 grad(V)=0.000043 grad(U)=0.000010\n",
      "downhill: Adam 1568 loss=0.419161 error=0.271877 grad(V)=0.000043 grad(U)=0.000010\n",
      "downhill: Adam 1569 loss=0.418867 error=0.271645 grad(V)=0.000043 grad(U)=0.000010\n",
      "downhill: Adam 1570 loss=0.418573 error=0.271413 grad(V)=0.000043 grad(U)=0.000010\n",
      "downhill: validation 157 loss=0.418280 error=0.271181 grad(V)=0.000042 grad(U)=0.000010 *\n",
      "downhill: Adam 1571 loss=0.418280 error=0.271181 grad(V)=0.000042 grad(U)=0.000010\n",
      "downhill: Adam 1572 loss=0.417987 error=0.270950 grad(V)=0.000042 grad(U)=0.000010\n",
      "downhill: Adam 1573 loss=0.417694 error=0.270719 grad(V)=0.000042 grad(U)=0.000010\n",
      "downhill: Adam 1574 loss=0.417401 error=0.270488 grad(V)=0.000042 grad(U)=0.000010\n",
      "downhill: Adam 1575 loss=0.417109 error=0.270257 grad(V)=0.000041 grad(U)=0.000010\n",
      "downhill: Adam 1576 loss=0.416817 error=0.270027 grad(V)=0.000041 grad(U)=0.000010\n",
      "downhill: Adam 1577 loss=0.416525 error=0.269797 grad(V)=0.000041 grad(U)=0.000010\n",
      "downhill: Adam 1578 loss=0.416233 error=0.269566 grad(V)=0.000041 grad(U)=0.000010\n",
      "downhill: Adam 1579 loss=0.415942 error=0.269336 grad(V)=0.000040 grad(U)=0.000010\n",
      "downhill: Adam 1580 loss=0.415651 error=0.269107 grad(V)=0.000040 grad(U)=0.000010\n",
      "downhill: validation 158 loss=0.415360 error=0.268877 grad(V)=0.000040 grad(U)=0.000010 *\n",
      "downhill: Adam 1581 loss=0.415360 error=0.268877 grad(V)=0.000040 grad(U)=0.000010\n",
      "downhill: Adam 1582 loss=0.415070 error=0.268648 grad(V)=0.000040 grad(U)=0.000010\n",
      "downhill: Adam 1583 loss=0.414779 error=0.268419 grad(V)=0.000039 grad(U)=0.000010\n",
      "downhill: Adam 1584 loss=0.414490 error=0.268190 grad(V)=0.000039 grad(U)=0.000010\n",
      "downhill: Adam 1585 loss=0.414200 error=0.267961 grad(V)=0.000039 grad(U)=0.000010\n",
      "downhill: Adam 1586 loss=0.413911 error=0.267732 grad(V)=0.000039 grad(U)=0.000010\n",
      "downhill: Adam 1587 loss=0.413622 error=0.267504 grad(V)=0.000038 grad(U)=0.000010\n",
      "downhill: Adam 1588 loss=0.413333 error=0.267276 grad(V)=0.000038 grad(U)=0.000010\n",
      "downhill: Adam 1589 loss=0.413044 error=0.267048 grad(V)=0.000038 grad(U)=0.000010\n",
      "downhill: Adam 1590 loss=0.412756 error=0.266820 grad(V)=0.000038 grad(U)=0.000010\n",
      "downhill: validation 159 loss=0.412468 error=0.266593 grad(V)=0.000037 grad(U)=0.000010 *\n",
      "downhill: Adam 1591 loss=0.412468 error=0.266593 grad(V)=0.000037 grad(U)=0.000010\n",
      "downhill: Adam 1592 loss=0.412180 error=0.266366 grad(V)=0.000037 grad(U)=0.000010\n",
      "downhill: Adam 1593 loss=0.411892 error=0.266139 grad(V)=0.000037 grad(U)=0.000010\n",
      "downhill: Adam 1594 loss=0.411605 error=0.265912 grad(V)=0.000037 grad(U)=0.000010\n",
      "downhill: Adam 1595 loss=0.411318 error=0.265685 grad(V)=0.000036 grad(U)=0.000010\n",
      "downhill: Adam 1596 loss=0.411031 error=0.265459 grad(V)=0.000036 grad(U)=0.000010\n",
      "downhill: Adam 1597 loss=0.410744 error=0.265232 grad(V)=0.000036 grad(U)=0.000010\n",
      "downhill: Adam 1598 loss=0.410458 error=0.265006 grad(V)=0.000036 grad(U)=0.000010\n",
      "downhill: Adam 1599 loss=0.410172 error=0.264780 grad(V)=0.000036 grad(U)=0.000010\n",
      "downhill: Adam 1600 loss=0.409886 error=0.264555 grad(V)=0.000035 grad(U)=0.000010\n",
      "downhill: validation 160 loss=0.409600 error=0.264329 grad(V)=0.000035 grad(U)=0.000010 *\n",
      "downhill: Adam 1601 loss=0.409600 error=0.264329 grad(V)=0.000035 grad(U)=0.000010\n",
      "downhill: Adam 1602 loss=0.409315 error=0.264104 grad(V)=0.000035 grad(U)=0.000010\n",
      "downhill: Adam 1603 loss=0.409030 error=0.263879 grad(V)=0.000035 grad(U)=0.000010\n",
      "downhill: Adam 1604 loss=0.408745 error=0.263654 grad(V)=0.000034 grad(U)=0.000010\n",
      "downhill: Adam 1605 loss=0.408461 error=0.263429 grad(V)=0.000034 grad(U)=0.000010\n",
      "downhill: Adam 1606 loss=0.408176 error=0.263204 grad(V)=0.000034 grad(U)=0.000010\n",
      "downhill: Adam 1607 loss=0.407892 error=0.262980 grad(V)=0.000034 grad(U)=0.000010\n",
      "downhill: Adam 1608 loss=0.407608 error=0.262756 grad(V)=0.000034 grad(U)=0.000010\n",
      "downhill: Adam 1609 loss=0.407325 error=0.262532 grad(V)=0.000033 grad(U)=0.000010\n",
      "downhill: Adam 1610 loss=0.407041 error=0.262308 grad(V)=0.000033 grad(U)=0.000010\n",
      "downhill: validation 161 loss=0.406758 error=0.262084 grad(V)=0.000033 grad(U)=0.000010 *\n",
      "downhill: Adam 1611 loss=0.406758 error=0.262084 grad(V)=0.000033 grad(U)=0.000010\n",
      "downhill: Adam 1612 loss=0.406475 error=0.261861 grad(V)=0.000033 grad(U)=0.000010\n",
      "downhill: Adam 1613 loss=0.406192 error=0.261637 grad(V)=0.000033 grad(U)=0.000010\n",
      "downhill: Adam 1614 loss=0.405910 error=0.261414 grad(V)=0.000032 grad(U)=0.000009\n",
      "downhill: Adam 1615 loss=0.405628 error=0.261191 grad(V)=0.000032 grad(U)=0.000009\n",
      "downhill: Adam 1616 loss=0.405345 error=0.260968 grad(V)=0.000032 grad(U)=0.000009\n",
      "downhill: Adam 1617 loss=0.405063 error=0.260746 grad(V)=0.000032 grad(U)=0.000009\n",
      "downhill: Adam 1618 loss=0.404781 error=0.260523 grad(V)=0.000032 grad(U)=0.000009\n",
      "downhill: Adam 1619 loss=0.404500 error=0.260301 grad(V)=0.000031 grad(U)=0.000009\n",
      "downhill: Adam 1620 loss=0.404218 error=0.260079 grad(V)=0.000031 grad(U)=0.000009\n",
      "downhill: validation 162 loss=0.403937 error=0.259857 grad(V)=0.000031 grad(U)=0.000009 *\n",
      "downhill: Adam 1621 loss=0.403937 error=0.259857 grad(V)=0.000031 grad(U)=0.000009\n",
      "downhill: Adam 1622 loss=0.403656 error=0.259635 grad(V)=0.000031 grad(U)=0.000009\n",
      "downhill: Adam 1623 loss=0.403375 error=0.259413 grad(V)=0.000031 grad(U)=0.000009\n",
      "downhill: Adam 1624 loss=0.403094 error=0.259191 grad(V)=0.000030 grad(U)=0.000009\n",
      "downhill: Adam 1625 loss=0.402814 error=0.258970 grad(V)=0.000030 grad(U)=0.000009\n",
      "downhill: Adam 1626 loss=0.402534 error=0.258749 grad(V)=0.000030 grad(U)=0.000009\n",
      "downhill: Adam 1627 loss=0.402254 error=0.258528 grad(V)=0.000030 grad(U)=0.000009\n",
      "downhill: Adam 1628 loss=0.401974 error=0.258307 grad(V)=0.000030 grad(U)=0.000009\n",
      "downhill: Adam 1629 loss=0.401695 error=0.258087 grad(V)=0.000029 grad(U)=0.000009\n",
      "downhill: Adam 1630 loss=0.401415 error=0.257866 grad(V)=0.000029 grad(U)=0.000009\n",
      "downhill: validation 163 loss=0.401136 error=0.257646 grad(V)=0.000029 grad(U)=0.000009 *\n",
      "downhill: Adam 1631 loss=0.401136 error=0.257646 grad(V)=0.000029 grad(U)=0.000009\n",
      "downhill: Adam 1632 loss=0.400857 error=0.257425 grad(V)=0.000029 grad(U)=0.000009\n",
      "downhill: Adam 1633 loss=0.400579 error=0.257205 grad(V)=0.000029 grad(U)=0.000009\n",
      "downhill: Adam 1634 loss=0.400300 error=0.256985 grad(V)=0.000029 grad(U)=0.000009\n",
      "downhill: Adam 1635 loss=0.400022 error=0.256766 grad(V)=0.000028 grad(U)=0.000009\n",
      "downhill: Adam 1636 loss=0.399744 error=0.256546 grad(V)=0.000028 grad(U)=0.000009\n",
      "downhill: Adam 1637 loss=0.399466 error=0.256326 grad(V)=0.000028 grad(U)=0.000009\n",
      "downhill: Adam 1638 loss=0.399189 error=0.256107 grad(V)=0.000028 grad(U)=0.000009\n",
      "downhill: Adam 1639 loss=0.398912 error=0.255888 grad(V)=0.000028 grad(U)=0.000009\n",
      "downhill: Adam 1640 loss=0.398635 error=0.255669 grad(V)=0.000027 grad(U)=0.000009\n",
      "downhill: validation 164 loss=0.398358 error=0.255450 grad(V)=0.000027 grad(U)=0.000009 *\n",
      "downhill: Adam 1641 loss=0.398358 error=0.255450 grad(V)=0.000027 grad(U)=0.000009\n",
      "downhill: Adam 1642 loss=0.398081 error=0.255232 grad(V)=0.000027 grad(U)=0.000009\n",
      "downhill: Adam 1643 loss=0.397805 error=0.255014 grad(V)=0.000027 grad(U)=0.000009\n",
      "downhill: Adam 1644 loss=0.397529 error=0.254796 grad(V)=0.000027 grad(U)=0.000009\n",
      "downhill: Adam 1645 loss=0.397253 error=0.254577 grad(V)=0.000027 grad(U)=0.000009\n",
      "downhill: Adam 1646 loss=0.396977 error=0.254360 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: Adam 1647 loss=0.396702 error=0.254142 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: Adam 1648 loss=0.396427 error=0.253924 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: Adam 1649 loss=0.396152 error=0.253707 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: Adam 1650 loss=0.395877 error=0.253490 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: validation 165 loss=0.395603 error=0.253272 grad(V)=0.000026 grad(U)=0.000009 *\n",
      "downhill: Adam 1651 loss=0.395603 error=0.253272 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: Adam 1652 loss=0.395329 error=0.253055 grad(V)=0.000026 grad(U)=0.000009\n",
      "downhill: Adam 1653 loss=0.395055 error=0.252839 grad(V)=0.000025 grad(U)=0.000009\n",
      "downhill: Adam 1654 loss=0.394781 error=0.252622 grad(V)=0.000025 grad(U)=0.000009\n",
      "downhill: Adam 1655 loss=0.394507 error=0.252405 grad(V)=0.000025 grad(U)=0.000009\n",
      "downhill: Adam 1656 loss=0.394234 error=0.252189 grad(V)=0.000025 grad(U)=0.000009\n",
      "downhill: Adam 1657 loss=0.393961 error=0.251973 grad(V)=0.000025 grad(U)=0.000009\n",
      "downhill: Adam 1658 loss=0.393688 error=0.251757 grad(V)=0.000025 grad(U)=0.000009\n",
      "downhill: Adam 1659 loss=0.393415 error=0.251541 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: Adam 1660 loss=0.393142 error=0.251326 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: validation 166 loss=0.392870 error=0.251110 grad(V)=0.000024 grad(U)=0.000009 *\n",
      "downhill: Adam 1661 loss=0.392870 error=0.251110 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: Adam 1662 loss=0.392598 error=0.250895 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: Adam 1663 loss=0.392326 error=0.250680 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: Adam 1664 loss=0.392054 error=0.250465 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: Adam 1665 loss=0.391783 error=0.250250 grad(V)=0.000024 grad(U)=0.000009\n",
      "downhill: Adam 1666 loss=0.391512 error=0.250035 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: Adam 1667 loss=0.391240 error=0.249821 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: Adam 1668 loss=0.390970 error=0.249606 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: Adam 1669 loss=0.390699 error=0.249392 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: Adam 1670 loss=0.390429 error=0.249178 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: validation 167 loss=0.390158 error=0.248964 grad(V)=0.000023 grad(U)=0.000009 *\n",
      "downhill: Adam 1671 loss=0.390158 error=0.248964 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: Adam 1672 loss=0.389888 error=0.248750 grad(V)=0.000023 grad(U)=0.000009\n",
      "downhill: Adam 1673 loss=0.389618 error=0.248537 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1674 loss=0.389349 error=0.248323 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1675 loss=0.389079 error=0.248110 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1676 loss=0.388810 error=0.247897 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1677 loss=0.388541 error=0.247684 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1678 loss=0.388272 error=0.247472 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1679 loss=0.388004 error=0.247259 grad(V)=0.000022 grad(U)=0.000009\n",
      "downhill: Adam 1680 loss=0.387736 error=0.247047 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: validation 168 loss=0.387467 error=0.246835 grad(V)=0.000021 grad(U)=0.000009 *\n",
      "downhill: Adam 1681 loss=0.387467 error=0.246835 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1682 loss=0.387200 error=0.246623 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1683 loss=0.386932 error=0.246411 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1684 loss=0.386664 error=0.246199 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1685 loss=0.386397 error=0.245988 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1686 loss=0.386130 error=0.245776 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1687 loss=0.385863 error=0.245565 grad(V)=0.000021 grad(U)=0.000009\n",
      "downhill: Adam 1688 loss=0.385597 error=0.245354 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1689 loss=0.385331 error=0.245144 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1690 loss=0.385065 error=0.244933 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: validation 169 loss=0.384799 error=0.244722 grad(V)=0.000020 grad(U)=0.000009 *\n",
      "downhill: Adam 1691 loss=0.384799 error=0.244722 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1692 loss=0.384534 error=0.244512 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1693 loss=0.384268 error=0.244302 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1694 loss=0.384003 error=0.244092 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1695 loss=0.383738 error=0.243882 grad(V)=0.000020 grad(U)=0.000009\n",
      "downhill: Adam 1696 loss=0.383474 error=0.243672 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1697 loss=0.383209 error=0.243463 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1698 loss=0.382945 error=0.243253 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1699 loss=0.382681 error=0.243044 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1700 loss=0.382417 error=0.242835 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: validation 170 loss=0.382154 error=0.242626 grad(V)=0.000019 grad(U)=0.000009 *\n",
      "downhill: Adam 1701 loss=0.382154 error=0.242626 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1702 loss=0.381890 error=0.242417 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1703 loss=0.381627 error=0.242209 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1704 loss=0.381364 error=0.242000 grad(V)=0.000019 grad(U)=0.000009\n",
      "downhill: Adam 1705 loss=0.381101 error=0.241792 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1706 loss=0.380839 error=0.241584 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1707 loss=0.380576 error=0.241375 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1708 loss=0.380314 error=0.241168 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1709 loss=0.380052 error=0.240960 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1710 loss=0.379791 error=0.240753 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: validation 171 loss=0.379529 error=0.240545 grad(V)=0.000018 grad(U)=0.000009 *\n",
      "downhill: Adam 1711 loss=0.379529 error=0.240545 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1712 loss=0.379268 error=0.240338 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1713 loss=0.379007 error=0.240131 grad(V)=0.000018 grad(U)=0.000009\n",
      "downhill: Adam 1714 loss=0.378746 error=0.239925 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1715 loss=0.378486 error=0.239718 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1716 loss=0.378226 error=0.239512 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1717 loss=0.377966 error=0.239306 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1718 loss=0.377706 error=0.239100 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1719 loss=0.377446 error=0.238894 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1720 loss=0.377187 error=0.238689 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: validation 172 loss=0.376928 error=0.238483 grad(V)=0.000017 grad(U)=0.000009 *\n",
      "downhill: Adam 1721 loss=0.376928 error=0.238483 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1722 loss=0.376669 error=0.238278 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1723 loss=0.376411 error=0.238073 grad(V)=0.000017 grad(U)=0.000009\n",
      "downhill: Adam 1724 loss=0.376152 error=0.237868 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1725 loss=0.375894 error=0.237664 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1726 loss=0.375636 error=0.237459 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1727 loss=0.375378 error=0.237255 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1728 loss=0.375120 error=0.237051 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1729 loss=0.374862 error=0.236847 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1730 loss=0.374605 error=0.236643 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: validation 173 loss=0.374348 error=0.236439 grad(V)=0.000016 grad(U)=0.000009 *\n",
      "downhill: Adam 1731 loss=0.374348 error=0.236439 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1732 loss=0.374092 error=0.236236 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1733 loss=0.373835 error=0.236033 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1734 loss=0.373578 error=0.235829 grad(V)=0.000016 grad(U)=0.000009\n",
      "downhill: Adam 1735 loss=0.373322 error=0.235626 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1736 loss=0.373066 error=0.235424 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1737 loss=0.372810 error=0.235221 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1738 loss=0.372554 error=0.235019 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1739 loss=0.372299 error=0.234816 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1740 loss=0.372043 error=0.234614 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: validation 174 loss=0.371788 error=0.234412 grad(V)=0.000015 grad(U)=0.000008 *\n",
      "downhill: Adam 1741 loss=0.371788 error=0.234412 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1742 loss=0.371533 error=0.234210 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1743 loss=0.371278 error=0.234008 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1744 loss=0.371024 error=0.233807 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1745 loss=0.370769 error=0.233605 grad(V)=0.000015 grad(U)=0.000008\n",
      "downhill: Adam 1746 loss=0.370515 error=0.233404 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1747 loss=0.370261 error=0.233203 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1748 loss=0.370007 error=0.233002 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1749 loss=0.369753 error=0.232802 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1750 loss=0.369500 error=0.232601 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: validation 175 loss=0.369246 error=0.232401 grad(V)=0.000014 grad(U)=0.000008 *\n",
      "downhill: Adam 1751 loss=0.369246 error=0.232401 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1752 loss=0.368993 error=0.232200 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1753 loss=0.368741 error=0.232000 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1754 loss=0.368488 error=0.231800 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1755 loss=0.368236 error=0.231600 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1756 loss=0.367984 error=0.231400 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1757 loss=0.367732 error=0.231201 grad(V)=0.000014 grad(U)=0.000008\n",
      "downhill: Adam 1758 loss=0.367480 error=0.231001 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1759 loss=0.367229 error=0.230802 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1760 loss=0.366978 error=0.230603 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: validation 176 loss=0.366726 error=0.230404 grad(V)=0.000013 grad(U)=0.000008 *\n",
      "downhill: Adam 1761 loss=0.366726 error=0.230404 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1762 loss=0.366476 error=0.230205 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1763 loss=0.366225 error=0.230006 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1764 loss=0.365974 error=0.229808 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1765 loss=0.365724 error=0.229610 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1766 loss=0.365474 error=0.229412 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1767 loss=0.365224 error=0.229214 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1768 loss=0.364974 error=0.229017 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1769 loss=0.364725 error=0.228819 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1770 loss=0.364475 error=0.228622 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: validation 177 loss=0.364226 error=0.228425 grad(V)=0.000013 grad(U)=0.000008 *\n",
      "downhill: Adam 1771 loss=0.364226 error=0.228425 grad(V)=0.000013 grad(U)=0.000008\n",
      "downhill: Adam 1772 loss=0.363977 error=0.228228 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1773 loss=0.363729 error=0.228031 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1774 loss=0.363480 error=0.227835 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1775 loss=0.363232 error=0.227638 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1776 loss=0.362985 error=0.227442 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1777 loss=0.362737 error=0.227246 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1778 loss=0.362490 error=0.227050 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1779 loss=0.362242 error=0.226854 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1780 loss=0.361995 error=0.226659 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: validation 178 loss=0.361748 error=0.226463 grad(V)=0.000012 grad(U)=0.000008 *\n",
      "downhill: Adam 1781 loss=0.361748 error=0.226463 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1782 loss=0.361502 error=0.226268 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1783 loss=0.361255 error=0.226073 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1784 loss=0.361009 error=0.225878 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1785 loss=0.360763 error=0.225684 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1786 loss=0.360518 error=0.225489 grad(V)=0.000012 grad(U)=0.000008\n",
      "downhill: Adam 1787 loss=0.360272 error=0.225295 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1788 loss=0.360027 error=0.225101 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1789 loss=0.359782 error=0.224907 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1790 loss=0.359537 error=0.224713 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: validation 179 loss=0.359293 error=0.224519 grad(V)=0.000011 grad(U)=0.000008 *\n",
      "downhill: Adam 1791 loss=0.359293 error=0.224519 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1792 loss=0.359049 error=0.224326 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1793 loss=0.358805 error=0.224133 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1794 loss=0.358561 error=0.223940 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1795 loss=0.358317 error=0.223748 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1796 loss=0.358074 error=0.223555 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1797 loss=0.357831 error=0.223363 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1798 loss=0.357588 error=0.223171 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1799 loss=0.357345 error=0.222979 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1800 loss=0.357102 error=0.222788 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: validation 180 loss=0.356860 error=0.222597 grad(V)=0.000011 grad(U)=0.000008 *\n",
      "downhill: Adam 1801 loss=0.356860 error=0.222597 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1802 loss=0.356618 error=0.222406 grad(V)=0.000011 grad(U)=0.000008\n",
      "downhill: Adam 1803 loss=0.356376 error=0.222215 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1804 loss=0.356134 error=0.222024 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1805 loss=0.355892 error=0.221833 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1806 loss=0.355651 error=0.221643 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1807 loss=0.355410 error=0.221452 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1808 loss=0.355169 error=0.221262 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1809 loss=0.354928 error=0.221072 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1810 loss=0.354687 error=0.220882 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: validation 181 loss=0.354447 error=0.220692 grad(V)=0.000010 grad(U)=0.000008 *\n",
      "downhill: Adam 1811 loss=0.354447 error=0.220692 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1812 loss=0.354207 error=0.220503 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1813 loss=0.353968 error=0.220314 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1814 loss=0.353728 error=0.220124 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1815 loss=0.353489 error=0.219936 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1816 loss=0.353250 error=0.219747 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1817 loss=0.353011 error=0.219558 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1818 loss=0.352772 error=0.219370 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1819 loss=0.352534 error=0.219182 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: Adam 1820 loss=0.352296 error=0.218994 grad(V)=0.000010 grad(U)=0.000008\n",
      "downhill: validation 182 loss=0.352058 error=0.218806 grad(V)=0.000009 grad(U)=0.000008 *\n",
      "downhill: Adam 1821 loss=0.352058 error=0.218806 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1822 loss=0.351820 error=0.218619 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1823 loss=0.351583 error=0.218431 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1824 loss=0.351346 error=0.218244 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1825 loss=0.351109 error=0.218057 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1826 loss=0.350872 error=0.217870 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1827 loss=0.350636 error=0.217684 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1828 loss=0.350399 error=0.217497 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1829 loss=0.350163 error=0.217311 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1830 loss=0.349927 error=0.217125 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: validation 183 loss=0.349691 error=0.216940 grad(V)=0.000009 grad(U)=0.000008 *\n",
      "downhill: Adam 1831 loss=0.349691 error=0.216940 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1832 loss=0.349456 error=0.216754 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1833 loss=0.349220 error=0.216569 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1834 loss=0.348985 error=0.216383 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1835 loss=0.348750 error=0.216198 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1836 loss=0.348516 error=0.216013 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1837 loss=0.348281 error=0.215829 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1838 loss=0.348047 error=0.215644 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1839 loss=0.347813 error=0.215460 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1840 loss=0.347579 error=0.215276 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: validation 184 loss=0.347345 error=0.215092 grad(V)=0.000009 grad(U)=0.000008 *\n",
      "downhill: Adam 1841 loss=0.347345 error=0.215092 grad(V)=0.000009 grad(U)=0.000008\n",
      "downhill: Adam 1842 loss=0.347112 error=0.214908 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1843 loss=0.346879 error=0.214725 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1844 loss=0.346647 error=0.214542 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1845 loss=0.346414 error=0.214359 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1846 loss=0.346182 error=0.214176 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1847 loss=0.345950 error=0.213993 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1848 loss=0.345718 error=0.213811 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1849 loss=0.345487 error=0.213628 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1850 loss=0.345255 error=0.213446 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: validation 185 loss=0.345024 error=0.213264 grad(V)=0.000008 grad(U)=0.000008 *\n",
      "downhill: Adam 1851 loss=0.345024 error=0.213264 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1852 loss=0.344793 error=0.213082 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1853 loss=0.344563 error=0.212901 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1854 loss=0.344332 error=0.212719 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1855 loss=0.344102 error=0.212538 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1856 loss=0.343872 error=0.212357 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1857 loss=0.343643 error=0.212176 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1858 loss=0.343413 error=0.211996 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1859 loss=0.343184 error=0.211815 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1860 loss=0.342955 error=0.211635 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: validation 186 loss=0.342726 error=0.211455 grad(V)=0.000008 grad(U)=0.000008 *\n",
      "downhill: Adam 1861 loss=0.342726 error=0.211455 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1862 loss=0.342497 error=0.211275 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1863 loss=0.342269 error=0.211096 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1864 loss=0.342041 error=0.210916 grad(V)=0.000008 grad(U)=0.000008\n",
      "downhill: Adam 1865 loss=0.341813 error=0.210737 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1866 loss=0.341585 error=0.210558 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1867 loss=0.341358 error=0.210379 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1868 loss=0.341131 error=0.210201 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1869 loss=0.340904 error=0.210022 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1870 loss=0.340677 error=0.209844 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: validation 187 loss=0.340450 error=0.209666 grad(V)=0.000007 grad(U)=0.000008 *\n",
      "downhill: Adam 1871 loss=0.340450 error=0.209666 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1872 loss=0.340224 error=0.209488 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1873 loss=0.339998 error=0.209311 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1874 loss=0.339772 error=0.209133 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1875 loss=0.339547 error=0.208956 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1876 loss=0.339321 error=0.208779 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1877 loss=0.339096 error=0.208602 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1878 loss=0.338871 error=0.208426 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1879 loss=0.338646 error=0.208250 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1880 loss=0.338421 error=0.208073 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: validation 188 loss=0.338197 error=0.207897 grad(V)=0.000007 grad(U)=0.000008 *\n",
      "downhill: Adam 1881 loss=0.338197 error=0.207897 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1882 loss=0.337973 error=0.207722 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1883 loss=0.337749 error=0.207546 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1884 loss=0.337525 error=0.207370 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1885 loss=0.337302 error=0.207195 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1886 loss=0.337079 error=0.207020 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1887 loss=0.336856 error=0.206845 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1888 loss=0.336633 error=0.206670 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1889 loss=0.336411 error=0.206495 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: Adam 1890 loss=0.336189 error=0.206321 grad(V)=0.000007 grad(U)=0.000008\n",
      "downhill: validation 189 loss=0.335967 error=0.206147 grad(V)=0.000006 grad(U)=0.000008 *\n",
      "downhill: Adam 1891 loss=0.335967 error=0.206147 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1892 loss=0.335745 error=0.205973 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1893 loss=0.335524 error=0.205799 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1894 loss=0.335303 error=0.205626 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1895 loss=0.335082 error=0.205453 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1896 loss=0.334861 error=0.205280 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1897 loss=0.334641 error=0.205107 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1898 loss=0.334421 error=0.204934 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1899 loss=0.334201 error=0.204762 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1900 loss=0.333982 error=0.204590 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: validation 190 loss=0.333762 error=0.204418 grad(V)=0.000006 grad(U)=0.000008 *\n",
      "downhill: Adam 1901 loss=0.333762 error=0.204418 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1902 loss=0.333543 error=0.204246 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1903 loss=0.333324 error=0.204074 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1904 loss=0.333106 error=0.203903 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1905 loss=0.332887 error=0.203731 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1906 loss=0.332669 error=0.203560 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1907 loss=0.332451 error=0.203389 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1908 loss=0.332233 error=0.203218 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1909 loss=0.332016 error=0.203048 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1910 loss=0.331798 error=0.202877 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: validation 191 loss=0.331581 error=0.202707 grad(V)=0.000006 grad(U)=0.000008 *\n",
      "downhill: Adam 1911 loss=0.331581 error=0.202707 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1912 loss=0.331364 error=0.202537 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1913 loss=0.331148 error=0.202368 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1914 loss=0.330931 error=0.202198 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1915 loss=0.330715 error=0.202029 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1916 loss=0.330499 error=0.201860 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1917 loss=0.330283 error=0.201691 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1918 loss=0.330067 error=0.201522 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1919 loss=0.329851 error=0.201354 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1920 loss=0.329636 error=0.201185 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: validation 192 loss=0.329421 error=0.201017 grad(V)=0.000006 grad(U)=0.000008 *\n",
      "downhill: Adam 1921 loss=0.329421 error=0.201017 grad(V)=0.000006 grad(U)=0.000008\n",
      "downhill: Adam 1922 loss=0.329206 error=0.200849 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1923 loss=0.328992 error=0.200681 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1924 loss=0.328777 error=0.200513 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1925 loss=0.328563 error=0.200345 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1926 loss=0.328349 error=0.200178 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1927 loss=0.328136 error=0.200011 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1928 loss=0.327922 error=0.199844 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1929 loss=0.327708 error=0.199678 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1930 loss=0.327495 error=0.199511 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: validation 193 loss=0.327282 error=0.199345 grad(V)=0.000005 grad(U)=0.000008 *\n",
      "downhill: Adam 1931 loss=0.327282 error=0.199345 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1932 loss=0.327069 error=0.199179 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1933 loss=0.326857 error=0.199013 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1934 loss=0.326645 error=0.198847 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1935 loss=0.326433 error=0.198681 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1936 loss=0.326221 error=0.198515 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1937 loss=0.326009 error=0.198350 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1938 loss=0.325798 error=0.198185 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1939 loss=0.325587 error=0.198020 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1940 loss=0.325376 error=0.197855 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: validation 194 loss=0.325165 error=0.197690 grad(V)=0.000005 grad(U)=0.000008 *\n",
      "downhill: Adam 1941 loss=0.325165 error=0.197690 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1942 loss=0.324954 error=0.197525 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1943 loss=0.324744 error=0.197361 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1944 loss=0.324534 error=0.197197 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1945 loss=0.324324 error=0.197033 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1946 loss=0.324114 error=0.196870 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1947 loss=0.323904 error=0.196706 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1948 loss=0.323695 error=0.196543 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1949 loss=0.323486 error=0.196380 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1950 loss=0.323277 error=0.196217 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: validation 195 loss=0.323068 error=0.196054 grad(V)=0.000005 grad(U)=0.000008 *\n",
      "downhill: Adam 1951 loss=0.323068 error=0.196054 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1952 loss=0.322860 error=0.195891 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1953 loss=0.322651 error=0.195728 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1954 loss=0.322443 error=0.195566 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1955 loss=0.322235 error=0.195403 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1956 loss=0.322027 error=0.195241 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1957 loss=0.321820 error=0.195079 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1958 loss=0.321612 error=0.194918 grad(V)=0.000005 grad(U)=0.000008\n",
      "downhill: Adam 1959 loss=0.321406 error=0.194756 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1960 loss=0.321199 error=0.194594 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: validation 196 loss=0.320992 error=0.194433 grad(V)=0.000004 grad(U)=0.000008 *\n",
      "downhill: Adam 1961 loss=0.320992 error=0.194433 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1962 loss=0.320785 error=0.194272 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1963 loss=0.320579 error=0.194111 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1964 loss=0.320372 error=0.193950 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1965 loss=0.320167 error=0.193790 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1966 loss=0.319961 error=0.193629 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1967 loss=0.319755 error=0.193469 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1968 loss=0.319550 error=0.193309 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1969 loss=0.319345 error=0.193148 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1970 loss=0.319140 error=0.192988 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: validation 197 loss=0.318936 error=0.192829 grad(V)=0.000004 grad(U)=0.000008 *\n",
      "downhill: Adam 1971 loss=0.318936 error=0.192829 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1972 loss=0.318731 error=0.192669 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1973 loss=0.318527 error=0.192509 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1974 loss=0.318323 error=0.192350 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1975 loss=0.318119 error=0.192191 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1976 loss=0.317916 error=0.192032 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1977 loss=0.317712 error=0.191873 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1978 loss=0.317509 error=0.191714 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1979 loss=0.317306 error=0.191556 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1980 loss=0.317103 error=0.191398 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: validation 198 loss=0.316901 error=0.191239 grad(V)=0.000004 grad(U)=0.000008 *\n",
      "downhill: Adam 1981 loss=0.316901 error=0.191239 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1982 loss=0.316698 error=0.191081 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1983 loss=0.316496 error=0.190923 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1984 loss=0.316294 error=0.190766 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1985 loss=0.316092 error=0.190608 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1986 loss=0.315890 error=0.190450 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1987 loss=0.315689 error=0.190293 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1988 loss=0.315488 error=0.190136 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1989 loss=0.315287 error=0.189979 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1990 loss=0.315086 error=0.189822 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: validation 199 loss=0.314885 error=0.189665 grad(V)=0.000004 grad(U)=0.000008 *\n",
      "downhill: Adam 1991 loss=0.314885 error=0.189665 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1992 loss=0.314685 error=0.189508 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1993 loss=0.314484 error=0.189351 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1994 loss=0.314284 error=0.189195 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1995 loss=0.314084 error=0.189039 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1996 loss=0.313884 error=0.188882 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1997 loss=0.313684 error=0.188726 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1998 loss=0.313485 error=0.188571 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 1999 loss=0.313285 error=0.188415 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 2000 loss=0.313086 error=0.188259 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: validation 200 loss=0.312887 error=0.188103 grad(V)=0.000004 grad(U)=0.000008 *\n",
      "downhill: Adam 2001 loss=0.312887 error=0.188103 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 2002 loss=0.312689 error=0.187947 grad(V)=0.000004 grad(U)=0.000008\n",
      "downhill: Adam 2003 loss=0.312490 error=0.187792 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2004 loss=0.312292 error=0.187636 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2005 loss=0.312093 error=0.187481 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2006 loss=0.311895 error=0.187326 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2007 loss=0.311697 error=0.187172 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2008 loss=0.311499 error=0.187017 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2009 loss=0.311301 error=0.186863 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2010 loss=0.311104 error=0.186708 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: validation 201 loss=0.310907 error=0.186554 grad(V)=0.000003 grad(U)=0.000008 *\n",
      "downhill: Adam 2011 loss=0.310907 error=0.186554 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2012 loss=0.310709 error=0.186399 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2013 loss=0.310513 error=0.186245 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2014 loss=0.310316 error=0.186091 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2015 loss=0.310119 error=0.185937 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2016 loss=0.309923 error=0.185783 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2017 loss=0.309726 error=0.185630 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2018 loss=0.309530 error=0.185476 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2019 loss=0.309334 error=0.185322 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2020 loss=0.309139 error=0.185169 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: validation 202 loss=0.308943 error=0.185016 grad(V)=0.000003 grad(U)=0.000008 *\n",
      "downhill: Adam 2021 loss=0.308943 error=0.185016 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2022 loss=0.308748 error=0.184862 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2023 loss=0.308553 error=0.184709 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2024 loss=0.308358 error=0.184556 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2025 loss=0.308163 error=0.184403 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2026 loss=0.307968 error=0.184251 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2027 loss=0.307773 error=0.184098 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2028 loss=0.307578 error=0.183945 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2029 loss=0.307384 error=0.183793 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2030 loss=0.307190 error=0.183640 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: validation 203 loss=0.306996 error=0.183488 grad(V)=0.000003 grad(U)=0.000008 *\n",
      "downhill: Adam 2031 loss=0.306996 error=0.183488 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2032 loss=0.306802 error=0.183336 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2033 loss=0.306609 error=0.183183 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2034 loss=0.306415 error=0.183031 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2035 loss=0.306222 error=0.182879 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2036 loss=0.306029 error=0.182727 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2037 loss=0.305836 error=0.182575 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2038 loss=0.305643 error=0.182423 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2039 loss=0.305450 error=0.182272 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2040 loss=0.305258 error=0.182120 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: validation 204 loss=0.305066 error=0.181969 grad(V)=0.000003 grad(U)=0.000008 *\n",
      "downhill: Adam 2041 loss=0.305066 error=0.181969 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2042 loss=0.304874 error=0.181817 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2043 loss=0.304682 error=0.181666 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2044 loss=0.304490 error=0.181515 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2045 loss=0.304298 error=0.181364 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2046 loss=0.304106 error=0.181213 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2047 loss=0.303915 error=0.181061 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2048 loss=0.303724 error=0.180910 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2049 loss=0.303533 error=0.180759 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2050 loss=0.303342 error=0.180608 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: validation 205 loss=0.303151 error=0.180457 grad(V)=0.000003 grad(U)=0.000008 *\n",
      "downhill: Adam 2051 loss=0.303151 error=0.180457 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2052 loss=0.302960 error=0.180307 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2053 loss=0.302770 error=0.180156 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2054 loss=0.302580 error=0.180006 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2055 loss=0.302390 error=0.179856 grad(V)=0.000003 grad(U)=0.000008\n",
      "downhill: Adam 2056 loss=0.302200 error=0.179705 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2057 loss=0.302010 error=0.179555 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2058 loss=0.301820 error=0.179405 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2059 loss=0.301630 error=0.179255 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2060 loss=0.301441 error=0.179105 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 206 loss=0.301251 error=0.178955 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2061 loss=0.301251 error=0.178955 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2062 loss=0.301062 error=0.178805 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2063 loss=0.300873 error=0.178655 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2064 loss=0.300684 error=0.178505 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2065 loss=0.300495 error=0.178356 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2066 loss=0.300306 error=0.178206 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2067 loss=0.300117 error=0.178056 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2068 loss=0.299929 error=0.177907 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2069 loss=0.299741 error=0.177757 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2070 loss=0.299552 error=0.177607 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 207 loss=0.299364 error=0.177458 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2071 loss=0.299364 error=0.177458 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2072 loss=0.299176 error=0.177309 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2073 loss=0.298988 error=0.177159 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2074 loss=0.298801 error=0.177010 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2075 loss=0.298613 error=0.176860 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2076 loss=0.298425 error=0.176711 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2077 loss=0.298238 error=0.176562 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2078 loss=0.298050 error=0.176413 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2079 loss=0.297863 error=0.176264 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2080 loss=0.297676 error=0.176115 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 208 loss=0.297489 error=0.175966 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2081 loss=0.297489 error=0.175966 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2082 loss=0.297303 error=0.175817 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2083 loss=0.297116 error=0.175668 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2084 loss=0.296930 error=0.175519 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2085 loss=0.296743 error=0.175370 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2086 loss=0.296557 error=0.175222 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2087 loss=0.296370 error=0.175073 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2088 loss=0.296184 error=0.174924 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2089 loss=0.295998 error=0.174775 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2090 loss=0.295812 error=0.174627 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 209 loss=0.295627 error=0.174478 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2091 loss=0.295627 error=0.174478 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2092 loss=0.295441 error=0.174329 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2093 loss=0.295255 error=0.174181 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2094 loss=0.295070 error=0.174033 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2095 loss=0.294884 error=0.173884 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2096 loss=0.294699 error=0.173736 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2097 loss=0.294514 error=0.173587 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2098 loss=0.294329 error=0.173439 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2099 loss=0.294144 error=0.173291 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2100 loss=0.293959 error=0.173143 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 210 loss=0.293774 error=0.172994 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2101 loss=0.293774 error=0.172994 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2102 loss=0.293589 error=0.172846 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2103 loss=0.293405 error=0.172698 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2104 loss=0.293220 error=0.172550 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2105 loss=0.293036 error=0.172402 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2106 loss=0.292851 error=0.172253 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2107 loss=0.292667 error=0.172105 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2108 loss=0.292483 error=0.171957 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2109 loss=0.292299 error=0.171809 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2110 loss=0.292115 error=0.171661 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 211 loss=0.291931 error=0.171513 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2111 loss=0.291931 error=0.171513 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2112 loss=0.291747 error=0.171365 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2113 loss=0.291564 error=0.171217 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2114 loss=0.291380 error=0.171069 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2115 loss=0.291197 error=0.170922 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2116 loss=0.291014 error=0.170774 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2117 loss=0.290830 error=0.170626 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2118 loss=0.290647 error=0.170478 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2119 loss=0.290464 error=0.170330 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2120 loss=0.290281 error=0.170182 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 212 loss=0.290098 error=0.170035 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2121 loss=0.290098 error=0.170035 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2122 loss=0.289915 error=0.169887 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2123 loss=0.289733 error=0.169739 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2124 loss=0.289550 error=0.169592 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2125 loss=0.289368 error=0.169444 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2126 loss=0.289186 error=0.169296 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2127 loss=0.289003 error=0.169149 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2128 loss=0.288821 error=0.169001 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2129 loss=0.288639 error=0.168854 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2130 loss=0.288457 error=0.168707 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 213 loss=0.288275 error=0.168559 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2131 loss=0.288275 error=0.168559 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2132 loss=0.288094 error=0.168412 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2133 loss=0.287912 error=0.168264 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2134 loss=0.287730 error=0.168117 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2135 loss=0.287549 error=0.167969 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2136 loss=0.287367 error=0.167822 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2137 loss=0.287186 error=0.167675 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2138 loss=0.287005 error=0.167528 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2139 loss=0.286824 error=0.167380 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2140 loss=0.286643 error=0.167233 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: validation 214 loss=0.286462 error=0.167086 grad(V)=0.000002 grad(U)=0.000008 *\n",
      "downhill: Adam 2141 loss=0.286462 error=0.167086 grad(V)=0.000002 grad(U)=0.000008\n",
      "downhill: Adam 2142 loss=0.286282 error=0.166939 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2143 loss=0.286101 error=0.166791 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2144 loss=0.285921 error=0.166644 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2145 loss=0.285740 error=0.166497 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2146 loss=0.285559 error=0.166350 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2147 loss=0.285379 error=0.166203 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2148 loss=0.285199 error=0.166056 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2149 loss=0.285019 error=0.165909 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2150 loss=0.284839 error=0.165762 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 215 loss=0.284659 error=0.165615 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2151 loss=0.284659 error=0.165615 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2152 loss=0.284479 error=0.165468 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2153 loss=0.284299 error=0.165321 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2154 loss=0.284120 error=0.165174 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2155 loss=0.283940 error=0.165028 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2156 loss=0.283760 error=0.164881 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2157 loss=0.283581 error=0.164734 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2158 loss=0.283401 error=0.164588 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2159 loss=0.283222 error=0.164441 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2160 loss=0.283043 error=0.164294 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 216 loss=0.282864 error=0.164148 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2161 loss=0.282864 error=0.164148 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2162 loss=0.282685 error=0.164001 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2163 loss=0.282506 error=0.163854 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2164 loss=0.282327 error=0.163708 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2165 loss=0.282149 error=0.163561 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2166 loss=0.281970 error=0.163415 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2167 loss=0.281792 error=0.163268 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2168 loss=0.281614 error=0.163122 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2169 loss=0.281436 error=0.162976 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2170 loss=0.281257 error=0.162829 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 217 loss=0.281079 error=0.162683 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2171 loss=0.281079 error=0.162683 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2172 loss=0.280902 error=0.162537 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2173 loss=0.280724 error=0.162391 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2174 loss=0.280546 error=0.162244 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2175 loss=0.280368 error=0.162098 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2176 loss=0.280191 error=0.161952 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2177 loss=0.280014 error=0.161806 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2178 loss=0.279836 error=0.161660 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2179 loss=0.279659 error=0.161514 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2180 loss=0.279482 error=0.161368 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 218 loss=0.279305 error=0.161222 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2181 loss=0.279305 error=0.161222 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2182 loss=0.279129 error=0.161077 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2183 loss=0.278952 error=0.160931 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2184 loss=0.278775 error=0.160785 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2185 loss=0.278598 error=0.160640 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2186 loss=0.278422 error=0.160494 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2187 loss=0.278245 error=0.160349 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2188 loss=0.278069 error=0.160204 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2189 loss=0.277893 error=0.160058 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2190 loss=0.277716 error=0.159913 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 219 loss=0.277540 error=0.159768 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2191 loss=0.277540 error=0.159768 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2192 loss=0.277364 error=0.159623 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2193 loss=0.277188 error=0.159478 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2194 loss=0.277013 error=0.159333 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2195 loss=0.276837 error=0.159188 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2196 loss=0.276662 error=0.159043 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2197 loss=0.276486 error=0.158898 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2198 loss=0.276311 error=0.158754 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2199 loss=0.276136 error=0.158609 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2200 loss=0.275961 error=0.158464 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 220 loss=0.275786 error=0.158320 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2201 loss=0.275786 error=0.158320 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2202 loss=0.275611 error=0.158175 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2203 loss=0.275436 error=0.158031 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2204 loss=0.275262 error=0.157887 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2205 loss=0.275087 error=0.157742 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2206 loss=0.274913 error=0.157598 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2207 loss=0.274739 error=0.157454 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2208 loss=0.274565 error=0.157311 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2209 loss=0.274391 error=0.157167 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2210 loss=0.274217 error=0.157023 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 221 loss=0.274043 error=0.156879 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2211 loss=0.274043 error=0.156879 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2212 loss=0.273869 error=0.156736 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2213 loss=0.273695 error=0.156592 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2214 loss=0.273522 error=0.156449 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2215 loss=0.273348 error=0.156306 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2216 loss=0.273175 error=0.156163 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2217 loss=0.273002 error=0.156020 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2218 loss=0.272829 error=0.155877 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2219 loss=0.272656 error=0.155733 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2220 loss=0.272483 error=0.155590 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 222 loss=0.272310 error=0.155447 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2221 loss=0.272310 error=0.155447 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2222 loss=0.272138 error=0.155304 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2223 loss=0.271965 error=0.155161 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2224 loss=0.271793 error=0.155018 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2225 loss=0.271621 error=0.154876 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2226 loss=0.271449 error=0.154733 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2227 loss=0.271277 error=0.154591 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2228 loss=0.271105 error=0.154448 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2229 loss=0.270934 error=0.154306 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2230 loss=0.270762 error=0.154164 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 223 loss=0.270591 error=0.154022 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2231 loss=0.270591 error=0.154022 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2232 loss=0.270419 error=0.153880 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2233 loss=0.270248 error=0.153738 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2234 loss=0.270077 error=0.153597 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2235 loss=0.269906 error=0.153455 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2236 loss=0.269736 error=0.153313 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2237 loss=0.269565 error=0.153172 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2238 loss=0.269395 error=0.153030 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2239 loss=0.269224 error=0.152889 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2240 loss=0.269054 error=0.152748 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 224 loss=0.268884 error=0.152607 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2241 loss=0.268884 error=0.152607 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2242 loss=0.268714 error=0.152466 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2243 loss=0.268544 error=0.152325 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2244 loss=0.268375 error=0.152184 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2245 loss=0.268206 error=0.152043 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2246 loss=0.268036 error=0.151903 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2247 loss=0.267867 error=0.151762 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2248 loss=0.267698 error=0.151622 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2249 loss=0.267530 error=0.151481 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2250 loss=0.267361 error=0.151341 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 225 loss=0.267192 error=0.151201 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2251 loss=0.267192 error=0.151201 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2252 loss=0.267024 error=0.151061 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2253 loss=0.266856 error=0.150922 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2254 loss=0.266687 error=0.150782 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2255 loss=0.266519 error=0.150643 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2256 loss=0.266351 error=0.150503 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2257 loss=0.266184 error=0.150364 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2258 loss=0.266016 error=0.150225 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2259 loss=0.265849 error=0.150086 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2260 loss=0.265681 error=0.149948 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 226 loss=0.265514 error=0.149809 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2261 loss=0.265514 error=0.149809 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2262 loss=0.265347 error=0.149671 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2263 loss=0.265181 error=0.149532 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2264 loss=0.265014 error=0.149394 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2265 loss=0.264848 error=0.149256 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2266 loss=0.264681 error=0.149118 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2267 loss=0.264515 error=0.148980 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2268 loss=0.264349 error=0.148843 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2269 loss=0.264183 error=0.148705 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2270 loss=0.264018 error=0.148568 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 227 loss=0.263853 error=0.148431 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2271 loss=0.263853 error=0.148431 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2272 loss=0.263687 error=0.148293 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2273 loss=0.263522 error=0.148157 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2274 loss=0.263357 error=0.148020 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2275 loss=0.263192 error=0.147884 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2276 loss=0.263028 error=0.147747 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2277 loss=0.262863 error=0.147611 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2278 loss=0.262699 error=0.147475 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2279 loss=0.262535 error=0.147339 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2280 loss=0.262371 error=0.147203 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 228 loss=0.262207 error=0.147068 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2281 loss=0.262207 error=0.147068 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2282 loss=0.262044 error=0.146933 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2283 loss=0.261881 error=0.146797 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2284 loss=0.261717 error=0.146662 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2285 loss=0.261554 error=0.146527 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2286 loss=0.261392 error=0.146393 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2287 loss=0.261229 error=0.146259 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2288 loss=0.261067 error=0.146124 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2289 loss=0.260905 error=0.145990 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2290 loss=0.260742 error=0.145856 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 229 loss=0.260580 error=0.145723 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2291 loss=0.260580 error=0.145723 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2292 loss=0.260418 error=0.145589 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2293 loss=0.260257 error=0.145455 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2294 loss=0.260095 error=0.145322 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2295 loss=0.259934 error=0.145189 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2296 loss=0.259773 error=0.145056 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2297 loss=0.259612 error=0.144923 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2298 loss=0.259451 error=0.144790 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2299 loss=0.259291 error=0.144658 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2300 loss=0.259130 error=0.144526 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 230 loss=0.258970 error=0.144393 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2301 loss=0.258970 error=0.144393 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2302 loss=0.258810 error=0.144261 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2303 loss=0.258650 error=0.144129 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2304 loss=0.258491 error=0.143998 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2305 loss=0.258331 error=0.143866 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2306 loss=0.258172 error=0.143735 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2307 loss=0.258013 error=0.143604 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2308 loss=0.257854 error=0.143473 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2309 loss=0.257695 error=0.143343 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2310 loss=0.257537 error=0.143212 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 231 loss=0.257378 error=0.143082 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2311 loss=0.257378 error=0.143082 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2312 loss=0.257220 error=0.142952 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2313 loss=0.257062 error=0.142822 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2314 loss=0.256904 error=0.142693 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2315 loss=0.256747 error=0.142563 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2316 loss=0.256589 error=0.142434 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2317 loss=0.256432 error=0.142305 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2318 loss=0.256275 error=0.142176 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2319 loss=0.256118 error=0.142047 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2320 loss=0.255962 error=0.141919 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 232 loss=0.255805 error=0.141790 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2321 loss=0.255805 error=0.141790 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2322 loss=0.255649 error=0.141662 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2323 loss=0.255493 error=0.141534 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2324 loss=0.255337 error=0.141406 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2325 loss=0.255181 error=0.141279 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2326 loss=0.255026 error=0.141151 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2327 loss=0.254871 error=0.141024 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2328 loss=0.254716 error=0.140897 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2329 loss=0.254561 error=0.140770 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2330 loss=0.254406 error=0.140643 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 233 loss=0.254252 error=0.140517 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2331 loss=0.254252 error=0.140517 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2332 loss=0.254097 error=0.140391 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2333 loss=0.253943 error=0.140265 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2334 loss=0.253789 error=0.140139 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2335 loss=0.253635 error=0.140014 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2336 loss=0.253482 error=0.139888 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2337 loss=0.253329 error=0.139763 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2338 loss=0.253176 error=0.139638 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2339 loss=0.253023 error=0.139513 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2340 loss=0.252870 error=0.139389 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 234 loss=0.252718 error=0.139264 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2341 loss=0.252718 error=0.139264 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2342 loss=0.252566 error=0.139140 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2343 loss=0.252414 error=0.139016 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2344 loss=0.252262 error=0.138892 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2345 loss=0.252110 error=0.138769 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2346 loss=0.251959 error=0.138646 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2347 loss=0.251808 error=0.138523 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2348 loss=0.251657 error=0.138400 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2349 loss=0.251506 error=0.138277 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2350 loss=0.251356 error=0.138155 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 235 loss=0.251205 error=0.138033 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2351 loss=0.251205 error=0.138033 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2352 loss=0.251055 error=0.137911 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2353 loss=0.250906 error=0.137789 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2354 loss=0.250756 error=0.137667 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2355 loss=0.250607 error=0.137545 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2356 loss=0.250458 error=0.137424 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2357 loss=0.250309 error=0.137303 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2358 loss=0.250161 error=0.137182 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2359 loss=0.250013 error=0.137062 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2360 loss=0.249864 error=0.136941 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 236 loss=0.249717 error=0.136821 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2361 loss=0.249717 error=0.136821 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2362 loss=0.249569 error=0.136702 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2363 loss=0.249422 error=0.136582 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2364 loss=0.249275 error=0.136463 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2365 loss=0.249128 error=0.136344 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2366 loss=0.248981 error=0.136225 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2367 loss=0.248834 error=0.136106 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2368 loss=0.248688 error=0.135988 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2369 loss=0.248542 error=0.135869 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2370 loss=0.248396 error=0.135752 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 237 loss=0.248251 error=0.135634 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2371 loss=0.248251 error=0.135634 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2372 loss=0.248105 error=0.135517 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2373 loss=0.247960 error=0.135400 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2374 loss=0.247816 error=0.135283 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2375 loss=0.247671 error=0.135166 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2376 loss=0.247527 error=0.135050 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2377 loss=0.247382 error=0.134934 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2378 loss=0.247238 error=0.134818 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2379 loss=0.247095 error=0.134702 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2380 loss=0.246951 error=0.134586 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 238 loss=0.246808 error=0.134471 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2381 loss=0.246808 error=0.134471 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2382 loss=0.246665 error=0.134356 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2383 loss=0.246523 error=0.134241 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2384 loss=0.246380 error=0.134126 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2385 loss=0.246238 error=0.134011 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2386 loss=0.246096 error=0.133897 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2387 loss=0.245954 error=0.133783 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2388 loss=0.245812 error=0.133669 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2389 loss=0.245671 error=0.133555 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2390 loss=0.245529 error=0.133442 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 239 loss=0.245388 error=0.133329 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2391 loss=0.245388 error=0.133329 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2392 loss=0.245247 error=0.133216 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2393 loss=0.245107 error=0.133103 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2394 loss=0.244966 error=0.132991 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2395 loss=0.244826 error=0.132879 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2396 loss=0.244686 error=0.132767 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2397 loss=0.244546 error=0.132655 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2398 loss=0.244407 error=0.132544 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2399 loss=0.244268 error=0.132432 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2400 loss=0.244128 error=0.132321 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 240 loss=0.243990 error=0.132210 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2401 loss=0.243990 error=0.132210 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2402 loss=0.243851 error=0.132099 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2403 loss=0.243713 error=0.131989 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2404 loss=0.243574 error=0.131878 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2405 loss=0.243436 error=0.131769 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2406 loss=0.243299 error=0.131659 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2407 loss=0.243161 error=0.131549 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2408 loss=0.243024 error=0.131440 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2409 loss=0.242887 error=0.131330 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2410 loss=0.242750 error=0.131221 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: validation 241 loss=0.242613 error=0.131112 grad(V)=0.000001 grad(U)=0.000008 *\n",
      "downhill: Adam 2411 loss=0.242613 error=0.131112 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2412 loss=0.242477 error=0.131003 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2413 loss=0.242341 error=0.130895 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2414 loss=0.242205 error=0.130786 grad(V)=0.000001 grad(U)=0.000008\n",
      "downhill: Adam 2415 loss=0.242069 error=0.130678 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2416 loss=0.241933 error=0.130571 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2417 loss=0.241798 error=0.130463 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2418 loss=0.241663 error=0.130356 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2419 loss=0.241528 error=0.130249 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2420 loss=0.241393 error=0.130142 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: validation 242 loss=0.241259 error=0.130035 grad(V)=0.000000 grad(U)=0.000008 *\n",
      "downhill: Adam 2421 loss=0.241259 error=0.130035 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2422 loss=0.241125 error=0.129929 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2423 loss=0.240991 error=0.129823 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2424 loss=0.240857 error=0.129717 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2425 loss=0.240724 error=0.129611 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2426 loss=0.240591 error=0.129505 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2427 loss=0.240458 error=0.129400 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2428 loss=0.240325 error=0.129295 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2429 loss=0.240193 error=0.129190 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2430 loss=0.240060 error=0.129085 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: validation 243 loss=0.239928 error=0.128981 grad(V)=0.000000 grad(U)=0.000008 *\n",
      "downhill: Adam 2431 loss=0.239928 error=0.128981 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2432 loss=0.239797 error=0.128876 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2433 loss=0.239665 error=0.128772 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2434 loss=0.239534 error=0.128668 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2435 loss=0.239403 error=0.128565 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2436 loss=0.239272 error=0.128461 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2437 loss=0.239141 error=0.128358 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2438 loss=0.239011 error=0.128255 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2439 loss=0.238880 error=0.128152 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2440 loss=0.238750 error=0.128050 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 244 loss=0.238620 error=0.127947 grad(V)=0.000000 grad(U)=0.000008 *\n",
      "downhill: Adam 2441 loss=0.238620 error=0.127947 grad(V)=0.000000 grad(U)=0.000008\n",
      "downhill: Adam 2442 loss=0.238491 error=0.127845 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2443 loss=0.238361 error=0.127743 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2444 loss=0.238233 error=0.127641 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2445 loss=0.238104 error=0.127540 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2446 loss=0.237975 error=0.127439 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2447 loss=0.237846 error=0.127338 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2448 loss=0.237718 error=0.127237 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2449 loss=0.237590 error=0.127136 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2450 loss=0.237463 error=0.127036 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 245 loss=0.237335 error=0.126936 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2451 loss=0.237335 error=0.126936 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2452 loss=0.237208 error=0.126836 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2453 loss=0.237081 error=0.126736 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2454 loss=0.236954 error=0.126636 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2455 loss=0.236828 error=0.126537 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2456 loss=0.236701 error=0.126438 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2457 loss=0.236575 error=0.126339 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2458 loss=0.236449 error=0.126240 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2459 loss=0.236324 error=0.126142 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2460 loss=0.236198 error=0.126043 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 246 loss=0.236073 error=0.125945 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2461 loss=0.236073 error=0.125945 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2462 loss=0.235948 error=0.125847 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2463 loss=0.235823 error=0.125749 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2464 loss=0.235699 error=0.125651 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2465 loss=0.235575 error=0.125554 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2466 loss=0.235451 error=0.125457 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2467 loss=0.235327 error=0.125360 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2468 loss=0.235204 error=0.125264 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2469 loss=0.235080 error=0.125167 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2470 loss=0.234957 error=0.125071 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 247 loss=0.234834 error=0.124975 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2471 loss=0.234834 error=0.124975 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2472 loss=0.234712 error=0.124879 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2473 loss=0.234590 error=0.124784 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2474 loss=0.234468 error=0.124688 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2475 loss=0.234346 error=0.124593 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2476 loss=0.234225 error=0.124498 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2477 loss=0.234103 error=0.124404 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2478 loss=0.233982 error=0.124309 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2479 loss=0.233862 error=0.124215 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2480 loss=0.233741 error=0.124121 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 248 loss=0.233621 error=0.124028 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2481 loss=0.233621 error=0.124028 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2482 loss=0.233501 error=0.123934 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2483 loss=0.233381 error=0.123841 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2484 loss=0.233261 error=0.123747 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2485 loss=0.233142 error=0.123655 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2486 loss=0.233023 error=0.123561 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2487 loss=0.232904 error=0.123469 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2488 loss=0.232785 error=0.123376 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2489 loss=0.232666 error=0.123284 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2490 loss=0.232548 error=0.123192 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 249 loss=0.232430 error=0.123101 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2491 loss=0.232430 error=0.123101 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2492 loss=0.232312 error=0.123010 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2493 loss=0.232195 error=0.122918 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2494 loss=0.232077 error=0.122828 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2495 loss=0.231960 error=0.122737 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2496 loss=0.231844 error=0.122646 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2497 loss=0.231727 error=0.122556 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2498 loss=0.231611 error=0.122466 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2499 loss=0.231495 error=0.122376 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2500 loss=0.231379 error=0.122286 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 250 loss=0.231264 error=0.122196 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2501 loss=0.231264 error=0.122196 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2502 loss=0.231149 error=0.122107 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2503 loss=0.231033 error=0.122018 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2504 loss=0.230919 error=0.121929 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2505 loss=0.230804 error=0.121841 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2506 loss=0.230690 error=0.121752 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2507 loss=0.230575 error=0.121664 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2508 loss=0.230461 error=0.121576 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2509 loss=0.230348 error=0.121488 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2510 loss=0.230234 error=0.121400 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 251 loss=0.230121 error=0.121313 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2511 loss=0.230121 error=0.121313 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2512 loss=0.230008 error=0.121226 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2513 loss=0.229895 error=0.121139 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2514 loss=0.229783 error=0.121052 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2515 loss=0.229670 error=0.120965 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2516 loss=0.229558 error=0.120879 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2517 loss=0.229447 error=0.120793 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2518 loss=0.229335 error=0.120706 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2519 loss=0.229224 error=0.120621 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2520 loss=0.229113 error=0.120535 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 252 loss=0.229002 error=0.120450 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2521 loss=0.229002 error=0.120450 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2522 loss=0.228891 error=0.120365 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2523 loss=0.228781 error=0.120280 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2524 loss=0.228671 error=0.120195 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2525 loss=0.228561 error=0.120111 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2526 loss=0.228451 error=0.120026 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2527 loss=0.228342 error=0.119942 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2528 loss=0.228232 error=0.119858 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2529 loss=0.228123 error=0.119774 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2530 loss=0.228015 error=0.119690 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 253 loss=0.227906 error=0.119607 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2531 loss=0.227906 error=0.119607 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2532 loss=0.227798 error=0.119523 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2533 loss=0.227690 error=0.119440 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2534 loss=0.227582 error=0.119357 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2535 loss=0.227474 error=0.119275 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2536 loss=0.227367 error=0.119192 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2537 loss=0.227260 error=0.119110 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2538 loss=0.227153 error=0.119028 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2539 loss=0.227046 error=0.118946 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2540 loss=0.226939 error=0.118864 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 254 loss=0.226833 error=0.118782 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2541 loss=0.226833 error=0.118782 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2542 loss=0.226727 error=0.118700 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2543 loss=0.226621 error=0.118619 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2544 loss=0.226515 error=0.118538 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2545 loss=0.226410 error=0.118458 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2546 loss=0.226304 error=0.118377 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2547 loss=0.226199 error=0.118297 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2548 loss=0.226095 error=0.118216 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2549 loss=0.225990 error=0.118136 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2550 loss=0.225886 error=0.118056 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 255 loss=0.225782 error=0.117976 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2551 loss=0.225782 error=0.117976 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2552 loss=0.225677 error=0.117897 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2553 loss=0.225574 error=0.117817 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2554 loss=0.225470 error=0.117738 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2555 loss=0.225367 error=0.117659 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2556 loss=0.225264 error=0.117580 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2557 loss=0.225161 error=0.117501 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2558 loss=0.225059 error=0.117423 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2559 loss=0.224956 error=0.117344 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2560 loss=0.224854 error=0.117266 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 256 loss=0.224752 error=0.117188 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2561 loss=0.224752 error=0.117188 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2562 loss=0.224651 error=0.117110 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2563 loss=0.224549 error=0.117032 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2564 loss=0.224448 error=0.116955 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2565 loss=0.224347 error=0.116878 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2566 loss=0.224246 error=0.116800 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2567 loss=0.224146 error=0.116723 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2568 loss=0.224045 error=0.116647 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2569 loss=0.223945 error=0.116570 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2570 loss=0.223845 error=0.116494 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 257 loss=0.223746 error=0.116418 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2571 loss=0.223746 error=0.116418 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2572 loss=0.223646 error=0.116342 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2573 loss=0.223547 error=0.116266 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2574 loss=0.223448 error=0.116190 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2575 loss=0.223349 error=0.116115 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2576 loss=0.223251 error=0.116039 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2577 loss=0.223152 error=0.115964 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2578 loss=0.223054 error=0.115889 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2579 loss=0.222956 error=0.115814 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2580 loss=0.222859 error=0.115740 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 258 loss=0.222761 error=0.115665 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2581 loss=0.222761 error=0.115665 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2582 loss=0.222664 error=0.115591 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2583 loss=0.222567 error=0.115517 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2584 loss=0.222470 error=0.115443 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2585 loss=0.222373 error=0.115369 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2586 loss=0.222277 error=0.115296 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2587 loss=0.222180 error=0.115222 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2588 loss=0.222085 error=0.115149 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2589 loss=0.221989 error=0.115076 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2590 loss=0.221894 error=0.115003 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 259 loss=0.221798 error=0.114930 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2591 loss=0.221798 error=0.114930 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2592 loss=0.221703 error=0.114858 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2593 loss=0.221608 error=0.114785 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2594 loss=0.221513 error=0.114713 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2595 loss=0.221419 error=0.114641 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2596 loss=0.221325 error=0.114569 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2597 loss=0.221231 error=0.114497 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2598 loss=0.221137 error=0.114425 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2599 loss=0.221043 error=0.114354 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2600 loss=0.220950 error=0.114283 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 260 loss=0.220857 error=0.114212 grad(V)=0.000000 grad(U)=0.000007 *\n",
      "downhill: Adam 2601 loss=0.220857 error=0.114212 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2602 loss=0.220764 error=0.114141 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2603 loss=0.220671 error=0.114070 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2604 loss=0.220579 error=0.113999 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2605 loss=0.220486 error=0.113929 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2606 loss=0.220394 error=0.113858 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2607 loss=0.220303 error=0.113788 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2608 loss=0.220211 error=0.113718 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2609 loss=0.220120 error=0.113648 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2610 loss=0.220029 error=0.113579 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: validation 261 loss=0.219938 error=0.113509 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2611 loss=0.219938 error=0.113509 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2612 loss=0.219847 error=0.113440 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2613 loss=0.219756 error=0.113371 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2614 loss=0.219666 error=0.113302 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2615 loss=0.219576 error=0.113233 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2616 loss=0.219486 error=0.113164 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2617 loss=0.219396 error=0.113095 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2618 loss=0.219306 error=0.113027 grad(V)=0.000000 grad(U)=0.000007\n",
      "downhill: Adam 2619 loss=0.219217 error=0.112959 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2620 loss=0.219128 error=0.112891 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 262 loss=0.219039 error=0.112823 grad(V)=0.000000 grad(U)=0.000006 *\n",
      "downhill: Adam 2621 loss=0.219039 error=0.112823 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2622 loss=0.218950 error=0.112755 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2623 loss=0.218862 error=0.112687 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2624 loss=0.218774 error=0.112620 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2625 loss=0.218686 error=0.112552 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2626 loss=0.218598 error=0.112485 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2627 loss=0.218510 error=0.112418 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2628 loss=0.218423 error=0.112351 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2629 loss=0.218335 error=0.112284 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2630 loss=0.218248 error=0.112217 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 263 loss=0.218161 error=0.112151 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2631 loss=0.218161 error=0.112151 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2632 loss=0.218075 error=0.112084 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2633 loss=0.217988 error=0.112018 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2634 loss=0.217902 error=0.111952 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2635 loss=0.217816 error=0.111887 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2636 loss=0.217730 error=0.111820 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2637 loss=0.217645 error=0.111755 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2638 loss=0.217559 error=0.111690 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2639 loss=0.217474 error=0.111624 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2640 loss=0.217389 error=0.111559 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 264 loss=0.217304 error=0.111494 grad(V)=0.000000 grad(U)=0.000006 *\n",
      "downhill: Adam 2641 loss=0.217304 error=0.111494 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2642 loss=0.217219 error=0.111429 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2643 loss=0.217135 error=0.111364 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2644 loss=0.217051 error=0.111300 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2645 loss=0.216967 error=0.111235 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2646 loss=0.216883 error=0.111171 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2647 loss=0.216799 error=0.111106 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2648 loss=0.216716 error=0.111042 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2649 loss=0.216633 error=0.110979 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2650 loss=0.216550 error=0.110915 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 265 loss=0.216467 error=0.110851 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2651 loss=0.216467 error=0.110851 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2652 loss=0.216384 error=0.110788 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2653 loss=0.216302 error=0.110725 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2654 loss=0.216220 error=0.110662 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2655 loss=0.216138 error=0.110599 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2656 loss=0.216056 error=0.110536 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2657 loss=0.215975 error=0.110474 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2658 loss=0.215893 error=0.110411 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2659 loss=0.215812 error=0.110349 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2660 loss=0.215731 error=0.110287 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 266 loss=0.215651 error=0.110225 grad(V)=0.000000 grad(U)=0.000006 *\n",
      "downhill: Adam 2661 loss=0.215651 error=0.110225 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2662 loss=0.215570 error=0.110163 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2663 loss=0.215490 error=0.110101 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2664 loss=0.215410 error=0.110040 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2665 loss=0.215330 error=0.109979 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2666 loss=0.215250 error=0.109917 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2667 loss=0.215171 error=0.109856 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2668 loss=0.215091 error=0.109795 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2669 loss=0.215012 error=0.109734 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2670 loss=0.214933 error=0.109673 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 267 loss=0.214854 error=0.109613 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2671 loss=0.214854 error=0.109613 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2672 loss=0.214776 error=0.109552 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2673 loss=0.214698 error=0.109492 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2674 loss=0.214620 error=0.109432 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2675 loss=0.214542 error=0.109372 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2676 loss=0.214464 error=0.109312 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2677 loss=0.214387 error=0.109253 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2678 loss=0.214309 error=0.109193 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2679 loss=0.214232 error=0.109134 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2680 loss=0.214155 error=0.109075 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 268 loss=0.214079 error=0.109016 grad(V)=0.000000 grad(U)=0.000006 *\n",
      "downhill: Adam 2681 loss=0.214079 error=0.109016 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2682 loss=0.214002 error=0.108957 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2683 loss=0.213926 error=0.108898 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2684 loss=0.213850 error=0.108840 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2685 loss=0.213774 error=0.108781 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2686 loss=0.213699 error=0.108723 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2687 loss=0.213623 error=0.108665 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2688 loss=0.213548 error=0.108607 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2689 loss=0.213473 error=0.108549 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2690 loss=0.213398 error=0.108491 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 269 loss=0.213323 error=0.108434 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2691 loss=0.213323 error=0.108434 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2692 loss=0.213249 error=0.108376 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2693 loss=0.213174 error=0.108319 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2694 loss=0.213100 error=0.108261 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2695 loss=0.213026 error=0.108205 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2696 loss=0.212952 error=0.108148 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2697 loss=0.212879 error=0.108091 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2698 loss=0.212806 error=0.108035 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2699 loss=0.212732 error=0.107979 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2700 loss=0.212659 error=0.107922 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 270 loss=0.212587 error=0.107866 grad(V)=0.000000 grad(U)=0.000006 *\n",
      "downhill: Adam 2701 loss=0.212587 error=0.107866 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2702 loss=0.212514 error=0.107810 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2703 loss=0.212442 error=0.107755 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2704 loss=0.212370 error=0.107699 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2705 loss=0.212298 error=0.107643 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2706 loss=0.212226 error=0.107587 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2707 loss=0.212155 error=0.107532 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2708 loss=0.212083 error=0.107476 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2709 loss=0.212012 error=0.107423 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2710 loss=0.211941 error=0.107366 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 271 loss=0.211870 error=0.107313 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2711 loss=0.211870 error=0.107313 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2712 loss=0.211800 error=0.107257 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2713 loss=0.211730 error=0.107203 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2714 loss=0.211660 error=0.107149 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2715 loss=0.211590 error=0.107094 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2716 loss=0.211520 error=0.107041 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2717 loss=0.211451 error=0.106987 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2718 loss=0.211381 error=0.106933 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2719 loss=0.211312 error=0.106880 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2720 loss=0.211243 error=0.106826 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 272 loss=0.211174 error=0.106773 grad(V)=0.000000 grad(U)=0.000006 *\n",
      "downhill: Adam 2721 loss=0.211174 error=0.106773 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2722 loss=0.211106 error=0.106720 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2723 loss=0.211037 error=0.106667 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2724 loss=0.210969 error=0.106615 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2725 loss=0.210901 error=0.106562 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2726 loss=0.210833 error=0.106509 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2727 loss=0.210765 error=0.106457 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2728 loss=0.210698 error=0.106404 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2729 loss=0.210631 error=0.106351 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2730 loss=0.210564 error=0.106299 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: validation 273 loss=0.210497 error=0.106247 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2731 loss=0.210497 error=0.106247 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2732 loss=0.210430 error=0.106196 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2733 loss=0.210364 error=0.106144 grad(V)=0.000000 grad(U)=0.000006\n",
      "downhill: Adam 2734 loss=0.210297 error=0.106092 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2735 loss=0.210231 error=0.106041 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2736 loss=0.210165 error=0.105989 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2737 loss=0.210100 error=0.105938 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2738 loss=0.210034 error=0.105887 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2739 loss=0.209969 error=0.105836 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2740 loss=0.209903 error=0.105785 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 274 loss=0.209838 error=0.105735 grad(V)=0.000000 grad(U)=0.000005 *\n",
      "downhill: Adam 2741 loss=0.209838 error=0.105735 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2742 loss=0.209774 error=0.105684 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2743 loss=0.209709 error=0.105634 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2744 loss=0.209645 error=0.105583 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2745 loss=0.209580 error=0.105533 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2746 loss=0.209516 error=0.105483 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2747 loss=0.209453 error=0.105433 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2748 loss=0.209389 error=0.105383 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2749 loss=0.209325 error=0.105333 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2750 loss=0.209262 error=0.105284 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 275 loss=0.209199 error=0.105234 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2751 loss=0.209199 error=0.105234 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2752 loss=0.209136 error=0.105185 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2753 loss=0.209073 error=0.105136 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2754 loss=0.209011 error=0.105087 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2755 loss=0.208948 error=0.105038 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2756 loss=0.208886 error=0.104989 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2757 loss=0.208824 error=0.104941 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2758 loss=0.208762 error=0.104892 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2759 loss=0.208701 error=0.104844 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2760 loss=0.208639 error=0.104796 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 276 loss=0.208578 error=0.104748 grad(V)=0.000000 grad(U)=0.000005 *\n",
      "downhill: Adam 2761 loss=0.208578 error=0.104748 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2762 loss=0.208517 error=0.104700 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2763 loss=0.208456 error=0.104653 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2764 loss=0.208395 error=0.104605 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2765 loss=0.208334 error=0.104557 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2766 loss=0.208274 error=0.104509 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2767 loss=0.208213 error=0.104462 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2768 loss=0.208153 error=0.104415 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2769 loss=0.208094 error=0.104368 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2770 loss=0.208034 error=0.104321 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 277 loss=0.207974 error=0.104274 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2771 loss=0.207974 error=0.104274 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2772 loss=0.207915 error=0.104228 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2773 loss=0.207856 error=0.104181 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2774 loss=0.207797 error=0.104135 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2775 loss=0.207738 error=0.104088 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2776 loss=0.207679 error=0.104043 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2777 loss=0.207621 error=0.103996 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2778 loss=0.207563 error=0.103951 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2779 loss=0.207505 error=0.103905 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2780 loss=0.207447 error=0.103859 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 278 loss=0.207389 error=0.103814 grad(V)=0.000000 grad(U)=0.000005 *\n",
      "downhill: Adam 2781 loss=0.207389 error=0.103814 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2782 loss=0.207331 error=0.103768 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2783 loss=0.207274 error=0.103723 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2784 loss=0.207217 error=0.103678 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2785 loss=0.207160 error=0.103633 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2786 loss=0.207103 error=0.103588 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2787 loss=0.207046 error=0.103543 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2788 loss=0.206990 error=0.103499 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2789 loss=0.206934 error=0.103454 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2790 loss=0.206878 error=0.103409 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 279 loss=0.206822 error=0.103365 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2791 loss=0.206822 error=0.103365 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2792 loss=0.206766 error=0.103321 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2793 loss=0.206710 error=0.103277 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2794 loss=0.206655 error=0.103233 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2795 loss=0.206599 error=0.103189 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2796 loss=0.206544 error=0.103146 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2797 loss=0.206489 error=0.103102 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2798 loss=0.206435 error=0.103059 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2799 loss=0.206380 error=0.103015 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2800 loss=0.206326 error=0.102972 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 280 loss=0.206271 error=0.102928 grad(V)=0.000000 grad(U)=0.000005 *\n",
      "downhill: Adam 2801 loss=0.206271 error=0.102928 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2802 loss=0.206217 error=0.102885 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2803 loss=0.206164 error=0.102842 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2804 loss=0.206110 error=0.102799 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2805 loss=0.206056 error=0.102757 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2806 loss=0.206003 error=0.102714 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2807 loss=0.205950 error=0.102672 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2808 loss=0.205897 error=0.102630 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2809 loss=0.205844 error=0.102588 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2810 loss=0.205791 error=0.102545 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 281 loss=0.205738 error=0.102504 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2811 loss=0.205738 error=0.102504 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2812 loss=0.205686 error=0.102462 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2813 loss=0.205634 error=0.102420 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2814 loss=0.205582 error=0.102378 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2815 loss=0.205530 error=0.102336 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2816 loss=0.205478 error=0.102295 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2817 loss=0.205427 error=0.102254 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2818 loss=0.205375 error=0.102213 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2819 loss=0.205324 error=0.102172 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2820 loss=0.205273 error=0.102131 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 282 loss=0.205222 error=0.102090 grad(V)=0.000000 grad(U)=0.000005 *\n",
      "downhill: Adam 2821 loss=0.205222 error=0.102090 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2822 loss=0.205171 error=0.102049 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2823 loss=0.205121 error=0.102009 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2824 loss=0.205070 error=0.101968 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2825 loss=0.205020 error=0.101928 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2826 loss=0.204970 error=0.101887 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2827 loss=0.204920 error=0.101848 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2828 loss=0.204870 error=0.101807 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2829 loss=0.204821 error=0.101768 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2830 loss=0.204771 error=0.101727 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: validation 283 loss=0.204722 error=0.101689 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2831 loss=0.204722 error=0.101689 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2832 loss=0.204673 error=0.101649 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2833 loss=0.204624 error=0.101610 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2834 loss=0.204575 error=0.101570 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2835 loss=0.204526 error=0.101531 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2836 loss=0.204477 error=0.101492 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2837 loss=0.204429 error=0.101453 grad(V)=0.000000 grad(U)=0.000005\n",
      "downhill: Adam 2838 loss=0.204381 error=0.101415 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2839 loss=0.204333 error=0.101375 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2840 loss=0.204285 error=0.101337 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 284 loss=0.204237 error=0.101299 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2841 loss=0.204237 error=0.101299 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2842 loss=0.204189 error=0.101260 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2843 loss=0.204142 error=0.101222 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2844 loss=0.204095 error=0.101184 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2845 loss=0.204047 error=0.101146 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2846 loss=0.204000 error=0.101107 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2847 loss=0.203953 error=0.101070 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2848 loss=0.203907 error=0.101032 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2849 loss=0.203860 error=0.100995 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2850 loss=0.203814 error=0.100957 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 285 loss=0.203768 error=0.100920 grad(V)=0.000000 grad(U)=0.000004 *\n",
      "downhill: Adam 2851 loss=0.203768 error=0.100920 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2852 loss=0.203722 error=0.100883 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2853 loss=0.203676 error=0.100845 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2854 loss=0.203630 error=0.100808 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2855 loss=0.203584 error=0.100771 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2856 loss=0.203539 error=0.100735 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2857 loss=0.203494 error=0.100698 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2858 loss=0.203448 error=0.100662 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2859 loss=0.203403 error=0.100625 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2860 loss=0.203358 error=0.100589 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 286 loss=0.203314 error=0.100552 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2861 loss=0.203314 error=0.100552 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2862 loss=0.203269 error=0.100516 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2863 loss=0.203224 error=0.100480 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2864 loss=0.203180 error=0.100444 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2865 loss=0.203136 error=0.100408 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2866 loss=0.203092 error=0.100373 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2867 loss=0.203048 error=0.100337 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2868 loss=0.203004 error=0.100302 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2869 loss=0.202960 error=0.100266 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2870 loss=0.202917 error=0.100232 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 287 loss=0.202873 error=0.100195 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2871 loss=0.202873 error=0.100195 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2872 loss=0.202830 error=0.100162 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2873 loss=0.202787 error=0.100126 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2874 loss=0.202744 error=0.100092 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2875 loss=0.202701 error=0.100056 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2876 loss=0.202658 error=0.100023 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2877 loss=0.202616 error=0.099987 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2878 loss=0.202574 error=0.099954 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2879 loss=0.202531 error=0.099919 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2880 loss=0.202489 error=0.099884 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 288 loss=0.202447 error=0.099852 grad(V)=0.000000 grad(U)=0.000004 *\n",
      "downhill: Adam 2881 loss=0.202447 error=0.099852 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2882 loss=0.202405 error=0.099817 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2883 loss=0.202364 error=0.099784 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2884 loss=0.202322 error=0.099750 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2885 loss=0.202280 error=0.099716 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2886 loss=0.202239 error=0.099683 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2887 loss=0.202198 error=0.099649 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2888 loss=0.202157 error=0.099617 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2889 loss=0.202116 error=0.099583 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2890 loss=0.202075 error=0.099550 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 289 loss=0.202034 error=0.099517 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2891 loss=0.202034 error=0.099517 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2892 loss=0.201994 error=0.099484 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2893 loss=0.201954 error=0.099451 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2894 loss=0.201913 error=0.099418 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2895 loss=0.201873 error=0.099386 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2896 loss=0.201833 error=0.099353 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2897 loss=0.201793 error=0.099321 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2898 loss=0.201753 error=0.099289 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2899 loss=0.201714 error=0.099257 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2900 loss=0.201674 error=0.099224 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 290 loss=0.201635 error=0.099193 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2901 loss=0.201635 error=0.099193 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2902 loss=0.201595 error=0.099161 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2903 loss=0.201556 error=0.099129 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2904 loss=0.201517 error=0.099097 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2905 loss=0.201478 error=0.099066 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2906 loss=0.201440 error=0.099034 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2907 loss=0.201401 error=0.099003 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2908 loss=0.201362 error=0.098972 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2909 loss=0.201324 error=0.098940 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2910 loss=0.201286 error=0.098909 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 291 loss=0.201248 error=0.098879 grad(V)=0.000000 grad(U)=0.000004 *\n",
      "downhill: Adam 2911 loss=0.201248 error=0.098879 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2912 loss=0.201210 error=0.098847 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2913 loss=0.201172 error=0.098817 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2914 loss=0.201134 error=0.098786 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2915 loss=0.201096 error=0.098756 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2916 loss=0.201059 error=0.098724 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2917 loss=0.201021 error=0.098695 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2918 loss=0.200984 error=0.098664 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2919 loss=0.200947 error=0.098635 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2920 loss=0.200909 error=0.098604 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 292 loss=0.200873 error=0.098574 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2921 loss=0.200873 error=0.098574 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2922 loss=0.200836 error=0.098544 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2923 loss=0.200799 error=0.098514 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2924 loss=0.200762 error=0.098485 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2925 loss=0.200726 error=0.098454 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2926 loss=0.200690 error=0.098425 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2927 loss=0.200653 error=0.098395 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2928 loss=0.200617 error=0.098366 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2929 loss=0.200581 error=0.098336 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2930 loss=0.200545 error=0.098308 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 293 loss=0.200509 error=0.098278 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2931 loss=0.200509 error=0.098278 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2932 loss=0.200474 error=0.098249 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2933 loss=0.200438 error=0.098220 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2934 loss=0.200403 error=0.098191 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2935 loss=0.200367 error=0.098162 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2936 loss=0.200332 error=0.098133 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2937 loss=0.200297 error=0.098104 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2938 loss=0.200262 error=0.098075 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2939 loss=0.200227 error=0.098047 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2940 loss=0.200192 error=0.098019 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: validation 294 loss=0.200158 error=0.097990 grad(V)=0.000000 grad(U)=0.000004 *\n",
      "downhill: Adam 2941 loss=0.200158 error=0.097990 grad(V)=0.000000 grad(U)=0.000004\n",
      "downhill: Adam 2942 loss=0.200123 error=0.097962 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2943 loss=0.200088 error=0.097933 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2944 loss=0.200054 error=0.097905 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2945 loss=0.200020 error=0.097878 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2946 loss=0.199986 error=0.097850 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2947 loss=0.199952 error=0.097822 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2948 loss=0.199918 error=0.097794 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2949 loss=0.199884 error=0.097766 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2950 loss=0.199850 error=0.097739 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 295 loss=0.199816 error=0.097711 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2951 loss=0.199816 error=0.097711 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2952 loss=0.199783 error=0.097684 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2953 loss=0.199749 error=0.097657 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2954 loss=0.199716 error=0.097629 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2955 loss=0.199683 error=0.097602 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2956 loss=0.199650 error=0.097575 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2957 loss=0.199617 error=0.097547 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2958 loss=0.199584 error=0.097522 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2959 loss=0.199551 error=0.097493 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2960 loss=0.199518 error=0.097468 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 296 loss=0.199486 error=0.097440 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2961 loss=0.199486 error=0.097440 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2962 loss=0.199453 error=0.097415 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2963 loss=0.199421 error=0.097386 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2964 loss=0.199389 error=0.097362 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2965 loss=0.199356 error=0.097334 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2966 loss=0.199324 error=0.097308 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2967 loss=0.199292 error=0.097282 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2968 loss=0.199260 error=0.097255 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2969 loss=0.199228 error=0.097229 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2970 loss=0.199197 error=0.097203 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 297 loss=0.199165 error=0.097177 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2971 loss=0.199165 error=0.097177 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2972 loss=0.199134 error=0.097151 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2973 loss=0.199102 error=0.097125 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2974 loss=0.199071 error=0.097099 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2975 loss=0.199040 error=0.097074 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2976 loss=0.199009 error=0.097048 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2977 loss=0.198978 error=0.097023 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2978 loss=0.198947 error=0.096997 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2979 loss=0.198916 error=0.096972 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2980 loss=0.198885 error=0.096947 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 298 loss=0.198855 error=0.096922 grad(V)=0.000000 grad(U)=0.000003 *\n",
      "downhill: Adam 2981 loss=0.198855 error=0.096922 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2982 loss=0.198824 error=0.096897 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2983 loss=0.198794 error=0.096872 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2984 loss=0.198763 error=0.096847 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2985 loss=0.198733 error=0.096822 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2986 loss=0.198703 error=0.096797 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2987 loss=0.198673 error=0.096773 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2988 loss=0.198643 error=0.096748 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2989 loss=0.198613 error=0.096723 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2990 loss=0.198583 error=0.096699 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 299 loss=0.198554 error=0.096675 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2991 loss=0.198554 error=0.096675 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2992 loss=0.198524 error=0.096650 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2993 loss=0.198495 error=0.096627 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2994 loss=0.198465 error=0.096602 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2995 loss=0.198436 error=0.096579 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2996 loss=0.198407 error=0.096554 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2997 loss=0.198378 error=0.096531 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2998 loss=0.198349 error=0.096507 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 2999 loss=0.198320 error=0.096484 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3000 loss=0.198291 error=0.096459 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 300 loss=0.198262 error=0.096437 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3001 loss=0.198262 error=0.096437 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3002 loss=0.198234 error=0.096411 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3003 loss=0.198205 error=0.096389 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3004 loss=0.198177 error=0.096364 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3005 loss=0.198148 error=0.096342 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3006 loss=0.198120 error=0.096318 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3007 loss=0.198092 error=0.096296 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3008 loss=0.198064 error=0.096272 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3009 loss=0.198036 error=0.096249 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3010 loss=0.198008 error=0.096226 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 301 loss=0.197980 error=0.096203 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3011 loss=0.197980 error=0.096203 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3012 loss=0.197952 error=0.096181 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3013 loss=0.197925 error=0.096158 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3014 loss=0.197897 error=0.096136 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3015 loss=0.197870 error=0.096113 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3016 loss=0.197843 error=0.096090 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3017 loss=0.197816 error=0.096067 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3018 loss=0.197788 error=0.096045 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3019 loss=0.197761 error=0.096022 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3020 loss=0.197735 error=0.096000 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 302 loss=0.197708 error=0.095978 grad(V)=0.000000 grad(U)=0.000003 *\n",
      "downhill: Adam 3021 loss=0.197708 error=0.095978 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3022 loss=0.197681 error=0.095955 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3023 loss=0.197654 error=0.095933 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3024 loss=0.197628 error=0.095912 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3025 loss=0.197601 error=0.095890 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3026 loss=0.197575 error=0.095869 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3027 loss=0.197548 error=0.095847 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3028 loss=0.197522 error=0.095826 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3029 loss=0.197496 error=0.095804 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3030 loss=0.197470 error=0.095783 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 303 loss=0.197444 error=0.095760 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3031 loss=0.197444 error=0.095760 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3032 loss=0.197418 error=0.095741 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3033 loss=0.197392 error=0.095717 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3034 loss=0.197366 error=0.095699 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3035 loss=0.197341 error=0.095674 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3036 loss=0.197315 error=0.095657 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3037 loss=0.197290 error=0.095632 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3038 loss=0.197264 error=0.095614 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3039 loss=0.197239 error=0.095592 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3040 loss=0.197214 error=0.095570 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 304 loss=0.197189 error=0.095551 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3041 loss=0.197189 error=0.095551 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3042 loss=0.197163 error=0.095528 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3043 loss=0.197138 error=0.095509 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3044 loss=0.197113 error=0.095488 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3045 loss=0.197089 error=0.095467 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3046 loss=0.197064 error=0.095448 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3047 loss=0.197039 error=0.095426 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3048 loss=0.197014 error=0.095407 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3049 loss=0.196990 error=0.095386 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3050 loss=0.196965 error=0.095365 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 305 loss=0.196941 error=0.095346 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3051 loss=0.196941 error=0.095346 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3052 loss=0.196916 error=0.095325 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3053 loss=0.196892 error=0.095306 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3054 loss=0.196868 error=0.095285 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3055 loss=0.196844 error=0.095265 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3056 loss=0.196820 error=0.095245 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3057 loss=0.196796 error=0.095225 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3058 loss=0.196772 error=0.095205 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3059 loss=0.196748 error=0.095185 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3060 loss=0.196724 error=0.095165 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: validation 306 loss=0.196701 error=0.095146 grad(V)=0.000000 grad(U)=0.000003 *\n",
      "downhill: Adam 3061 loss=0.196701 error=0.095146 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3062 loss=0.196677 error=0.095125 grad(V)=0.000000 grad(U)=0.000003\n",
      "downhill: Adam 3063 loss=0.196653 error=0.095106 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3064 loss=0.196630 error=0.095086 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3065 loss=0.196607 error=0.095067 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3066 loss=0.196583 error=0.095047 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3067 loss=0.196560 error=0.095028 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3068 loss=0.196537 error=0.095008 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3069 loss=0.196514 error=0.094990 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3070 loss=0.196491 error=0.094969 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 307 loss=0.196468 error=0.094952 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3071 loss=0.196468 error=0.094952 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3072 loss=0.196445 error=0.094931 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3073 loss=0.196422 error=0.094914 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3074 loss=0.196399 error=0.094894 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3075 loss=0.196377 error=0.094876 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3076 loss=0.196354 error=0.094857 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3077 loss=0.196331 error=0.094838 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3078 loss=0.196309 error=0.094819 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3079 loss=0.196287 error=0.094800 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3080 loss=0.196264 error=0.094782 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 308 loss=0.196242 error=0.094763 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3081 loss=0.196242 error=0.094763 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3082 loss=0.196220 error=0.094745 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3083 loss=0.196198 error=0.094727 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3084 loss=0.196176 error=0.094708 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3085 loss=0.196154 error=0.094690 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3086 loss=0.196132 error=0.094672 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3087 loss=0.196110 error=0.094654 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3088 loss=0.196088 error=0.094636 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3089 loss=0.196067 error=0.094618 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3090 loss=0.196045 error=0.094601 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 309 loss=0.196023 error=0.094581 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3091 loss=0.196023 error=0.094581 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3092 loss=0.196002 error=0.094565 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3093 loss=0.195981 error=0.094545 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3094 loss=0.195959 error=0.094529 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3095 loss=0.195938 error=0.094509 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3096 loss=0.195917 error=0.094494 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3097 loss=0.195896 error=0.094473 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3098 loss=0.195875 error=0.094458 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3099 loss=0.195854 error=0.094438 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3100 loss=0.195833 error=0.094423 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 310 loss=0.195812 error=0.094404 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3101 loss=0.195812 error=0.094404 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3102 loss=0.195791 error=0.094389 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3103 loss=0.195771 error=0.094370 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3104 loss=0.195750 error=0.094354 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3105 loss=0.195730 error=0.094337 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3106 loss=0.195709 error=0.094319 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3107 loss=0.195689 error=0.094303 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3108 loss=0.195668 error=0.094285 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3109 loss=0.195648 error=0.094269 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3110 loss=0.195628 error=0.094252 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 311 loss=0.195608 error=0.094235 grad(V)=0.000000 grad(U)=0.000002 *\n",
      "downhill: Adam 3111 loss=0.195608 error=0.094235 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3112 loss=0.195588 error=0.094218 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3113 loss=0.195568 error=0.094201 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3114 loss=0.195548 error=0.094185 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3115 loss=0.195528 error=0.094168 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3116 loss=0.195508 error=0.094152 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3117 loss=0.195488 error=0.094135 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3118 loss=0.195469 error=0.094119 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3119 loss=0.195449 error=0.094103 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3120 loss=0.195429 error=0.094087 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 312 loss=0.195410 error=0.094071 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3121 loss=0.195410 error=0.094071 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3122 loss=0.195391 error=0.094054 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3123 loss=0.195371 error=0.094038 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3124 loss=0.195352 error=0.094022 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3125 loss=0.195333 error=0.094006 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3126 loss=0.195314 error=0.093990 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3127 loss=0.195294 error=0.093975 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3128 loss=0.195275 error=0.093959 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3129 loss=0.195256 error=0.093943 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3130 loss=0.195238 error=0.093928 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 313 loss=0.195219 error=0.093912 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3131 loss=0.195219 error=0.093912 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3132 loss=0.195200 error=0.093896 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3133 loss=0.195181 error=0.093881 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3134 loss=0.195163 error=0.093866 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3135 loss=0.195144 error=0.093850 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3136 loss=0.195125 error=0.093835 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3137 loss=0.195107 error=0.093820 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3138 loss=0.195089 error=0.093805 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3139 loss=0.195070 error=0.093789 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3140 loss=0.195052 error=0.093775 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 314 loss=0.195034 error=0.093759 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3141 loss=0.195034 error=0.093759 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3142 loss=0.195016 error=0.093745 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3143 loss=0.194998 error=0.093729 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3144 loss=0.194980 error=0.093715 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3145 loss=0.194962 error=0.093699 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3146 loss=0.194944 error=0.093686 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3147 loss=0.194926 error=0.093669 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3148 loss=0.194908 error=0.093657 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3149 loss=0.194890 error=0.093640 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3150 loss=0.194873 error=0.093628 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 315 loss=0.194855 error=0.093612 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3151 loss=0.194855 error=0.093612 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3152 loss=0.194838 error=0.093599 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3153 loss=0.194820 error=0.093584 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3154 loss=0.194803 error=0.093570 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3155 loss=0.194785 error=0.093556 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3156 loss=0.194768 error=0.093541 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3157 loss=0.194751 error=0.093527 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3158 loss=0.194734 error=0.093513 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3159 loss=0.194717 error=0.093498 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3160 loss=0.194700 error=0.093485 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 316 loss=0.194682 error=0.093470 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3161 loss=0.194682 error=0.093470 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3162 loss=0.194666 error=0.093457 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3163 loss=0.194649 error=0.093442 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3164 loss=0.194632 error=0.093429 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3165 loss=0.194615 error=0.093414 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3166 loss=0.194599 error=0.093402 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3167 loss=0.194582 error=0.093387 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3168 loss=0.194566 error=0.093374 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3169 loss=0.194549 error=0.093360 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3170 loss=0.194533 error=0.093347 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 317 loss=0.194516 error=0.093333 grad(V)=0.000000 grad(U)=0.000002 *\n",
      "downhill: Adam 3171 loss=0.194516 error=0.093333 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3172 loss=0.194500 error=0.093320 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3173 loss=0.194484 error=0.093305 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3174 loss=0.194468 error=0.093295 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3175 loss=0.194451 error=0.093278 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3176 loss=0.194435 error=0.093269 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3177 loss=0.194419 error=0.093251 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3178 loss=0.194403 error=0.093243 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3179 loss=0.194388 error=0.093226 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3180 loss=0.194371 error=0.093215 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 318 loss=0.194356 error=0.093202 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3181 loss=0.194356 error=0.093202 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3182 loss=0.194340 error=0.093188 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3183 loss=0.194324 error=0.093178 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3184 loss=0.194309 error=0.093162 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3185 loss=0.194293 error=0.093152 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3186 loss=0.194277 error=0.093138 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3187 loss=0.194262 error=0.093125 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3188 loss=0.194246 error=0.093113 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3189 loss=0.194231 error=0.093099 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3190 loss=0.194216 error=0.093088 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 319 loss=0.194200 error=0.093074 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3191 loss=0.194200 error=0.093074 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3192 loss=0.194185 error=0.093062 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3193 loss=0.194170 error=0.093050 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3194 loss=0.194155 error=0.093036 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3195 loss=0.194140 error=0.093025 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3196 loss=0.194125 error=0.093012 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3197 loss=0.194110 error=0.093000 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3198 loss=0.194095 error=0.092988 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3199 loss=0.194080 error=0.092976 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3200 loss=0.194065 error=0.092965 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 320 loss=0.194050 error=0.092952 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3201 loss=0.194050 error=0.092952 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3202 loss=0.194035 error=0.092940 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3203 loss=0.194020 error=0.092928 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3204 loss=0.194006 error=0.092916 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3205 loss=0.193991 error=0.092904 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3206 loss=0.193977 error=0.092891 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3207 loss=0.193962 error=0.092880 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3208 loss=0.193948 error=0.092868 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3209 loss=0.193933 error=0.092857 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3210 loss=0.193919 error=0.092845 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 321 loss=0.193904 error=0.092833 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3211 loss=0.193904 error=0.092833 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3212 loss=0.193890 error=0.092822 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3213 loss=0.193876 error=0.092810 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3214 loss=0.193862 error=0.092798 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3215 loss=0.193848 error=0.092788 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3216 loss=0.193834 error=0.092775 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3217 loss=0.193819 error=0.092766 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3218 loss=0.193806 error=0.092752 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3219 loss=0.193792 error=0.092744 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3220 loss=0.193778 error=0.092730 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 322 loss=0.193764 error=0.092721 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3221 loss=0.193764 error=0.092721 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3222 loss=0.193750 error=0.092708 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3223 loss=0.193736 error=0.092698 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3224 loss=0.193722 error=0.092686 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3225 loss=0.193709 error=0.092676 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3226 loss=0.193695 error=0.092664 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3227 loss=0.193681 error=0.092654 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3228 loss=0.193668 error=0.092642 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3229 loss=0.193654 error=0.092633 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: Adam 3230 loss=0.193641 error=0.092621 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: validation 323 loss=0.193627 error=0.092611 grad(V)=0.000000 grad(U)=0.000002\n",
      "downhill: patience elapsed!\n"
     ]
    }
   ],
   "source": [
    "x_filled_fac = MatrixFactorization(l1_penalty=0.3).complete(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _round(x):\n",
    "    x[x < 0.5] = 0\n",
    "    x[x >= 0.5] = 1\n",
    "\n",
    "x_filled_knn = (x_filled_knn * std) + mean\n",
    "_round(x_filled_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_filled_softimpute = (x_filled_softimpute * std) + mean\n",
    "_round(x_filled_softimpute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_filled_fac = (x_filled_fac * std) + mean\n",
    "_round(x_filled_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"knn_filled.txt\", x_filled_knn.astype(np.uint64))\n",
    "np.savetxt(\"softimpute_filled_txt\", x_filled_softimpute.astype(np.uint64))\n",
    "np.savetxt(\"fac_filled.txt\", x_filled_fac.astype(np.uint64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
